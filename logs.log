2024-01-17 19:06:15,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 19:06:15,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 19:06:15,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 19:06:15,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 19:33:46,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 19:33:46,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 19:33:46,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 19:33:46,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 19:33:52,003:INFO:PyCaret RegressionExperiment
2024-01-17 19:33:52,003:INFO:Logging name: reg-default-name
2024-01-17 19:33:52,003:INFO:ML Usecase: MLUsecase.REGRESSION
2024-01-17 19:33:52,003:INFO:version 3.2.0
2024-01-17 19:33:52,003:INFO:Initializing setup()
2024-01-17 19:33:52,003:INFO:self.USI: a94c
2024-01-17 19:33:52,003:INFO:self._variable_keys: {'idx', 'exp_name_log', 'X_train', 'gpu_param', 'y_train', 'fold_shuffle_param', 'USI', 'html_param', 'pipeline', 'target_param', 'seed', 'X', 'data', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', 'n_jobs_param', '_available_plots', 'X_test', 'fold_groups_param', 'y_test', 'log_plots_param', 'logging_param', '_ml_usecase', 'y', 'memory', 'transform_target_param'}
2024-01-17 19:33:52,003:INFO:Checking environment
2024-01-17 19:33:52,003:INFO:python_version: 3.11.5
2024-01-17 19:33:52,018:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 19:33:52,018:INFO:machine: AMD64
2024-01-17 19:33:52,018:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 19:33:52,018:INFO:Memory: svmem(total=8361132032, available=1649520640, percent=80.3, used=6711611392, free=1649520640)
2024-01-17 19:33:52,018:INFO:Physical Core: 2
2024-01-17 19:33:52,018:INFO:Logical Core: 4
2024-01-17 19:33:52,018:INFO:Checking libraries
2024-01-17 19:33:52,018:INFO:System:
2024-01-17 19:33:52,018:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 19:33:52,018:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 19:33:52,018:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 19:33:52,018:INFO:PyCaret required dependencies:
2024-01-17 19:34:00,688:INFO:                 pip: 23.2.1
2024-01-17 19:34:00,688:INFO:          setuptools: 68.0.0
2024-01-17 19:34:00,688:INFO:             pycaret: 3.2.0
2024-01-17 19:34:00,688:INFO:             IPython: 8.15.0
2024-01-17 19:34:00,688:INFO:          ipywidgets: 8.0.4
2024-01-17 19:34:00,688:INFO:                tqdm: 4.65.0
2024-01-17 19:34:00,688:INFO:               numpy: 1.24.3
2024-01-17 19:34:00,688:INFO:              pandas: 1.5.3
2024-01-17 19:34:00,688:INFO:              jinja2: 3.1.2
2024-01-17 19:34:00,688:INFO:               scipy: 1.10.1
2024-01-17 19:34:00,688:INFO:              joblib: 1.2.0
2024-01-17 19:34:00,688:INFO:             sklearn: 1.2.2
2024-01-17 19:34:00,688:INFO:                pyod: 1.1.2
2024-01-17 19:34:00,688:INFO:            imblearn: 0.10.1
2024-01-17 19:34:00,688:INFO:   category_encoders: 2.6.3
2024-01-17 19:34:00,688:INFO:            lightgbm: 4.2.0
2024-01-17 19:34:00,688:INFO:               numba: 0.57.1
2024-01-17 19:34:00,688:INFO:            requests: 2.31.0
2024-01-17 19:34:00,688:INFO:          matplotlib: 3.6.0
2024-01-17 19:34:00,688:INFO:          scikitplot: 0.3.7
2024-01-17 19:34:00,688:INFO:         yellowbrick: 1.5
2024-01-17 19:34:00,688:INFO:              plotly: 5.9.0
2024-01-17 19:34:00,688:INFO:    plotly-resampler: Not installed
2024-01-17 19:34:00,688:INFO:             kaleido: 0.2.1
2024-01-17 19:34:00,688:INFO:           schemdraw: 0.15
2024-01-17 19:34:00,688:INFO:         statsmodels: 0.14.0
2024-01-17 19:34:00,688:INFO:              sktime: 0.21.1
2024-01-17 19:34:00,688:INFO:               tbats: 1.1.3
2024-01-17 19:34:00,688:INFO:            pmdarima: 2.0.4
2024-01-17 19:34:00,688:INFO:              psutil: 5.9.0
2024-01-17 19:34:00,688:INFO:          markupsafe: 2.1.1
2024-01-17 19:34:00,688:INFO:             pickle5: Not installed
2024-01-17 19:34:00,688:INFO:         cloudpickle: 2.2.1
2024-01-17 19:34:00,688:INFO:         deprecation: 2.1.0
2024-01-17 19:34:00,688:INFO:              xxhash: 2.0.2
2024-01-17 19:34:00,688:INFO:           wurlitzer: Not installed
2024-01-17 19:34:00,688:INFO:PyCaret optional dependencies:
2024-01-17 19:34:00,734:INFO:                shap: Not installed
2024-01-17 19:34:00,734:INFO:           interpret: Not installed
2024-01-17 19:34:00,736:INFO:                umap: Not installed
2024-01-17 19:34:00,736:INFO:     ydata_profiling: Not installed
2024-01-17 19:34:00,736:INFO:  explainerdashboard: Not installed
2024-01-17 19:34:00,736:INFO:             autoviz: Not installed
2024-01-17 19:34:00,736:INFO:           fairlearn: Not installed
2024-01-17 19:34:00,736:INFO:          deepchecks: Not installed
2024-01-17 19:34:00,736:INFO:             xgboost: Not installed
2024-01-17 19:34:00,736:INFO:            catboost: 1.2.2
2024-01-17 19:34:00,736:INFO:              kmodes: Not installed
2024-01-17 19:34:00,736:INFO:             mlxtend: Not installed
2024-01-17 19:34:00,736:INFO:       statsforecast: Not installed
2024-01-17 19:34:00,736:INFO:        tune_sklearn: Not installed
2024-01-17 19:34:00,736:INFO:                 ray: Not installed
2024-01-17 19:34:00,736:INFO:            hyperopt: Not installed
2024-01-17 19:34:00,736:INFO:              optuna: Not installed
2024-01-17 19:34:00,736:INFO:               skopt: Not installed
2024-01-17 19:34:00,736:INFO:              mlflow: Not installed
2024-01-17 19:34:00,736:INFO:              gradio: Not installed
2024-01-17 19:34:00,736:INFO:             fastapi: Not installed
2024-01-17 19:34:00,736:INFO:             uvicorn: Not installed
2024-01-17 19:34:00,736:INFO:              m2cgen: Not installed
2024-01-17 19:34:00,736:INFO:           evidently: Not installed
2024-01-17 19:34:00,736:INFO:               fugue: Not installed
2024-01-17 19:34:00,736:INFO:           streamlit: Not installed
2024-01-17 19:34:00,736:INFO:             prophet: Not installed
2024-01-17 19:34:00,736:INFO:None
2024-01-17 19:34:00,736:INFO:Set up data.
2024-01-17 19:34:01,500:INFO:Set up folding strategy.
2024-01-17 19:34:01,500:INFO:Set up train/test split.
2024-01-17 19:34:01,721:INFO:Set up index.
2024-01-17 19:34:01,799:INFO:Assigning column types.
2024-01-17 19:34:01,846:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-17 19:34:01,846:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-01-17 19:34:01,856:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-01-17 19:34:01,862:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,129:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:02,129:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:02,269:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,285:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,301:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,474:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:02,580:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:02,580:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-01-17 19:34:02,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,585:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,835:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:02,836:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:02,839:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-01-17 19:34:02,978:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:03,088:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:03,088:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-01-17 19:34:03,104:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,340:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:03,340:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:03,371:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:03,590:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:03,590:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-01-17 19:34:03,762:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:34:03,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:03,902:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:04,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:06,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:34:06,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:06,220:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:06,235:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-17 19:34:06,439:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:06,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:06,566:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:06,769:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-01-17 19:34:06,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:06,911:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:06,911:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-01-17 19:34:07,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:07,255:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:07,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:07,586:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:07,698:INFO:Preparing preprocessing pipeline...
2024-01-17 19:34:07,698:INFO:Set up simple imputation.
2024-01-17 19:34:07,714:INFO:Set up encoding of categorical features.
2024-01-17 19:34:07,983:INFO:Finished creating preprocessing pipeline.
2024-01-17 19:34:08,034:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['longitude', 'latitude',
                                             'housing_median_age',
                                             'total_rooms', 'total_bedrooms',
                                             'population', 'households',
                                             'median_income'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['ocean_proximity'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['ocean_proximity'],
                                    transformer=OneHotEncoder(cols=['ocean_proximity'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2024-01-17 19:34:08,034:INFO:Creating final display dataframe.
2024-01-17 19:34:08,595:INFO:Setup _display_container:                     Description               Value
0                    Session id                8618
1                        Target  median_house_value
2                   Target type          Regression
3           Original data shape         (20640, 10)
4        Transformed data shape         (20640, 14)
5   Transformed train set shape         (14447, 14)
6    Transformed test set shape          (6193, 14)
7              Numeric features                   8
8          Categorical features                   1
9      Rows with missing values                1.0%
10                   Preprocess                True
11              Imputation type              simple
12           Numeric imputation                mean
13       Categorical imputation                mode
14     Maximum one-hot encoding                  25
15              Encoding method                None
16               Fold Generator               KFold
17                  Fold Number                  10
18                     CPU Jobs                  -1
19                      Use GPU               False
20               Log Experiment               False
21              Experiment Name    reg-default-name
22                          USI                a94c
2024-01-17 19:34:08,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:08,962:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:09,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:34:09,308:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:34:09,308:INFO:setup() successfully completed in 17.32s...............
2024-01-17 19:44:40,346:INFO:PyCaret ClassificationExperiment
2024-01-17 19:44:40,346:INFO:Logging name: clf-default-name
2024-01-17 19:44:40,346:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-17 19:44:40,346:INFO:version 3.2.0
2024-01-17 19:44:40,346:INFO:Initializing setup()
2024-01-17 19:44:40,346:INFO:self.USI: 2ae8
2024-01-17 19:44:40,346:INFO:self._variable_keys: {'idx', 'exp_name_log', 'X_train', 'gpu_param', 'y_train', 'fold_shuffle_param', 'USI', 'html_param', 'pipeline', 'target_param', 'seed', 'X', 'data', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', 'n_jobs_param', '_available_plots', 'X_test', 'fold_groups_param', 'fix_imbalance', 'y_test', 'log_plots_param', 'logging_param', '_ml_usecase', 'y', 'memory', 'is_multiclass'}
2024-01-17 19:44:40,346:INFO:Checking environment
2024-01-17 19:44:40,346:INFO:python_version: 3.11.5
2024-01-17 19:44:40,346:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 19:44:40,346:INFO:machine: AMD64
2024-01-17 19:44:40,346:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 19:44:40,346:INFO:Memory: svmem(total=8361132032, available=1253363712, percent=85.0, used=7107768320, free=1253363712)
2024-01-17 19:44:40,346:INFO:Physical Core: 2
2024-01-17 19:44:40,346:INFO:Logical Core: 4
2024-01-17 19:44:40,346:INFO:Checking libraries
2024-01-17 19:44:40,346:INFO:System:
2024-01-17 19:44:40,346:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 19:44:40,346:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 19:44:40,346:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 19:44:40,346:INFO:PyCaret required dependencies:
2024-01-17 19:44:40,346:INFO:                 pip: 23.2.1
2024-01-17 19:44:40,346:INFO:          setuptools: 68.0.0
2024-01-17 19:44:40,346:INFO:             pycaret: 3.2.0
2024-01-17 19:44:40,346:INFO:             IPython: 8.15.0
2024-01-17 19:44:40,346:INFO:          ipywidgets: 8.0.4
2024-01-17 19:44:40,346:INFO:                tqdm: 4.65.0
2024-01-17 19:44:40,346:INFO:               numpy: 1.24.3
2024-01-17 19:44:40,346:INFO:              pandas: 1.5.3
2024-01-17 19:44:40,346:INFO:              jinja2: 3.1.2
2024-01-17 19:44:40,346:INFO:               scipy: 1.10.1
2024-01-17 19:44:40,346:INFO:              joblib: 1.2.0
2024-01-17 19:44:40,346:INFO:             sklearn: 1.2.2
2024-01-17 19:44:40,346:INFO:                pyod: 1.1.2
2024-01-17 19:44:40,346:INFO:            imblearn: 0.10.1
2024-01-17 19:44:40,346:INFO:   category_encoders: 2.6.3
2024-01-17 19:44:40,346:INFO:            lightgbm: 4.2.0
2024-01-17 19:44:40,346:INFO:               numba: 0.57.1
2024-01-17 19:44:40,346:INFO:            requests: 2.31.0
2024-01-17 19:44:40,346:INFO:          matplotlib: 3.6.0
2024-01-17 19:44:40,346:INFO:          scikitplot: 0.3.7
2024-01-17 19:44:40,346:INFO:         yellowbrick: 1.5
2024-01-17 19:44:40,346:INFO:              plotly: 5.9.0
2024-01-17 19:44:40,346:INFO:    plotly-resampler: Not installed
2024-01-17 19:44:40,346:INFO:             kaleido: 0.2.1
2024-01-17 19:44:40,346:INFO:           schemdraw: 0.15
2024-01-17 19:44:40,346:INFO:         statsmodels: 0.14.0
2024-01-17 19:44:40,346:INFO:              sktime: 0.21.1
2024-01-17 19:44:40,346:INFO:               tbats: 1.1.3
2024-01-17 19:44:40,346:INFO:            pmdarima: 2.0.4
2024-01-17 19:44:40,346:INFO:              psutil: 5.9.0
2024-01-17 19:44:40,346:INFO:          markupsafe: 2.1.1
2024-01-17 19:44:40,346:INFO:             pickle5: Not installed
2024-01-17 19:44:40,346:INFO:         cloudpickle: 2.2.1
2024-01-17 19:44:40,346:INFO:         deprecation: 2.1.0
2024-01-17 19:44:40,346:INFO:              xxhash: 2.0.2
2024-01-17 19:44:40,346:INFO:           wurlitzer: Not installed
2024-01-17 19:44:40,346:INFO:PyCaret optional dependencies:
2024-01-17 19:44:40,346:INFO:                shap: Not installed
2024-01-17 19:44:40,346:INFO:           interpret: Not installed
2024-01-17 19:44:40,346:INFO:                umap: Not installed
2024-01-17 19:44:40,346:INFO:     ydata_profiling: Not installed
2024-01-17 19:44:40,346:INFO:  explainerdashboard: Not installed
2024-01-17 19:44:40,346:INFO:             autoviz: Not installed
2024-01-17 19:44:40,346:INFO:           fairlearn: Not installed
2024-01-17 19:44:40,346:INFO:          deepchecks: Not installed
2024-01-17 19:44:40,346:INFO:             xgboost: Not installed
2024-01-17 19:44:40,346:INFO:            catboost: 1.2.2
2024-01-17 19:44:40,346:INFO:              kmodes: Not installed
2024-01-17 19:44:40,346:INFO:             mlxtend: Not installed
2024-01-17 19:44:40,346:INFO:       statsforecast: Not installed
2024-01-17 19:44:40,346:INFO:        tune_sklearn: Not installed
2024-01-17 19:44:40,362:INFO:                 ray: Not installed
2024-01-17 19:44:40,362:INFO:            hyperopt: Not installed
2024-01-17 19:44:40,362:INFO:              optuna: Not installed
2024-01-17 19:44:40,362:INFO:               skopt: Not installed
2024-01-17 19:44:40,362:INFO:              mlflow: Not installed
2024-01-17 19:44:40,362:INFO:              gradio: Not installed
2024-01-17 19:44:40,362:INFO:             fastapi: Not installed
2024-01-17 19:44:40,362:INFO:             uvicorn: Not installed
2024-01-17 19:44:40,362:INFO:              m2cgen: Not installed
2024-01-17 19:44:40,362:INFO:           evidently: Not installed
2024-01-17 19:44:40,362:INFO:               fugue: Not installed
2024-01-17 19:44:40,362:INFO:           streamlit: Not installed
2024-01-17 19:44:40,362:INFO:             prophet: Not installed
2024-01-17 19:44:40,362:INFO:None
2024-01-17 19:44:40,362:INFO:Set up data.
2024-01-17 19:44:40,446:INFO:Set up folding strategy.
2024-01-17 19:44:40,446:INFO:Set up train/test split.
2024-01-17 19:44:40,889:INFO:Set up index.
2024-01-17 19:44:40,889:INFO:Assigning column types.
2024-01-17 19:44:40,896:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-17 19:44:41,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:44:41,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 19:44:41,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:44:41,265:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:44:41,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:44:41,441:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 19:44:41,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:44:41,528:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:44:41,528:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-17 19:44:41,678:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 19:44:41,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:44:41,772:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:44:41,888:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 19:44:41,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:44:41,979:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:44:41,985:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-17 19:44:42,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:44:42,089:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:44:42,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:44:42,198:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:44:42,204:INFO:Preparing preprocessing pipeline...
2024-01-17 19:44:42,204:INFO:Set up label encoding.
2024-01-17 19:44:42,204:INFO:Set up simple imputation.
2024-01-17 19:44:42,214:INFO:Set up encoding of ordinal features.
2024-01-17 19:44:42,230:INFO:Set up encoding of categorical features.
2024-01-17 19:44:43,161:INFO:Finished creating preprocessing pipeline.
2024-01-17 19:44:43,241:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Age', 'SibSp',
                                             'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=Tru...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-17 19:44:43,241:INFO:Creating final display dataframe.
2024-01-17 19:44:44,825:INFO:Setup _display_container:                     Description             Value
0                    Session id              8756
1                        Target            Pclass
2                   Target type        Multiclass
3                Target mapping  1: 0, 2: 1, 3: 2
4           Original data shape         (891, 11)
5        Transformed data shape         (891, 13)
6   Transformed train set shape         (623, 13)
7    Transformed test set shape         (268, 13)
8              Ordinal features                 1
9              Numeric features                 5
10         Categorical features                 5
11     Rows with missing values             79.5%
12                   Preprocess              True
13              Imputation type            simple
14           Numeric imputation              mean
15       Categorical imputation              mode
16     Maximum one-hot encoding                25
17              Encoding method              None
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              2ae8
2024-01-17 19:44:45,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:44:45,055:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:44:45,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:44:45,267:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:44:45,267:INFO:setup() successfully completed in 4.94s...............
2024-01-17 19:44:52,057:INFO:Initializing compare_models()
2024-01-17 19:44:52,058:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-17 19:44:52,058:INFO:Checking exceptions
2024-01-17 19:44:52,135:INFO:Preparing display monitor
2024-01-17 19:44:52,250:INFO:Initializing Logistic Regression
2024-01-17 19:44:52,250:INFO:Total runtime is 0.0 minutes
2024-01-17 19:44:52,259:INFO:SubProcess create_model() called ==================================
2024-01-17 19:44:52,261:INFO:Initializing create_model()
2024-01-17 19:44:52,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:44:52,261:INFO:Checking exceptions
2024-01-17 19:44:52,261:INFO:Importing libraries
2024-01-17 19:44:52,261:INFO:Copying training dataset
2024-01-17 19:44:52,265:INFO:Defining folds
2024-01-17 19:44:52,265:INFO:Declaring metric variables
2024-01-17 19:44:52,275:INFO:Importing untrained model
2024-01-17 19:44:52,280:INFO:Logistic Regression Imported successfully
2024-01-17 19:44:52,301:INFO:Starting cross validation
2024-01-17 19:44:52,302:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:45:50,701:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:45:50,701:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:45:50,717:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:45:51,014:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:51,030:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:51,030:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:51,030:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:51,045:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:51,045:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:51,045:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:51,045:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:51,061:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,678:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:45:52,709:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:45:52,725:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:45:52,788:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:45:52,869:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,884:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,899:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,903:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,914:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,914:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,914:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,930:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,947:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,977:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,978:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:52,994:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:54,032:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:45:54,064:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:45:54,158:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:54,174:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:54,174:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:54,189:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:54,189:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:54,189:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:54,205:INFO:Calculating mean and std
2024-01-17 19:45:54,220:INFO:Creating metrics dataframe
2024-01-17 19:45:54,392:INFO:Uploading results into container
2024-01-17 19:45:54,392:INFO:Uploading model into container now
2024-01-17 19:45:54,392:INFO:_master_model_container: 1
2024-01-17 19:45:54,392:INFO:_display_container: 2
2024-01-17 19:45:54,409:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 19:45:54,409:INFO:create_model() successfully completed......................................
2024-01-17 19:45:54,633:INFO:SubProcess create_model() end ==================================
2024-01-17 19:45:54,633:INFO:Creating metrics dataframe
2024-01-17 19:45:54,662:INFO:Initializing K Neighbors Classifier
2024-01-17 19:45:54,662:INFO:Total runtime is 1.0401859402656555 minutes
2024-01-17 19:45:54,679:INFO:SubProcess create_model() called ==================================
2024-01-17 19:45:54,680:INFO:Initializing create_model()
2024-01-17 19:45:54,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:45:54,680:INFO:Checking exceptions
2024-01-17 19:45:54,680:INFO:Importing libraries
2024-01-17 19:45:54,680:INFO:Copying training dataset
2024-01-17 19:45:54,697:INFO:Defining folds
2024-01-17 19:45:54,698:INFO:Declaring metric variables
2024-01-17 19:45:54,706:INFO:Importing untrained model
2024-01-17 19:45:54,741:INFO:K Neighbors Classifier Imported successfully
2024-01-17 19:45:54,754:INFO:Starting cross validation
2024-01-17 19:45:54,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:45:56,675:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,683:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,691:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,691:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,691:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,691:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,707:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,709:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,724:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,944:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,963:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:56,975:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,385:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,385:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,401:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,401:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,412:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,412:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,417:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,433:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,448:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,625:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,631:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,938:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,954:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,970:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,970:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,986:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:57,986:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:58,001:INFO:Calculating mean and std
2024-01-17 19:45:58,017:INFO:Creating metrics dataframe
2024-01-17 19:45:58,018:INFO:Uploading results into container
2024-01-17 19:45:58,033:INFO:Uploading model into container now
2024-01-17 19:45:58,033:INFO:_master_model_container: 2
2024-01-17 19:45:58,033:INFO:_display_container: 2
2024-01-17 19:45:58,033:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-17 19:45:58,033:INFO:create_model() successfully completed......................................
2024-01-17 19:45:58,259:INFO:SubProcess create_model() end ==================================
2024-01-17 19:45:58,259:INFO:Creating metrics dataframe
2024-01-17 19:45:58,288:INFO:Initializing Naive Bayes
2024-01-17 19:45:58,288:INFO:Total runtime is 1.100626007715861 minutes
2024-01-17 19:45:58,308:INFO:SubProcess create_model() called ==================================
2024-01-17 19:45:58,308:INFO:Initializing create_model()
2024-01-17 19:45:58,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:45:58,308:INFO:Checking exceptions
2024-01-17 19:45:58,311:INFO:Importing libraries
2024-01-17 19:45:58,311:INFO:Copying training dataset
2024-01-17 19:45:58,327:INFO:Defining folds
2024-01-17 19:45:58,327:INFO:Declaring metric variables
2024-01-17 19:45:58,345:INFO:Importing untrained model
2024-01-17 19:45:58,359:INFO:Naive Bayes Imported successfully
2024-01-17 19:45:58,375:INFO:Starting cross validation
2024-01-17 19:45:58,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:45:59,055:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,071:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,087:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:45:59,087:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,087:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,119:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:45:59,123:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,150:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,151:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,166:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,166:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,181:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,197:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,700:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,715:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,730:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:45:59,736:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,740:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,748:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,765:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:45:59,765:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,779:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,780:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,780:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:45:59,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:00,204:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:00,204:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:00,220:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:00,220:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:00,220:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:00,220:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:00,251:INFO:Calculating mean and std
2024-01-17 19:46:00,251:INFO:Creating metrics dataframe
2024-01-17 19:46:00,267:INFO:Uploading results into container
2024-01-17 19:46:00,267:INFO:Uploading model into container now
2024-01-17 19:46:00,267:INFO:_master_model_container: 3
2024-01-17 19:46:00,267:INFO:_display_container: 2
2024-01-17 19:46:00,267:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-17 19:46:00,267:INFO:create_model() successfully completed......................................
2024-01-17 19:46:00,458:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:00,458:INFO:Creating metrics dataframe
2024-01-17 19:46:00,489:INFO:Initializing Decision Tree Classifier
2024-01-17 19:46:00,489:INFO:Total runtime is 1.1373057643572488 minutes
2024-01-17 19:46:00,497:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:00,497:INFO:Initializing create_model()
2024-01-17 19:46:00,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:00,497:INFO:Checking exceptions
2024-01-17 19:46:00,497:INFO:Importing libraries
2024-01-17 19:46:00,497:INFO:Copying training dataset
2024-01-17 19:46:00,513:INFO:Defining folds
2024-01-17 19:46:00,513:INFO:Declaring metric variables
2024-01-17 19:46:00,521:INFO:Importing untrained model
2024-01-17 19:46:00,532:INFO:Decision Tree Classifier Imported successfully
2024-01-17 19:46:00,546:INFO:Starting cross validation
2024-01-17 19:46:00,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:02,481:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,496:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,496:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,504:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,504:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,504:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:02,504:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,513:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,513:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,513:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:02,513:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

odifier, msg_start, len(result))

2024-01-17 19:46:02,528:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,528:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:02,528:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,528:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,827:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,842:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,842:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,842:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:02,842:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,842:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,842:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:02,842:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:02,842:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,858:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,858:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,858:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,858:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:02,858:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,999:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,999:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,999:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,999:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:02,999:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,999:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:02,999:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:02,999:INFO:Calculating mean and std
2024-01-17 19:46:02,999:INFO:Creating metrics dataframe
2024-01-17 19:46:02,999:INFO:Uploading results into container
2024-01-17 19:46:02,999:INFO:Uploading model into container now
2024-01-17 19:46:03,014:INFO:_master_model_container: 4
2024-01-17 19:46:03,014:INFO:_display_container: 2
2024-01-17 19:46:03,014:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8756, splitter='best')
2024-01-17 19:46:03,014:INFO:create_model() successfully completed......................................
2024-01-17 19:46:03,089:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:03,089:INFO:Creating metrics dataframe
2024-01-17 19:46:03,104:INFO:Initializing SVM - Linear Kernel
2024-01-17 19:46:03,104:INFO:Total runtime is 1.1808929522832234 minutes
2024-01-17 19:46:03,114:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:03,114:INFO:Initializing create_model()
2024-01-17 19:46:03,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:03,114:INFO:Checking exceptions
2024-01-17 19:46:03,114:INFO:Importing libraries
2024-01-17 19:46:03,114:INFO:Copying training dataset
2024-01-17 19:46:03,125:INFO:Defining folds
2024-01-17 19:46:03,125:INFO:Declaring metric variables
2024-01-17 19:46:03,125:INFO:Importing untrained model
2024-01-17 19:46:03,125:INFO:SVM - Linear Kernel Imported successfully
2024-01-17 19:46:03,147:INFO:Starting cross validation
2024-01-17 19:46:03,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:04,752:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:46:04,752:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:46:04,752:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:46:04,752:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:46:04,752:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,752:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,752:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,766:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:04,766:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,766:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,766:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,766:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:04,783:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,804:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,807:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:04,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:04,830:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:04,830:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:05,433:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:46:09,538:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,538:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,538:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,546:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,546:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,546:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:09,546:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,561:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,578:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,578:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:09,578:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,887:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:46:09,888:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,894:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,894:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:09,894:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,913:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:46:09,913:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,925:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,925:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:09,925:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:09,942:INFO:Calculating mean and std
2024-01-17 19:46:09,942:INFO:Creating metrics dataframe
2024-01-17 19:46:09,960:INFO:Uploading results into container
2024-01-17 19:46:09,960:INFO:Uploading model into container now
2024-01-17 19:46:09,960:INFO:_master_model_container: 5
2024-01-17 19:46:09,971:INFO:_display_container: 2
2024-01-17 19:46:09,971:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8756, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-17 19:46:09,971:INFO:create_model() successfully completed......................................
2024-01-17 19:46:10,150:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:10,150:INFO:Creating metrics dataframe
2024-01-17 19:46:10,175:INFO:Initializing Ridge Classifier
2024-01-17 19:46:10,175:INFO:Total runtime is 1.29873739083608 minutes
2024-01-17 19:46:10,187:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:10,187:INFO:Initializing create_model()
2024-01-17 19:46:10,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:10,187:INFO:Checking exceptions
2024-01-17 19:46:10,187:INFO:Importing libraries
2024-01-17 19:46:10,187:INFO:Copying training dataset
2024-01-17 19:46:10,196:INFO:Defining folds
2024-01-17 19:46:10,196:INFO:Declaring metric variables
2024-01-17 19:46:10,203:INFO:Importing untrained model
2024-01-17 19:46:10,212:INFO:Ridge Classifier Imported successfully
2024-01-17 19:46:10,224:INFO:Starting cross validation
2024-01-17 19:46:10,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:14,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:46:14,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:46:14,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,654:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,654:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,654:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,671:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,671:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,671:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:46:14,671:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,686:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,686:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:46:14,701:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,701:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,701:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:14,717:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:15,284:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:46:18,006:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,008:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,008:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,011:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,014:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,014:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,018:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,020:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,047:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,067:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,082:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,438:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:46:18,438:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,454:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,454:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:46:18,469:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,469:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,469:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,469:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:18,485:INFO:Calculating mean and std
2024-01-17 19:46:18,485:INFO:Creating metrics dataframe
2024-01-17 19:46:18,501:INFO:Uploading results into container
2024-01-17 19:46:18,501:INFO:Uploading model into container now
2024-01-17 19:46:18,501:INFO:_master_model_container: 6
2024-01-17 19:46:18,501:INFO:_display_container: 2
2024-01-17 19:46:18,501:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8756, solver='auto',
                tol=0.0001)
2024-01-17 19:46:18,501:INFO:create_model() successfully completed......................................
2024-01-17 19:46:18,708:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:18,708:INFO:Creating metrics dataframe
2024-01-17 19:46:18,742:INFO:Initializing Random Forest Classifier
2024-01-17 19:46:18,742:INFO:Total runtime is 1.4415181954701741 minutes
2024-01-17 19:46:18,742:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:18,742:INFO:Initializing create_model()
2024-01-17 19:46:18,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:18,742:INFO:Checking exceptions
2024-01-17 19:46:18,742:INFO:Importing libraries
2024-01-17 19:46:18,742:INFO:Copying training dataset
2024-01-17 19:46:18,759:INFO:Defining folds
2024-01-17 19:46:18,759:INFO:Declaring metric variables
2024-01-17 19:46:18,772:INFO:Importing untrained model
2024-01-17 19:46:18,788:INFO:Random Forest Classifier Imported successfully
2024-01-17 19:46:18,803:INFO:Starting cross validation
2024-01-17 19:46:18,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:19,650:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,656:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,656:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,656:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,656:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,672:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,672:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,672:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,687:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,754:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,770:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:19,770:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:21,451:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:21,580:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:21,580:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:21,592:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:21,592:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:21,592:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:21,592:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:21,592:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:22,542:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:22,546:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:22,548:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:22,551:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:22,580:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:22,587:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:22,590:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:22,603:INFO:Calculating mean and std
2024-01-17 19:46:22,603:INFO:Creating metrics dataframe
2024-01-17 19:46:22,603:INFO:Uploading results into container
2024-01-17 19:46:22,603:INFO:Uploading model into container now
2024-01-17 19:46:22,603:INFO:_master_model_container: 7
2024-01-17 19:46:22,603:INFO:_display_container: 2
2024-01-17 19:46:22,603:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8756, verbose=0, warm_start=False)
2024-01-17 19:46:22,603:INFO:create_model() successfully completed......................................
2024-01-17 19:46:22,758:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:22,758:INFO:Creating metrics dataframe
2024-01-17 19:46:22,790:INFO:Initializing Quadratic Discriminant Analysis
2024-01-17 19:46:22,796:INFO:Total runtime is 1.5089951713879903 minutes
2024-01-17 19:46:22,801:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:22,804:INFO:Initializing create_model()
2024-01-17 19:46:22,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:22,804:INFO:Checking exceptions
2024-01-17 19:46:22,804:INFO:Importing libraries
2024-01-17 19:46:22,804:INFO:Copying training dataset
2024-01-17 19:46:22,814:INFO:Defining folds
2024-01-17 19:46:22,818:INFO:Declaring metric variables
2024-01-17 19:46:22,827:INFO:Importing untrained model
2024-01-17 19:46:22,837:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-17 19:46:22,848:INFO:Starting cross validation
2024-01-17 19:46:22,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:24,472:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:24,472:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:24,473:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:24,476:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:24,666:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,682:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,684:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,684:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:24,684:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,684:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,684:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,698:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,698:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:24,701:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:24,701:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,708:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,710:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,738:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:24,738:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:24,745:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,095:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:25,205:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:25,221:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:25,252:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:25,362:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,378:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,378:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:25,391:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,426:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,440:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,440:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,456:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:25,456:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,456:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,456:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:25,474:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,488:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,504:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,504:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:25,504:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,763:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:25,821:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:46:25,945:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,961:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,967:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:25,970:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,980:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,989:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:25,995:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:25,995:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:26,009:INFO:Calculating mean and std
2024-01-17 19:46:26,009:INFO:Creating metrics dataframe
2024-01-17 19:46:26,031:INFO:Uploading results into container
2024-01-17 19:46:26,031:INFO:Uploading model into container now
2024-01-17 19:46:26,031:INFO:_master_model_container: 8
2024-01-17 19:46:26,031:INFO:_display_container: 2
2024-01-17 19:46:26,031:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-17 19:46:26,031:INFO:create_model() successfully completed......................................
2024-01-17 19:46:26,222:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:26,222:INFO:Creating metrics dataframe
2024-01-17 19:46:26,265:INFO:Initializing Ada Boost Classifier
2024-01-17 19:46:26,265:INFO:Total runtime is 1.5669086217880248 minutes
2024-01-17 19:46:26,276:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:26,276:INFO:Initializing create_model()
2024-01-17 19:46:26,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:26,276:INFO:Checking exceptions
2024-01-17 19:46:26,276:INFO:Importing libraries
2024-01-17 19:46:26,276:INFO:Copying training dataset
2024-01-17 19:46:26,290:INFO:Defining folds
2024-01-17 19:46:26,290:INFO:Declaring metric variables
2024-01-17 19:46:26,298:INFO:Importing untrained model
2024-01-17 19:46:26,314:INFO:Ada Boost Classifier Imported successfully
2024-01-17 19:46:26,329:INFO:Starting cross validation
2024-01-17 19:46:26,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:28,597:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,597:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,597:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,597:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:28,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:28,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,628:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:28,630:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,630:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:28,630:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:28,630:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,752:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,759:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,759:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:29,775:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,775:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,790:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,790:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:29,806:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,806:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,806:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,806:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,806:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,806:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:29,822:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:29,822:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:29,822:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:30,637:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:30,778:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:30,778:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:30,778:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:30,778:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:30,778:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:30,793:INFO:Calculating mean and std
2024-01-17 19:46:30,793:INFO:Creating metrics dataframe
2024-01-17 19:46:30,810:INFO:Uploading results into container
2024-01-17 19:46:30,810:INFO:Uploading model into container now
2024-01-17 19:46:30,810:INFO:_master_model_container: 9
2024-01-17 19:46:30,810:INFO:_display_container: 2
2024-01-17 19:46:30,810:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8756)
2024-01-17 19:46:30,810:INFO:create_model() successfully completed......................................
2024-01-17 19:46:31,013:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:31,013:INFO:Creating metrics dataframe
2024-01-17 19:46:31,048:INFO:Initializing Gradient Boosting Classifier
2024-01-17 19:46:31,048:INFO:Total runtime is 1.6466248035430908 minutes
2024-01-17 19:46:31,048:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:31,048:INFO:Initializing create_model()
2024-01-17 19:46:31,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:31,048:INFO:Checking exceptions
2024-01-17 19:46:31,048:INFO:Importing libraries
2024-01-17 19:46:31,048:INFO:Copying training dataset
2024-01-17 19:46:31,064:INFO:Defining folds
2024-01-17 19:46:31,070:INFO:Declaring metric variables
2024-01-17 19:46:31,079:INFO:Importing untrained model
2024-01-17 19:46:31,087:INFO:Gradient Boosting Classifier Imported successfully
2024-01-17 19:46:31,102:INFO:Starting cross validation
2024-01-17 19:46:31,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:33,424:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,427:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,427:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,427:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,436:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,436:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,440:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,440:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,443:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:33,443:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,443:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,451:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:33,451:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,607:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,622:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,627:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,668:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,682:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,693:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,729:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,737:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,746:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,759:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,779:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:35,787:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:36,855:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:36,855:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:36,870:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:36,870:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:36,870:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:36,886:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:36,886:INFO:Calculating mean and std
2024-01-17 19:46:36,886:INFO:Creating metrics dataframe
2024-01-17 19:46:36,904:INFO:Uploading results into container
2024-01-17 19:46:36,909:INFO:Uploading model into container now
2024-01-17 19:46:36,909:INFO:_master_model_container: 10
2024-01-17 19:46:36,909:INFO:_display_container: 2
2024-01-17 19:46:36,911:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8756, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 19:46:36,912:INFO:create_model() successfully completed......................................
2024-01-17 19:46:37,073:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:37,073:INFO:Creating metrics dataframe
2024-01-17 19:46:37,108:INFO:Initializing Linear Discriminant Analysis
2024-01-17 19:46:37,108:INFO:Total runtime is 1.7476194063822428 minutes
2024-01-17 19:46:37,114:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:37,121:INFO:Initializing create_model()
2024-01-17 19:46:37,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:37,121:INFO:Checking exceptions
2024-01-17 19:46:37,122:INFO:Importing libraries
2024-01-17 19:46:37,122:INFO:Copying training dataset
2024-01-17 19:46:37,129:INFO:Defining folds
2024-01-17 19:46:37,129:INFO:Declaring metric variables
2024-01-17 19:46:37,146:INFO:Importing untrained model
2024-01-17 19:46:37,154:INFO:Linear Discriminant Analysis Imported successfully
2024-01-17 19:46:37,173:INFO:Starting cross validation
2024-01-17 19:46:37,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:38,044:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,044:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,059:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,059:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,059:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,059:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,059:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:38,059:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:38,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:38,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:38,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,688:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,688:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,688:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,703:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,704:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,704:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,704:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:38,704:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:38,704:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:38,704:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,704:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,704:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,704:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:38,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:38,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:39,208:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:39,209:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:39,224:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:39,230:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:39,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:39,240:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:39,240:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:39,255:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:39,271:INFO:Calculating mean and std
2024-01-17 19:46:39,271:INFO:Creating metrics dataframe
2024-01-17 19:46:39,287:INFO:Uploading results into container
2024-01-17 19:46:39,287:INFO:Uploading model into container now
2024-01-17 19:46:39,287:INFO:_master_model_container: 11
2024-01-17 19:46:39,287:INFO:_display_container: 2
2024-01-17 19:46:39,287:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-17 19:46:39,302:INFO:create_model() successfully completed......................................
2024-01-17 19:46:39,501:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:39,501:INFO:Creating metrics dataframe
2024-01-17 19:46:39,548:INFO:Initializing Extra Trees Classifier
2024-01-17 19:46:39,548:INFO:Total runtime is 1.7882969856262207 minutes
2024-01-17 19:46:39,548:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:39,548:INFO:Initializing create_model()
2024-01-17 19:46:39,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:39,548:INFO:Checking exceptions
2024-01-17 19:46:39,548:INFO:Importing libraries
2024-01-17 19:46:39,548:INFO:Copying training dataset
2024-01-17 19:46:39,565:INFO:Defining folds
2024-01-17 19:46:39,565:INFO:Declaring metric variables
2024-01-17 19:46:39,588:INFO:Importing untrained model
2024-01-17 19:46:39,597:INFO:Extra Trees Classifier Imported successfully
2024-01-17 19:46:39,625:INFO:Starting cross validation
2024-01-17 19:46:39,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:40,956:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:40,956:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:40,963:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:40,967:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:40,971:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:40,971:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:40,979:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:40,979:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:41,004:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:41,010:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:41,026:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:41,042:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,302:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,310:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,326:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,342:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,351:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,385:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,392:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,402:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,417:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,423:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,425:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:42,442:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:43,386:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:43,395:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:43,411:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:43,444:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:43,456:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:43,460:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:43,473:INFO:Calculating mean and std
2024-01-17 19:46:43,479:INFO:Creating metrics dataframe
2024-01-17 19:46:43,490:INFO:Uploading results into container
2024-01-17 19:46:43,490:INFO:Uploading model into container now
2024-01-17 19:46:43,494:INFO:_master_model_container: 12
2024-01-17 19:46:43,494:INFO:_display_container: 2
2024-01-17 19:46:43,494:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8756, verbose=0, warm_start=False)
2024-01-17 19:46:43,494:INFO:create_model() successfully completed......................................
2024-01-17 19:46:43,708:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:43,708:INFO:Creating metrics dataframe
2024-01-17 19:46:43,765:INFO:Initializing Light Gradient Boosting Machine
2024-01-17 19:46:43,765:INFO:Total runtime is 1.8585793137550355 minutes
2024-01-17 19:46:43,765:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:43,776:INFO:Initializing create_model()
2024-01-17 19:46:43,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:43,776:INFO:Checking exceptions
2024-01-17 19:46:43,776:INFO:Importing libraries
2024-01-17 19:46:43,779:INFO:Copying training dataset
2024-01-17 19:46:43,795:INFO:Defining folds
2024-01-17 19:46:43,795:INFO:Declaring metric variables
2024-01-17 19:46:43,795:INFO:Importing untrained model
2024-01-17 19:46:43,811:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-17 19:46:43,843:INFO:Starting cross validation
2024-01-17 19:46:43,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:46:45,881:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:45,891:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:45,903:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:45,909:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:45,909:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:45,917:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:45,924:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:45,932:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:45,932:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:45,944:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:45,946:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:45,960:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:46,103:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:46,114:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:46,134:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:46,140:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,140:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,151:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,157:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:47,164:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,172:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,184:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,198:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:47,205:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,243:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,251:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,257:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:47,260:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,443:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,450:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:47,455:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:47,488:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:48,028:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:48,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:48,742:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:48,747:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:48,915:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:48,919:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:48,922:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:46:48,927:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:46:48,942:INFO:Calculating mean and std
2024-01-17 19:46:48,945:INFO:Creating metrics dataframe
2024-01-17 19:46:48,957:INFO:Uploading results into container
2024-01-17 19:46:48,959:INFO:Uploading model into container now
2024-01-17 19:46:48,960:INFO:_master_model_container: 13
2024-01-17 19:46:48,961:INFO:_display_container: 2
2024-01-17 19:46:48,963:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8756, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-17 19:46:48,963:INFO:create_model() successfully completed......................................
2024-01-17 19:46:49,138:INFO:SubProcess create_model() end ==================================
2024-01-17 19:46:49,138:INFO:Creating metrics dataframe
2024-01-17 19:46:49,169:INFO:Initializing CatBoost Classifier
2024-01-17 19:46:49,169:INFO:Total runtime is 1.948648492495219 minutes
2024-01-17 19:46:49,185:INFO:SubProcess create_model() called ==================================
2024-01-17 19:46:49,185:INFO:Initializing create_model()
2024-01-17 19:46:49,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:46:49,185:INFO:Checking exceptions
2024-01-17 19:46:49,185:INFO:Importing libraries
2024-01-17 19:46:49,185:INFO:Copying training dataset
2024-01-17 19:46:49,201:INFO:Defining folds
2024-01-17 19:46:49,201:INFO:Declaring metric variables
2024-01-17 19:46:49,216:INFO:Importing untrained model
2024-01-17 19:46:50,714:INFO:CatBoost Classifier Imported successfully
2024-01-17 19:46:50,736:INFO:Starting cross validation
2024-01-17 19:46:50,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:47:26,955:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:26,969:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:26,969:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:26,969:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:26,969:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:26,969:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:26,985:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:26,991:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:26,991:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:27,001:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:27,001:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:47:27,017:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,794:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,810:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,810:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,816:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:47:43,816:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,816:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,816:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,827:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:47:43,827:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,827:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,827:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:47:43,859:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\catboost\core.py", line 5100, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\catboost\core.py", line 2319, in _fit
    self._train(
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\catboost\core.py", line 1723, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 4645, in _catboost._CatBoost._train
  File "_catboost.pyx", line 4694, in _catboost._CatBoost._train
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-01-17 19:47:43,865:INFO:Calculating mean and std
2024-01-17 19:47:43,866:INFO:Creating metrics dataframe
2024-01-17 19:47:43,882:INFO:Uploading results into container
2024-01-17 19:47:43,884:INFO:Uploading model into container now
2024-01-17 19:47:43,884:INFO:_master_model_container: 14
2024-01-17 19:47:43,886:INFO:_display_container: 2
2024-01-17 19:47:43,886:INFO:<catboost.core.CatBoostClassifier object at 0x0000029A0D9D7ED0>
2024-01-17 19:47:43,886:INFO:create_model() successfully completed......................................
2024-01-17 19:47:44,127:WARNING:create_model() for <catboost.core.CatBoostClassifier object at 0x0000029A0D9D7ED0> raised an exception or returned all 0.0, trying without fit_kwargs:
2024-01-17 19:47:44,239:WARNING:Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-01-17 19:47:44,239:INFO:Initializing create_model()
2024-01-17 19:47:44,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:47:44,239:INFO:Checking exceptions
2024-01-17 19:47:44,239:INFO:Importing libraries
2024-01-17 19:47:44,239:INFO:Copying training dataset
2024-01-17 19:47:44,259:INFO:Defining folds
2024-01-17 19:47:44,259:INFO:Declaring metric variables
2024-01-17 19:47:44,277:INFO:Importing untrained model
2024-01-17 19:47:44,292:INFO:CatBoost Classifier Imported successfully
2024-01-17 19:47:44,308:INFO:Starting cross validation
2024-01-17 19:47:44,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:48:05,209:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,239:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,239:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,239:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,253:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,285:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,285:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:05,302:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,363:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,379:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:05,395:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,365:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,365:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,365:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,365:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:29,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,396:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,396:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,412:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,428:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,428:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,443:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:29,443:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:29,459:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:46,474:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:46,484:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:46,484:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:46,486:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:46,486:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:46,500:INFO:Calculating mean and std
2024-01-17 19:48:46,500:INFO:Creating metrics dataframe
2024-01-17 19:48:46,529:INFO:Uploading results into container
2024-01-17 19:48:46,530:INFO:Uploading model into container now
2024-01-17 19:48:46,530:INFO:_master_model_container: 15
2024-01-17 19:48:46,530:INFO:_display_container: 2
2024-01-17 19:48:46,530:INFO:<catboost.core.CatBoostClassifier object at 0x0000029A0D561A10>
2024-01-17 19:48:46,530:INFO:create_model() successfully completed......................................
2024-01-17 19:48:46,727:INFO:SubProcess create_model() end ==================================
2024-01-17 19:48:46,727:INFO:Creating metrics dataframe
2024-01-17 19:48:46,758:INFO:Initializing Dummy Classifier
2024-01-17 19:48:46,758:INFO:Total runtime is 3.908462206522624 minutes
2024-01-17 19:48:46,782:INFO:SubProcess create_model() called ==================================
2024-01-17 19:48:46,782:INFO:Initializing create_model()
2024-01-17 19:48:46,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A0B80D0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:48:46,782:INFO:Checking exceptions
2024-01-17 19:48:46,782:INFO:Importing libraries
2024-01-17 19:48:46,782:INFO:Copying training dataset
2024-01-17 19:48:46,790:INFO:Defining folds
2024-01-17 19:48:46,790:INFO:Declaring metric variables
2024-01-17 19:48:46,790:INFO:Importing untrained model
2024-01-17 19:48:46,808:INFO:Dummy Classifier Imported successfully
2024-01-17 19:48:46,824:INFO:Starting cross validation
2024-01-17 19:48:46,826:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:48:47,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,420:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,426:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:47,426:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,474:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,474:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,474:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:47,489:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,489:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,489:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,489:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:47,489:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,506:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:47,506:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:47,506:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,102:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,117:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,117:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:48,117:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,148:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,151:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,151:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,151:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:48,165:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,169:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,169:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:48,169:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,180:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,185:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,205:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:48,210:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,577:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,577:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,591:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:48,591:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:48:48,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:48:48,653:INFO:Calculating mean and std
2024-01-17 19:48:48,676:INFO:Creating metrics dataframe
2024-01-17 19:48:48,689:INFO:Uploading results into container
2024-01-17 19:48:48,694:INFO:Uploading model into container now
2024-01-17 19:48:48,695:INFO:_master_model_container: 16
2024-01-17 19:48:48,695:INFO:_display_container: 2
2024-01-17 19:48:48,696:INFO:DummyClassifier(constant=None, random_state=8756, strategy='prior')
2024-01-17 19:48:48,696:INFO:create_model() successfully completed......................................
2024-01-17 19:48:48,879:INFO:SubProcess create_model() end ==================================
2024-01-17 19:48:48,879:INFO:Creating metrics dataframe
2024-01-17 19:48:48,943:INFO:Initializing create_model()
2024-01-17 19:48:48,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:48:48,943:INFO:Checking exceptions
2024-01-17 19:48:48,947:INFO:Importing libraries
2024-01-17 19:48:48,947:INFO:Copying training dataset
2024-01-17 19:48:48,961:INFO:Defining folds
2024-01-17 19:48:48,961:INFO:Declaring metric variables
2024-01-17 19:48:48,961:INFO:Importing untrained model
2024-01-17 19:48:48,961:INFO:Declaring custom model
2024-01-17 19:48:48,968:INFO:Logistic Regression Imported successfully
2024-01-17 19:48:48,969:INFO:Cross validation set to False
2024-01-17 19:48:48,969:INFO:Fitting Model
2024-01-17 19:48:51,940:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:48:51,956:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 19:48:51,956:INFO:create_model() successfully completed......................................
2024-01-17 19:48:52,256:INFO:_master_model_container: 16
2024-01-17 19:48:52,256:INFO:_display_container: 2
2024-01-17 19:48:52,256:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 19:48:52,259:INFO:compare_models() successfully completed......................................
2024-01-17 19:49:28,872:INFO:Initializing finalize_model()
2024-01-17 19:49:28,872:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-17 19:49:28,872:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 19:49:28,886:INFO:Initializing create_model()
2024-01-17 19:49:28,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:49:28,887:INFO:Checking exceptions
2024-01-17 19:49:28,891:INFO:Importing libraries
2024-01-17 19:49:28,891:INFO:Copying training dataset
2024-01-17 19:49:28,891:INFO:Defining folds
2024-01-17 19:49:28,891:INFO:Declaring metric variables
2024-01-17 19:49:28,891:INFO:Importing untrained model
2024-01-17 19:49:28,891:INFO:Declaring custom model
2024-01-17 19:49:28,895:INFO:Logistic Regression Imported successfully
2024-01-17 19:49:28,905:INFO:Cross validation set to False
2024-01-17 19:49:28,905:INFO:Fitting Model
2024-01-17 19:49:29,991:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:49:30,070:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Age', 'SibSp',
                                             'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=8756,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-01-17 19:49:30,070:INFO:create_model() successfully completed......................................
2024-01-17 19:49:30,252:INFO:_master_model_container: 16
2024-01-17 19:49:30,252:INFO:_display_container: 2
2024-01-17 19:49:30,304:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Age', 'SibSp',
                                             'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=8756,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-01-17 19:49:30,304:INFO:finalize_model() successfully completed......................................
2024-01-17 19:50:15,189:INFO:Initializing evaluate_model()
2024-01-17 19:50:15,189:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-17 19:50:15,803:INFO:Initializing plot_model()
2024-01-17 19:50:15,803:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 19:50:15,803:INFO:Checking exceptions
2024-01-17 19:50:15,815:INFO:Preloading libraries
2024-01-17 19:50:15,816:INFO:Copying training dataset
2024-01-17 19:50:15,816:INFO:Plot type: pipeline
2024-01-17 19:50:19,476:INFO:Visual Rendered Successfully
2024-01-17 19:50:19,672:INFO:plot_model() successfully completed......................................
2024-01-17 19:50:28,260:INFO:Initializing plot_model()
2024-01-17 19:50:28,260:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 19:50:28,260:INFO:Checking exceptions
2024-01-17 19:50:28,265:INFO:Preloading libraries
2024-01-17 19:50:28,267:INFO:Copying training dataset
2024-01-17 19:50:28,267:INFO:Plot type: feature_all
2024-01-17 19:50:29,937:INFO:Visual Rendered Successfully
2024-01-17 19:50:30,146:INFO:plot_model() successfully completed......................................
2024-01-17 19:51:40,462:INFO:Initializing predict_model()
2024-01-17 19:51:40,462:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029A0D65FB00>)
2024-01-17 19:51:40,462:INFO:Checking exceptions
2024-01-17 19:51:40,462:INFO:Preloading libraries
2024-01-17 19:51:41,567:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:51:41,567:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:51:41,567:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:52:06,277:INFO:Initializing predict_model()
2024-01-17 19:52:06,278:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029A0D65FBA0>)
2024-01-17 19:52:06,278:INFO:Checking exceptions
2024-01-17 19:52:06,278:INFO:Preloading libraries
2024-01-17 19:52:06,278:INFO:Set up data.
2024-01-17 19:52:06,300:INFO:Set up index.
2024-01-17 19:52:07,160:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:52:07,166:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:52:07,174:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:52:49,683:INFO:Initializing predict_model()
2024-01-17 19:52:49,683:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0C882BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8756, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029A0D65E660>)
2024-01-17 19:52:49,683:INFO:Checking exceptions
2024-01-17 19:52:49,683:INFO:Preloading libraries
2024-01-17 19:52:49,683:INFO:Set up data.
2024-01-17 19:52:49,700:INFO:Set up index.
2024-01-17 19:52:49,817:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:52:49,819:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:52:49,835:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-01-17 19:54:03,392:INFO:PyCaret ClassificationExperiment
2024-01-17 19:54:03,394:INFO:Logging name: clf-default-name
2024-01-17 19:54:03,394:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-17 19:54:03,394:INFO:version 3.2.0
2024-01-17 19:54:03,394:INFO:Initializing setup()
2024-01-17 19:54:03,394:INFO:self.USI: 3875
2024-01-17 19:54:03,394:INFO:self._variable_keys: {'idx', 'exp_name_log', 'X_train', 'gpu_param', 'y_train', 'fold_shuffle_param', 'USI', 'html_param', 'pipeline', 'target_param', 'seed', 'X', 'data', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', 'n_jobs_param', '_available_plots', 'X_test', 'fold_groups_param', 'fix_imbalance', 'y_test', 'log_plots_param', 'logging_param', '_ml_usecase', 'y', 'memory', 'is_multiclass'}
2024-01-17 19:54:03,394:INFO:Checking environment
2024-01-17 19:54:03,394:INFO:python_version: 3.11.5
2024-01-17 19:54:03,394:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 19:54:03,394:INFO:machine: AMD64
2024-01-17 19:54:03,394:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 19:54:03,397:INFO:Memory: svmem(total=8361132032, available=1431531520, percent=82.9, used=6929600512, free=1431531520)
2024-01-17 19:54:03,397:INFO:Physical Core: 2
2024-01-17 19:54:03,397:INFO:Logical Core: 4
2024-01-17 19:54:03,397:INFO:Checking libraries
2024-01-17 19:54:03,397:INFO:System:
2024-01-17 19:54:03,397:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 19:54:03,397:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 19:54:03,397:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 19:54:03,397:INFO:PyCaret required dependencies:
2024-01-17 19:54:03,397:INFO:                 pip: 23.2.1
2024-01-17 19:54:03,397:INFO:          setuptools: 68.0.0
2024-01-17 19:54:03,397:INFO:             pycaret: 3.2.0
2024-01-17 19:54:03,397:INFO:             IPython: 8.15.0
2024-01-17 19:54:03,397:INFO:          ipywidgets: 8.0.4
2024-01-17 19:54:03,397:INFO:                tqdm: 4.65.0
2024-01-17 19:54:03,397:INFO:               numpy: 1.24.3
2024-01-17 19:54:03,397:INFO:              pandas: 1.5.3
2024-01-17 19:54:03,397:INFO:              jinja2: 3.1.2
2024-01-17 19:54:03,397:INFO:               scipy: 1.10.1
2024-01-17 19:54:03,397:INFO:              joblib: 1.2.0
2024-01-17 19:54:03,397:INFO:             sklearn: 1.2.2
2024-01-17 19:54:03,397:INFO:                pyod: 1.1.2
2024-01-17 19:54:03,397:INFO:            imblearn: 0.10.1
2024-01-17 19:54:03,397:INFO:   category_encoders: 2.6.3
2024-01-17 19:54:03,397:INFO:            lightgbm: 4.2.0
2024-01-17 19:54:03,397:INFO:               numba: 0.57.1
2024-01-17 19:54:03,397:INFO:            requests: 2.31.0
2024-01-17 19:54:03,397:INFO:          matplotlib: 3.6.0
2024-01-17 19:54:03,397:INFO:          scikitplot: 0.3.7
2024-01-17 19:54:03,397:INFO:         yellowbrick: 1.5
2024-01-17 19:54:03,397:INFO:              plotly: 5.9.0
2024-01-17 19:54:03,397:INFO:    plotly-resampler: Not installed
2024-01-17 19:54:03,397:INFO:             kaleido: 0.2.1
2024-01-17 19:54:03,397:INFO:           schemdraw: 0.15
2024-01-17 19:54:03,397:INFO:         statsmodels: 0.14.0
2024-01-17 19:54:03,397:INFO:              sktime: 0.21.1
2024-01-17 19:54:03,397:INFO:               tbats: 1.1.3
2024-01-17 19:54:03,402:INFO:            pmdarima: 2.0.4
2024-01-17 19:54:03,402:INFO:              psutil: 5.9.0
2024-01-17 19:54:03,402:INFO:          markupsafe: 2.1.1
2024-01-17 19:54:03,402:INFO:             pickle5: Not installed
2024-01-17 19:54:03,402:INFO:         cloudpickle: 2.2.1
2024-01-17 19:54:03,403:INFO:         deprecation: 2.1.0
2024-01-17 19:54:03,403:INFO:              xxhash: 2.0.2
2024-01-17 19:54:03,403:INFO:           wurlitzer: Not installed
2024-01-17 19:54:03,403:INFO:PyCaret optional dependencies:
2024-01-17 19:54:03,403:INFO:                shap: Not installed
2024-01-17 19:54:03,403:INFO:           interpret: Not installed
2024-01-17 19:54:03,403:INFO:                umap: Not installed
2024-01-17 19:54:03,403:INFO:     ydata_profiling: Not installed
2024-01-17 19:54:03,403:INFO:  explainerdashboard: Not installed
2024-01-17 19:54:03,403:INFO:             autoviz: Not installed
2024-01-17 19:54:03,403:INFO:           fairlearn: Not installed
2024-01-17 19:54:03,403:INFO:          deepchecks: Not installed
2024-01-17 19:54:03,403:INFO:             xgboost: Not installed
2024-01-17 19:54:03,403:INFO:            catboost: 1.2.2
2024-01-17 19:54:03,403:INFO:              kmodes: Not installed
2024-01-17 19:54:03,403:INFO:             mlxtend: Not installed
2024-01-17 19:54:03,403:INFO:       statsforecast: Not installed
2024-01-17 19:54:03,403:INFO:        tune_sklearn: Not installed
2024-01-17 19:54:03,403:INFO:                 ray: Not installed
2024-01-17 19:54:03,403:INFO:            hyperopt: Not installed
2024-01-17 19:54:03,403:INFO:              optuna: Not installed
2024-01-17 19:54:03,403:INFO:               skopt: Not installed
2024-01-17 19:54:03,403:INFO:              mlflow: Not installed
2024-01-17 19:54:03,403:INFO:              gradio: Not installed
2024-01-17 19:54:03,405:INFO:             fastapi: Not installed
2024-01-17 19:54:03,405:INFO:             uvicorn: Not installed
2024-01-17 19:54:03,405:INFO:              m2cgen: Not installed
2024-01-17 19:54:03,405:INFO:           evidently: Not installed
2024-01-17 19:54:03,405:INFO:               fugue: Not installed
2024-01-17 19:54:03,405:INFO:           streamlit: Not installed
2024-01-17 19:54:03,405:INFO:             prophet: Not installed
2024-01-17 19:54:03,405:INFO:None
2024-01-17 19:54:03,406:INFO:Set up data.
2024-01-17 19:55:15,979:INFO:PyCaret ClassificationExperiment
2024-01-17 19:55:15,979:INFO:Logging name: clf-default-name
2024-01-17 19:55:15,979:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-17 19:55:15,979:INFO:version 3.2.0
2024-01-17 19:55:15,979:INFO:Initializing setup()
2024-01-17 19:55:15,979:INFO:self.USI: 5388
2024-01-17 19:55:15,979:INFO:self._variable_keys: {'idx', 'exp_name_log', 'X_train', 'gpu_param', 'y_train', 'fold_shuffle_param', 'USI', 'html_param', 'pipeline', 'target_param', 'seed', 'X', 'data', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', 'n_jobs_param', '_available_plots', 'X_test', 'fold_groups_param', 'fix_imbalance', 'y_test', 'log_plots_param', 'logging_param', '_ml_usecase', 'y', 'memory', 'is_multiclass'}
2024-01-17 19:55:15,979:INFO:Checking environment
2024-01-17 19:55:15,979:INFO:python_version: 3.11.5
2024-01-17 19:55:15,979:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 19:55:15,979:INFO:machine: AMD64
2024-01-17 19:55:15,979:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 19:55:15,979:INFO:Memory: svmem(total=8361132032, available=1469796352, percent=82.4, used=6891335680, free=1469796352)
2024-01-17 19:55:15,979:INFO:Physical Core: 2
2024-01-17 19:55:15,979:INFO:Logical Core: 4
2024-01-17 19:55:15,979:INFO:Checking libraries
2024-01-17 19:55:15,979:INFO:System:
2024-01-17 19:55:15,979:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 19:55:15,979:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 19:55:15,979:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 19:55:15,979:INFO:PyCaret required dependencies:
2024-01-17 19:55:15,979:INFO:                 pip: 23.2.1
2024-01-17 19:55:15,979:INFO:          setuptools: 68.0.0
2024-01-17 19:55:15,979:INFO:             pycaret: 3.2.0
2024-01-17 19:55:15,979:INFO:             IPython: 8.15.0
2024-01-17 19:55:15,979:INFO:          ipywidgets: 8.0.4
2024-01-17 19:55:15,979:INFO:                tqdm: 4.65.0
2024-01-17 19:55:15,979:INFO:               numpy: 1.24.3
2024-01-17 19:55:15,979:INFO:              pandas: 1.5.3
2024-01-17 19:55:15,979:INFO:              jinja2: 3.1.2
2024-01-17 19:55:15,979:INFO:               scipy: 1.10.1
2024-01-17 19:55:15,979:INFO:              joblib: 1.2.0
2024-01-17 19:55:15,979:INFO:             sklearn: 1.2.2
2024-01-17 19:55:15,979:INFO:                pyod: 1.1.2
2024-01-17 19:55:15,979:INFO:            imblearn: 0.10.1
2024-01-17 19:55:15,979:INFO:   category_encoders: 2.6.3
2024-01-17 19:55:15,979:INFO:            lightgbm: 4.2.0
2024-01-17 19:55:15,979:INFO:               numba: 0.57.1
2024-01-17 19:55:15,979:INFO:            requests: 2.31.0
2024-01-17 19:55:15,979:INFO:          matplotlib: 3.6.0
2024-01-17 19:55:15,979:INFO:          scikitplot: 0.3.7
2024-01-17 19:55:15,979:INFO:         yellowbrick: 1.5
2024-01-17 19:55:15,979:INFO:              plotly: 5.9.0
2024-01-17 19:55:15,979:INFO:    plotly-resampler: Not installed
2024-01-17 19:55:15,979:INFO:             kaleido: 0.2.1
2024-01-17 19:55:15,979:INFO:           schemdraw: 0.15
2024-01-17 19:55:15,979:INFO:         statsmodels: 0.14.0
2024-01-17 19:55:15,979:INFO:              sktime: 0.21.1
2024-01-17 19:55:15,979:INFO:               tbats: 1.1.3
2024-01-17 19:55:15,979:INFO:            pmdarima: 2.0.4
2024-01-17 19:55:15,979:INFO:              psutil: 5.9.0
2024-01-17 19:55:15,979:INFO:          markupsafe: 2.1.1
2024-01-17 19:55:15,979:INFO:             pickle5: Not installed
2024-01-17 19:55:15,979:INFO:         cloudpickle: 2.2.1
2024-01-17 19:55:15,979:INFO:         deprecation: 2.1.0
2024-01-17 19:55:15,979:INFO:              xxhash: 2.0.2
2024-01-17 19:55:15,979:INFO:           wurlitzer: Not installed
2024-01-17 19:55:15,979:INFO:PyCaret optional dependencies:
2024-01-17 19:55:15,979:INFO:                shap: Not installed
2024-01-17 19:55:15,979:INFO:           interpret: Not installed
2024-01-17 19:55:15,979:INFO:                umap: Not installed
2024-01-17 19:55:15,979:INFO:     ydata_profiling: Not installed
2024-01-17 19:55:15,979:INFO:  explainerdashboard: Not installed
2024-01-17 19:55:15,994:INFO:             autoviz: Not installed
2024-01-17 19:55:15,994:INFO:           fairlearn: Not installed
2024-01-17 19:55:15,994:INFO:          deepchecks: Not installed
2024-01-17 19:55:15,994:INFO:             xgboost: Not installed
2024-01-17 19:55:15,994:INFO:            catboost: 1.2.2
2024-01-17 19:55:15,994:INFO:              kmodes: Not installed
2024-01-17 19:55:15,994:INFO:             mlxtend: Not installed
2024-01-17 19:55:15,994:INFO:       statsforecast: Not installed
2024-01-17 19:55:15,994:INFO:        tune_sklearn: Not installed
2024-01-17 19:55:15,994:INFO:                 ray: Not installed
2024-01-17 19:55:15,994:INFO:            hyperopt: Not installed
2024-01-17 19:55:15,994:INFO:              optuna: Not installed
2024-01-17 19:55:15,994:INFO:               skopt: Not installed
2024-01-17 19:55:15,994:INFO:              mlflow: Not installed
2024-01-17 19:55:15,994:INFO:              gradio: Not installed
2024-01-17 19:55:15,994:INFO:             fastapi: Not installed
2024-01-17 19:55:15,994:INFO:             uvicorn: Not installed
2024-01-17 19:55:15,994:INFO:              m2cgen: Not installed
2024-01-17 19:55:15,994:INFO:           evidently: Not installed
2024-01-17 19:55:15,994:INFO:               fugue: Not installed
2024-01-17 19:55:15,994:INFO:           streamlit: Not installed
2024-01-17 19:55:15,994:INFO:             prophet: Not installed
2024-01-17 19:55:15,994:INFO:None
2024-01-17 19:55:15,994:INFO:Set up data.
2024-01-17 19:55:59,416:INFO:PyCaret ClassificationExperiment
2024-01-17 19:55:59,416:INFO:Logging name: clf-default-name
2024-01-17 19:55:59,416:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-17 19:55:59,416:INFO:version 3.2.0
2024-01-17 19:55:59,417:INFO:Initializing setup()
2024-01-17 19:55:59,417:INFO:self.USI: 2214
2024-01-17 19:55:59,417:INFO:self._variable_keys: {'idx', 'exp_name_log', 'X_train', 'gpu_param', 'y_train', 'fold_shuffle_param', 'USI', 'html_param', 'pipeline', 'target_param', 'seed', 'X', 'data', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', 'n_jobs_param', '_available_plots', 'X_test', 'fold_groups_param', 'fix_imbalance', 'y_test', 'log_plots_param', 'logging_param', '_ml_usecase', 'y', 'memory', 'is_multiclass'}
2024-01-17 19:55:59,417:INFO:Checking environment
2024-01-17 19:55:59,417:INFO:python_version: 3.11.5
2024-01-17 19:55:59,417:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 19:55:59,417:INFO:machine: AMD64
2024-01-17 19:55:59,418:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 19:55:59,418:INFO:Memory: svmem(total=8361132032, available=1441329152, percent=82.8, used=6919802880, free=1441329152)
2024-01-17 19:55:59,418:INFO:Physical Core: 2
2024-01-17 19:55:59,418:INFO:Logical Core: 4
2024-01-17 19:55:59,418:INFO:Checking libraries
2024-01-17 19:55:59,418:INFO:System:
2024-01-17 19:55:59,418:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 19:55:59,418:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 19:55:59,418:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 19:55:59,418:INFO:PyCaret required dependencies:
2024-01-17 19:55:59,418:INFO:                 pip: 23.2.1
2024-01-17 19:55:59,418:INFO:          setuptools: 68.0.0
2024-01-17 19:55:59,418:INFO:             pycaret: 3.2.0
2024-01-17 19:55:59,420:INFO:             IPython: 8.15.0
2024-01-17 19:55:59,420:INFO:          ipywidgets: 8.0.4
2024-01-17 19:55:59,420:INFO:                tqdm: 4.65.0
2024-01-17 19:55:59,420:INFO:               numpy: 1.24.3
2024-01-17 19:55:59,420:INFO:              pandas: 1.5.3
2024-01-17 19:55:59,420:INFO:              jinja2: 3.1.2
2024-01-17 19:55:59,420:INFO:               scipy: 1.10.1
2024-01-17 19:55:59,420:INFO:              joblib: 1.2.0
2024-01-17 19:55:59,420:INFO:             sklearn: 1.2.2
2024-01-17 19:55:59,420:INFO:                pyod: 1.1.2
2024-01-17 19:55:59,420:INFO:            imblearn: 0.10.1
2024-01-17 19:55:59,421:INFO:   category_encoders: 2.6.3
2024-01-17 19:55:59,421:INFO:            lightgbm: 4.2.0
2024-01-17 19:55:59,421:INFO:               numba: 0.57.1
2024-01-17 19:55:59,421:INFO:            requests: 2.31.0
2024-01-17 19:55:59,421:INFO:          matplotlib: 3.6.0
2024-01-17 19:55:59,421:INFO:          scikitplot: 0.3.7
2024-01-17 19:55:59,421:INFO:         yellowbrick: 1.5
2024-01-17 19:55:59,421:INFO:              plotly: 5.9.0
2024-01-17 19:55:59,421:INFO:    plotly-resampler: Not installed
2024-01-17 19:55:59,421:INFO:             kaleido: 0.2.1
2024-01-17 19:55:59,421:INFO:           schemdraw: 0.15
2024-01-17 19:55:59,421:INFO:         statsmodels: 0.14.0
2024-01-17 19:55:59,421:INFO:              sktime: 0.21.1
2024-01-17 19:55:59,421:INFO:               tbats: 1.1.3
2024-01-17 19:55:59,421:INFO:            pmdarima: 2.0.4
2024-01-17 19:55:59,421:INFO:              psutil: 5.9.0
2024-01-17 19:55:59,421:INFO:          markupsafe: 2.1.1
2024-01-17 19:55:59,421:INFO:             pickle5: Not installed
2024-01-17 19:55:59,421:INFO:         cloudpickle: 2.2.1
2024-01-17 19:55:59,421:INFO:         deprecation: 2.1.0
2024-01-17 19:55:59,421:INFO:              xxhash: 2.0.2
2024-01-17 19:55:59,421:INFO:           wurlitzer: Not installed
2024-01-17 19:55:59,421:INFO:PyCaret optional dependencies:
2024-01-17 19:55:59,421:INFO:                shap: Not installed
2024-01-17 19:55:59,421:INFO:           interpret: Not installed
2024-01-17 19:55:59,421:INFO:                umap: Not installed
2024-01-17 19:55:59,421:INFO:     ydata_profiling: Not installed
2024-01-17 19:55:59,421:INFO:  explainerdashboard: Not installed
2024-01-17 19:55:59,421:INFO:             autoviz: Not installed
2024-01-17 19:55:59,421:INFO:           fairlearn: Not installed
2024-01-17 19:55:59,421:INFO:          deepchecks: Not installed
2024-01-17 19:55:59,421:INFO:             xgboost: Not installed
2024-01-17 19:55:59,421:INFO:            catboost: 1.2.2
2024-01-17 19:55:59,421:INFO:              kmodes: Not installed
2024-01-17 19:55:59,421:INFO:             mlxtend: Not installed
2024-01-17 19:55:59,421:INFO:       statsforecast: Not installed
2024-01-17 19:55:59,421:INFO:        tune_sklearn: Not installed
2024-01-17 19:55:59,421:INFO:                 ray: Not installed
2024-01-17 19:55:59,421:INFO:            hyperopt: Not installed
2024-01-17 19:55:59,421:INFO:              optuna: Not installed
2024-01-17 19:55:59,421:INFO:               skopt: Not installed
2024-01-17 19:55:59,421:INFO:              mlflow: Not installed
2024-01-17 19:55:59,421:INFO:              gradio: Not installed
2024-01-17 19:55:59,421:INFO:             fastapi: Not installed
2024-01-17 19:55:59,421:INFO:             uvicorn: Not installed
2024-01-17 19:55:59,421:INFO:              m2cgen: Not installed
2024-01-17 19:55:59,421:INFO:           evidently: Not installed
2024-01-17 19:55:59,421:INFO:               fugue: Not installed
2024-01-17 19:55:59,421:INFO:           streamlit: Not installed
2024-01-17 19:55:59,421:INFO:             prophet: Not installed
2024-01-17 19:55:59,421:INFO:None
2024-01-17 19:55:59,421:INFO:Set up data.
2024-01-17 19:55:59,442:INFO:Set up folding strategy.
2024-01-17 19:55:59,443:INFO:Set up train/test split.
2024-01-17 19:55:59,463:INFO:Set up index.
2024-01-17 19:55:59,464:INFO:Assigning column types.
2024-01-17 19:55:59,479:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-17 19:55:59,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:55:59,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 19:55:59,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:55:59,758:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:55:59,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 19:55:59,932:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 19:56:00,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:56:00,059:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:56:00,062:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-17 19:56:00,251:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 19:56:00,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:56:00,370:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:56:00,552:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 19:56:00,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:56:00,669:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:56:00,669:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-17 19:56:01,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:56:01,009:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:56:01,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:56:01,259:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:56:01,262:INFO:Preparing preprocessing pipeline...
2024-01-17 19:56:01,262:INFO:Set up simple imputation.
2024-01-17 19:56:01,270:INFO:Set up encoding of ordinal features.
2024-01-17 19:56:01,278:INFO:Set up encoding of categorical features.
2024-01-17 19:56:01,630:INFO:Finished creating preprocessing pipeline.
2024-01-17 19:56:01,708:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprec...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-17 19:56:01,708:INFO:Creating final display dataframe.
2024-01-17 19:56:03,261:INFO:Setup _display_container:                     Description             Value
0                    Session id              2612
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 13)
5   Transformed train set shape         (623, 13)
6    Transformed test set shape         (268, 13)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 4
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              2214
2024-01-17 19:56:03,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:56:03,509:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:56:03,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-17 19:56:03,792:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 19:56:03,805:INFO:setup() successfully completed in 4.4s...............
2024-01-17 19:56:07,574:INFO:Initializing compare_models()
2024-01-17 19:56:07,574:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-17 19:56:07,574:INFO:Checking exceptions
2024-01-17 19:56:07,579:INFO:Preparing display monitor
2024-01-17 19:56:07,675:INFO:Initializing Logistic Regression
2024-01-17 19:56:07,677:INFO:Total runtime is 3.069639205932617e-05 minutes
2024-01-17 19:56:07,685:INFO:SubProcess create_model() called ==================================
2024-01-17 19:56:07,685:INFO:Initializing create_model()
2024-01-17 19:56:07,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:56:07,688:INFO:Checking exceptions
2024-01-17 19:56:07,688:INFO:Importing libraries
2024-01-17 19:56:07,688:INFO:Copying training dataset
2024-01-17 19:56:07,704:INFO:Defining folds
2024-01-17 19:56:07,704:INFO:Declaring metric variables
2024-01-17 19:56:07,710:INFO:Importing untrained model
2024-01-17 19:56:07,725:INFO:Logistic Regression Imported successfully
2024-01-17 19:56:07,742:INFO:Starting cross validation
2024-01-17 19:56:07,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:04,190:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:57:04,206:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:57:05,529:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:57:05,766:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:57:06,553:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:57:06,662:INFO:Calculating mean and std
2024-01-17 19:57:06,678:INFO:Creating metrics dataframe
2024-01-17 19:57:06,688:INFO:Uploading results into container
2024-01-17 19:57:06,688:INFO:Uploading model into container now
2024-01-17 19:57:06,688:INFO:_master_model_container: 1
2024-01-17 19:57:06,688:INFO:_display_container: 2
2024-01-17 19:57:06,688:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 19:57:06,699:INFO:create_model() successfully completed......................................
2024-01-17 19:57:06,978:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:06,978:INFO:Creating metrics dataframe
2024-01-17 19:57:07,009:INFO:Initializing K Neighbors Classifier
2024-01-17 19:57:07,009:INFO:Total runtime is 0.9889039715131124 minutes
2024-01-17 19:57:07,009:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:07,009:INFO:Initializing create_model()
2024-01-17 19:57:07,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:07,009:INFO:Checking exceptions
2024-01-17 19:57:07,009:INFO:Importing libraries
2024-01-17 19:57:07,009:INFO:Copying training dataset
2024-01-17 19:57:07,031:INFO:Defining folds
2024-01-17 19:57:07,032:INFO:Declaring metric variables
2024-01-17 19:57:07,041:INFO:Importing untrained model
2024-01-17 19:57:07,047:INFO:K Neighbors Classifier Imported successfully
2024-01-17 19:57:07,061:INFO:Starting cross validation
2024-01-17 19:57:07,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:09,478:INFO:Calculating mean and std
2024-01-17 19:57:09,478:INFO:Creating metrics dataframe
2024-01-17 19:57:09,493:INFO:Uploading results into container
2024-01-17 19:57:09,499:INFO:Uploading model into container now
2024-01-17 19:57:09,500:INFO:_master_model_container: 2
2024-01-17 19:57:09,500:INFO:_display_container: 2
2024-01-17 19:57:09,500:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-17 19:57:09,501:INFO:create_model() successfully completed......................................
2024-01-17 19:57:09,739:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:09,739:INFO:Creating metrics dataframe
2024-01-17 19:57:09,769:INFO:Initializing Naive Bayes
2024-01-17 19:57:09,769:INFO:Total runtime is 1.0348976333936055 minutes
2024-01-17 19:57:09,781:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:09,781:INFO:Initializing create_model()
2024-01-17 19:57:09,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:09,781:INFO:Checking exceptions
2024-01-17 19:57:09,781:INFO:Importing libraries
2024-01-17 19:57:09,781:INFO:Copying training dataset
2024-01-17 19:57:09,796:INFO:Defining folds
2024-01-17 19:57:09,796:INFO:Declaring metric variables
2024-01-17 19:57:09,808:INFO:Importing untrained model
2024-01-17 19:57:09,814:INFO:Naive Bayes Imported successfully
2024-01-17 19:57:09,837:INFO:Starting cross validation
2024-01-17 19:57:09,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:12,252:INFO:Calculating mean and std
2024-01-17 19:57:12,252:INFO:Creating metrics dataframe
2024-01-17 19:57:12,273:INFO:Uploading results into container
2024-01-17 19:57:12,273:INFO:Uploading model into container now
2024-01-17 19:57:12,277:INFO:_master_model_container: 3
2024-01-17 19:57:12,277:INFO:_display_container: 2
2024-01-17 19:57:12,277:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-17 19:57:12,277:INFO:create_model() successfully completed......................................
2024-01-17 19:57:12,521:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:12,521:INFO:Creating metrics dataframe
2024-01-17 19:57:12,552:INFO:Initializing Decision Tree Classifier
2024-01-17 19:57:12,552:INFO:Total runtime is 1.0812870820363363 minutes
2024-01-17 19:57:12,568:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:12,568:INFO:Initializing create_model()
2024-01-17 19:57:12,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:12,568:INFO:Checking exceptions
2024-01-17 19:57:12,568:INFO:Importing libraries
2024-01-17 19:57:12,568:INFO:Copying training dataset
2024-01-17 19:57:12,585:INFO:Defining folds
2024-01-17 19:57:12,585:INFO:Declaring metric variables
2024-01-17 19:57:12,587:INFO:Importing untrained model
2024-01-17 19:57:12,602:INFO:Decision Tree Classifier Imported successfully
2024-01-17 19:57:12,617:INFO:Starting cross validation
2024-01-17 19:57:12,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:14,213:INFO:Calculating mean and std
2024-01-17 19:57:14,213:INFO:Creating metrics dataframe
2024-01-17 19:57:14,228:INFO:Uploading results into container
2024-01-17 19:57:14,228:INFO:Uploading model into container now
2024-01-17 19:57:14,228:INFO:_master_model_container: 4
2024-01-17 19:57:14,228:INFO:_display_container: 2
2024-01-17 19:57:14,228:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2612, splitter='best')
2024-01-17 19:57:14,228:INFO:create_model() successfully completed......................................
2024-01-17 19:57:14,453:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:14,453:INFO:Creating metrics dataframe
2024-01-17 19:57:14,482:INFO:Initializing SVM - Linear Kernel
2024-01-17 19:57:14,482:INFO:Total runtime is 1.1134411613146464 minutes
2024-01-17 19:57:14,493:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:14,493:INFO:Initializing create_model()
2024-01-17 19:57:14,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:14,497:INFO:Checking exceptions
2024-01-17 19:57:14,497:INFO:Importing libraries
2024-01-17 19:57:14,497:INFO:Copying training dataset
2024-01-17 19:57:14,522:INFO:Defining folds
2024-01-17 19:57:14,522:INFO:Declaring metric variables
2024-01-17 19:57:14,535:INFO:Importing untrained model
2024-01-17 19:57:14,548:INFO:SVM - Linear Kernel Imported successfully
2024-01-17 19:57:14,562:INFO:Starting cross validation
2024-01-17 19:57:14,567:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:15,368:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:15,368:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:15,368:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:15,415:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:15,839:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:15,886:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:15,886:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:15,917:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:16,121:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:16,231:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 19:57:16,248:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:57:16,248:INFO:Calculating mean and std
2024-01-17 19:57:16,248:INFO:Creating metrics dataframe
2024-01-17 19:57:16,269:INFO:Uploading results into container
2024-01-17 19:57:16,269:INFO:Uploading model into container now
2024-01-17 19:57:16,269:INFO:_master_model_container: 5
2024-01-17 19:57:16,269:INFO:_display_container: 2
2024-01-17 19:57:16,269:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2612, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-17 19:57:16,269:INFO:create_model() successfully completed......................................
2024-01-17 19:57:16,518:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:16,518:INFO:Creating metrics dataframe
2024-01-17 19:57:16,534:INFO:Initializing Ridge Classifier
2024-01-17 19:57:16,534:INFO:Total runtime is 1.1476498246192932 minutes
2024-01-17 19:57:16,550:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:16,550:INFO:Initializing create_model()
2024-01-17 19:57:16,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:16,553:INFO:Checking exceptions
2024-01-17 19:57:16,553:INFO:Importing libraries
2024-01-17 19:57:16,553:INFO:Copying training dataset
2024-01-17 19:57:16,558:INFO:Defining folds
2024-01-17 19:57:16,563:INFO:Declaring metric variables
2024-01-17 19:57:16,571:INFO:Importing untrained model
2024-01-17 19:57:16,577:INFO:Ridge Classifier Imported successfully
2024-01-17 19:57:16,596:INFO:Starting cross validation
2024-01-17 19:57:16,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:17,495:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:17,495:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:17,558:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:17,590:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:17,936:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:17,981:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:18,033:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:18,139:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:18,279:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:18,295:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 19:57:18,329:INFO:Calculating mean and std
2024-01-17 19:57:18,329:INFO:Creating metrics dataframe
2024-01-17 19:57:18,329:INFO:Uploading results into container
2024-01-17 19:57:18,329:INFO:Uploading model into container now
2024-01-17 19:57:18,329:INFO:_master_model_container: 6
2024-01-17 19:57:18,329:INFO:_display_container: 2
2024-01-17 19:57:18,340:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2612, solver='auto',
                tol=0.0001)
2024-01-17 19:57:18,341:INFO:create_model() successfully completed......................................
2024-01-17 19:57:18,581:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:18,581:INFO:Creating metrics dataframe
2024-01-17 19:57:18,594:INFO:Initializing Random Forest Classifier
2024-01-17 19:57:18,609:INFO:Total runtime is 1.1822385470072427 minutes
2024-01-17 19:57:18,617:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:18,617:INFO:Initializing create_model()
2024-01-17 19:57:18,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:18,618:INFO:Checking exceptions
2024-01-17 19:57:18,618:INFO:Importing libraries
2024-01-17 19:57:18,618:INFO:Copying training dataset
2024-01-17 19:57:18,627:INFO:Defining folds
2024-01-17 19:57:18,627:INFO:Declaring metric variables
2024-01-17 19:57:18,634:INFO:Importing untrained model
2024-01-17 19:57:18,641:INFO:Random Forest Classifier Imported successfully
2024-01-17 19:57:18,655:INFO:Starting cross validation
2024-01-17 19:57:18,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:23,065:INFO:Calculating mean and std
2024-01-17 19:57:23,065:INFO:Creating metrics dataframe
2024-01-17 19:57:23,091:INFO:Uploading results into container
2024-01-17 19:57:23,091:INFO:Uploading model into container now
2024-01-17 19:57:23,091:INFO:_master_model_container: 7
2024-01-17 19:57:23,091:INFO:_display_container: 2
2024-01-17 19:57:23,091:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2612, verbose=0, warm_start=False)
2024-01-17 19:57:23,098:INFO:create_model() successfully completed......................................
2024-01-17 19:57:23,345:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:23,345:INFO:Creating metrics dataframe
2024-01-17 19:57:23,376:INFO:Initializing Quadratic Discriminant Analysis
2024-01-17 19:57:23,376:INFO:Total runtime is 1.2616838137308755 minutes
2024-01-17 19:57:23,386:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:23,386:INFO:Initializing create_model()
2024-01-17 19:57:23,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:23,386:INFO:Checking exceptions
2024-01-17 19:57:23,386:INFO:Importing libraries
2024-01-17 19:57:23,386:INFO:Copying training dataset
2024-01-17 19:57:23,402:INFO:Defining folds
2024-01-17 19:57:23,402:INFO:Declaring metric variables
2024-01-17 19:57:23,402:INFO:Importing untrained model
2024-01-17 19:57:23,414:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-17 19:57:23,430:INFO:Starting cross validation
2024-01-17 19:57:23,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:25,025:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:57:25,025:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:57:25,029:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:57:25,622:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:57:25,637:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:57:25,662:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:57:25,700:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:57:26,078:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:57:26,094:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 19:57:26,219:INFO:Calculating mean and std
2024-01-17 19:57:26,229:INFO:Creating metrics dataframe
2024-01-17 19:57:26,236:INFO:Uploading results into container
2024-01-17 19:57:26,236:INFO:Uploading model into container now
2024-01-17 19:57:26,236:INFO:_master_model_container: 8
2024-01-17 19:57:26,236:INFO:_display_container: 2
2024-01-17 19:57:26,236:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-17 19:57:26,236:INFO:create_model() successfully completed......................................
2024-01-17 19:57:26,508:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:26,508:INFO:Creating metrics dataframe
2024-01-17 19:57:26,535:INFO:Initializing Ada Boost Classifier
2024-01-17 19:57:26,535:INFO:Total runtime is 1.3143234650293985 minutes
2024-01-17 19:57:26,558:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:26,558:INFO:Initializing create_model()
2024-01-17 19:57:26,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:26,558:INFO:Checking exceptions
2024-01-17 19:57:26,558:INFO:Importing libraries
2024-01-17 19:57:26,558:INFO:Copying training dataset
2024-01-17 19:57:26,576:INFO:Defining folds
2024-01-17 19:57:26,577:INFO:Declaring metric variables
2024-01-17 19:57:26,580:INFO:Importing untrained model
2024-01-17 19:57:26,589:INFO:Ada Boost Classifier Imported successfully
2024-01-17 19:57:26,613:INFO:Starting cross validation
2024-01-17 19:57:26,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:29,545:INFO:Calculating mean and std
2024-01-17 19:57:29,545:INFO:Creating metrics dataframe
2024-01-17 19:57:29,561:INFO:Uploading results into container
2024-01-17 19:57:29,561:INFO:Uploading model into container now
2024-01-17 19:57:29,561:INFO:_master_model_container: 9
2024-01-17 19:57:29,561:INFO:_display_container: 2
2024-01-17 19:57:29,561:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2612)
2024-01-17 19:57:29,561:INFO:create_model() successfully completed......................................
2024-01-17 19:57:29,852:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:29,852:INFO:Creating metrics dataframe
2024-01-17 19:57:29,914:INFO:Initializing Gradient Boosting Classifier
2024-01-17 19:57:29,914:INFO:Total runtime is 1.3706505775451658 minutes
2024-01-17 19:57:29,925:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:29,925:INFO:Initializing create_model()
2024-01-17 19:57:29,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:29,929:INFO:Checking exceptions
2024-01-17 19:57:29,929:INFO:Importing libraries
2024-01-17 19:57:29,929:INFO:Copying training dataset
2024-01-17 19:57:29,940:INFO:Defining folds
2024-01-17 19:57:29,940:INFO:Declaring metric variables
2024-01-17 19:57:29,950:INFO:Importing untrained model
2024-01-17 19:57:29,959:INFO:Gradient Boosting Classifier Imported successfully
2024-01-17 19:57:29,970:INFO:Starting cross validation
2024-01-17 19:57:29,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:32,979:INFO:Calculating mean and std
2024-01-17 19:57:32,979:INFO:Creating metrics dataframe
2024-01-17 19:57:32,979:INFO:Uploading results into container
2024-01-17 19:57:32,979:INFO:Uploading model into container now
2024-01-17 19:57:32,979:INFO:_master_model_container: 10
2024-01-17 19:57:32,979:INFO:_display_container: 2
2024-01-17 19:57:32,979:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2612, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 19:57:32,979:INFO:create_model() successfully completed......................................
2024-01-17 19:57:33,192:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:33,192:INFO:Creating metrics dataframe
2024-01-17 19:57:33,216:INFO:Initializing Linear Discriminant Analysis
2024-01-17 19:57:33,217:INFO:Total runtime is 1.4256901105244952 minutes
2024-01-17 19:57:33,217:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:33,217:INFO:Initializing create_model()
2024-01-17 19:57:33,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:33,217:INFO:Checking exceptions
2024-01-17 19:57:33,217:INFO:Importing libraries
2024-01-17 19:57:33,217:INFO:Copying training dataset
2024-01-17 19:57:33,230:INFO:Defining folds
2024-01-17 19:57:33,238:INFO:Declaring metric variables
2024-01-17 19:57:33,238:INFO:Importing untrained model
2024-01-17 19:57:33,257:INFO:Linear Discriminant Analysis Imported successfully
2024-01-17 19:57:33,264:INFO:Starting cross validation
2024-01-17 19:57:33,271:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:34,701:INFO:Calculating mean and std
2024-01-17 19:57:34,701:INFO:Creating metrics dataframe
2024-01-17 19:57:34,717:INFO:Uploading results into container
2024-01-17 19:57:34,717:INFO:Uploading model into container now
2024-01-17 19:57:34,717:INFO:_master_model_container: 11
2024-01-17 19:57:34,717:INFO:_display_container: 2
2024-01-17 19:57:34,717:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-17 19:57:34,717:INFO:create_model() successfully completed......................................
2024-01-17 19:57:34,970:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:34,970:INFO:Creating metrics dataframe
2024-01-17 19:57:35,002:INFO:Initializing Extra Trees Classifier
2024-01-17 19:57:35,002:INFO:Total runtime is 1.455447999636332 minutes
2024-01-17 19:57:35,017:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:35,017:INFO:Initializing create_model()
2024-01-17 19:57:35,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:35,017:INFO:Checking exceptions
2024-01-17 19:57:35,017:INFO:Importing libraries
2024-01-17 19:57:35,017:INFO:Copying training dataset
2024-01-17 19:57:35,033:INFO:Defining folds
2024-01-17 19:57:35,033:INFO:Declaring metric variables
2024-01-17 19:57:35,033:INFO:Importing untrained model
2024-01-17 19:57:35,048:INFO:Extra Trees Classifier Imported successfully
2024-01-17 19:57:35,064:INFO:Starting cross validation
2024-01-17 19:57:35,064:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:38,810:INFO:Calculating mean and std
2024-01-17 19:57:38,815:INFO:Creating metrics dataframe
2024-01-17 19:57:38,815:INFO:Uploading results into container
2024-01-17 19:57:38,826:INFO:Uploading model into container now
2024-01-17 19:57:38,830:INFO:_master_model_container: 12
2024-01-17 19:57:38,830:INFO:_display_container: 2
2024-01-17 19:57:38,830:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2612, verbose=0, warm_start=False)
2024-01-17 19:57:38,830:INFO:create_model() successfully completed......................................
2024-01-17 19:57:39,112:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:39,112:INFO:Creating metrics dataframe
2024-01-17 19:57:39,166:INFO:Initializing Light Gradient Boosting Machine
2024-01-17 19:57:39,166:INFO:Total runtime is 1.524855355421702 minutes
2024-01-17 19:57:39,180:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:39,180:INFO:Initializing create_model()
2024-01-17 19:57:39,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:39,182:INFO:Checking exceptions
2024-01-17 19:57:39,182:INFO:Importing libraries
2024-01-17 19:57:39,182:INFO:Copying training dataset
2024-01-17 19:57:39,197:INFO:Defining folds
2024-01-17 19:57:39,197:INFO:Declaring metric variables
2024-01-17 19:57:39,212:INFO:Importing untrained model
2024-01-17 19:57:39,222:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-17 19:57:39,246:INFO:Starting cross validation
2024-01-17 19:57:39,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:57:42,472:INFO:Calculating mean and std
2024-01-17 19:57:42,472:INFO:Creating metrics dataframe
2024-01-17 19:57:42,487:INFO:Uploading results into container
2024-01-17 19:57:42,487:INFO:Uploading model into container now
2024-01-17 19:57:42,487:INFO:_master_model_container: 13
2024-01-17 19:57:42,487:INFO:_display_container: 2
2024-01-17 19:57:42,487:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2612, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-17 19:57:42,487:INFO:create_model() successfully completed......................................
2024-01-17 19:57:42,793:INFO:SubProcess create_model() end ==================================
2024-01-17 19:57:42,793:INFO:Creating metrics dataframe
2024-01-17 19:57:42,831:INFO:Initializing CatBoost Classifier
2024-01-17 19:57:42,831:INFO:Total runtime is 1.5859288851420084 minutes
2024-01-17 19:57:42,847:INFO:SubProcess create_model() called ==================================
2024-01-17 19:57:42,847:INFO:Initializing create_model()
2024-01-17 19:57:42,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:57:42,847:INFO:Checking exceptions
2024-01-17 19:57:42,847:INFO:Importing libraries
2024-01-17 19:57:42,847:INFO:Copying training dataset
2024-01-17 19:57:42,863:INFO:Defining folds
2024-01-17 19:57:42,864:INFO:Declaring metric variables
2024-01-17 19:57:42,869:INFO:Importing untrained model
2024-01-17 19:57:42,880:INFO:CatBoost Classifier Imported successfully
2024-01-17 19:57:42,903:INFO:Starting cross validation
2024-01-17 19:57:42,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:58:30,658:INFO:Calculating mean and std
2024-01-17 19:58:30,674:INFO:Creating metrics dataframe
2024-01-17 19:58:30,684:INFO:Uploading results into container
2024-01-17 19:58:30,684:INFO:Uploading model into container now
2024-01-17 19:58:30,684:INFO:_master_model_container: 14
2024-01-17 19:58:30,684:INFO:_display_container: 2
2024-01-17 19:58:30,684:INFO:<catboost.core.CatBoostClassifier object at 0x0000029A0E1ABA90>
2024-01-17 19:58:30,695:INFO:create_model() successfully completed......................................
2024-01-17 19:58:30,989:INFO:SubProcess create_model() end ==================================
2024-01-17 19:58:30,989:INFO:Creating metrics dataframe
2024-01-17 19:58:31,036:INFO:Initializing Dummy Classifier
2024-01-17 19:58:31,036:INFO:Total runtime is 2.3893501520156857 minutes
2024-01-17 19:58:31,053:INFO:SubProcess create_model() called ==================================
2024-01-17 19:58:31,053:INFO:Initializing create_model()
2024-01-17 19:58:31,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A11558510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:58:31,053:INFO:Checking exceptions
2024-01-17 19:58:31,053:INFO:Importing libraries
2024-01-17 19:58:31,053:INFO:Copying training dataset
2024-01-17 19:58:31,068:INFO:Defining folds
2024-01-17 19:58:31,068:INFO:Declaring metric variables
2024-01-17 19:58:31,085:INFO:Importing untrained model
2024-01-17 19:58:31,100:INFO:Dummy Classifier Imported successfully
2024-01-17 19:58:31,115:INFO:Starting cross validation
2024-01-17 19:58:31,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 19:58:31,685:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:31,732:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:31,763:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:31,763:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:32,219:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:32,328:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:32,328:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:32,328:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:32,564:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:32,597:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 19:58:32,618:INFO:Calculating mean and std
2024-01-17 19:58:32,621:INFO:Creating metrics dataframe
2024-01-17 19:58:32,629:INFO:Uploading results into container
2024-01-17 19:58:32,631:INFO:Uploading model into container now
2024-01-17 19:58:32,631:INFO:_master_model_container: 15
2024-01-17 19:58:32,633:INFO:_display_container: 2
2024-01-17 19:58:32,633:INFO:DummyClassifier(constant=None, random_state=2612, strategy='prior')
2024-01-17 19:58:32,633:INFO:create_model() successfully completed......................................
2024-01-17 19:58:32,863:INFO:SubProcess create_model() end ==================================
2024-01-17 19:58:33,288:INFO:Creating metrics dataframe
2024-01-17 19:58:33,352:INFO:Initializing create_model()
2024-01-17 19:58:33,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:58:33,352:INFO:Checking exceptions
2024-01-17 19:58:33,352:INFO:Importing libraries
2024-01-17 19:58:33,352:INFO:Copying training dataset
2024-01-17 19:58:33,368:INFO:Defining folds
2024-01-17 19:58:33,368:INFO:Declaring metric variables
2024-01-17 19:58:33,368:INFO:Importing untrained model
2024-01-17 19:58:33,368:INFO:Declaring custom model
2024-01-17 19:58:33,368:INFO:Logistic Regression Imported successfully
2024-01-17 19:58:33,368:INFO:Cross validation set to False
2024-01-17 19:58:33,368:INFO:Fitting Model
2024-01-17 19:58:35,799:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 19:58:35,799:INFO:create_model() successfully completed......................................
2024-01-17 19:58:36,081:INFO:_master_model_container: 15
2024-01-17 19:58:36,081:INFO:_display_container: 2
2024-01-17 19:58:36,081:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 19:58:36,081:INFO:compare_models() successfully completed......................................
2024-01-17 19:58:43,999:INFO:Initializing finalize_model()
2024-01-17 19:58:43,999:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-17 19:58:44,001:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 19:58:44,007:INFO:Initializing create_model()
2024-01-17 19:58:44,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 19:58:44,007:INFO:Checking exceptions
2024-01-17 19:58:44,009:INFO:Importing libraries
2024-01-17 19:58:44,009:INFO:Copying training dataset
2024-01-17 19:58:44,010:INFO:Defining folds
2024-01-17 19:58:44,010:INFO:Declaring metric variables
2024-01-17 19:58:44,011:INFO:Importing untrained model
2024-01-17 19:58:44,011:INFO:Declaring custom model
2024-01-17 19:58:44,013:INFO:Logistic Regression Imported successfully
2024-01-17 19:58:44,017:INFO:Cross validation set to False
2024-01-17 19:58:44,017:INFO:Fitting Model
2024-01-17 19:58:44,848:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 19:58:44,915:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Transforme...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2612,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-01-17 19:58:44,915:INFO:create_model() successfully completed......................................
2024-01-17 19:58:45,152:INFO:_master_model_container: 15
2024-01-17 19:58:45,152:INFO:_display_container: 2
2024-01-17 19:58:45,216:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Transforme...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2612,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-01-17 19:58:45,216:INFO:finalize_model() successfully completed......................................
2024-01-17 19:58:47,090:INFO:Initializing evaluate_model()
2024-01-17 19:58:47,090:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-17 19:58:47,107:INFO:Initializing plot_model()
2024-01-17 19:58:47,107:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 19:58:47,107:INFO:Checking exceptions
2024-01-17 19:58:47,113:INFO:Preloading libraries
2024-01-17 19:58:47,114:INFO:Copying training dataset
2024-01-17 19:58:47,114:INFO:Plot type: pipeline
2024-01-17 19:58:47,541:INFO:Visual Rendered Successfully
2024-01-17 19:58:47,810:INFO:plot_model() successfully completed......................................
2024-01-17 19:58:53,329:INFO:Initializing plot_model()
2024-01-17 19:58:53,329:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 19:58:53,329:INFO:Checking exceptions
2024-01-17 19:58:53,334:INFO:Preloading libraries
2024-01-17 19:58:53,334:INFO:Copying training dataset
2024-01-17 19:58:53,334:INFO:Plot type: feature_all
2024-01-17 19:58:53,959:INFO:Visual Rendered Successfully
2024-01-17 19:58:54,209:INFO:plot_model() successfully completed......................................
2024-01-17 19:59:04,768:INFO:Initializing plot_model()
2024-01-17 19:59:04,768:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 19:59:04,768:INFO:Checking exceptions
2024-01-17 19:59:04,777:INFO:Preloading libraries
2024-01-17 19:59:04,778:INFO:Copying training dataset
2024-01-17 19:59:04,778:INFO:Plot type: feature
2024-01-17 19:59:05,354:INFO:Visual Rendered Successfully
2024-01-17 19:59:05,608:INFO:plot_model() successfully completed......................................
2024-01-17 19:59:07,603:INFO:Initializing plot_model()
2024-01-17 19:59:07,603:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 19:59:07,603:INFO:Checking exceptions
2024-01-17 19:59:07,608:INFO:Preloading libraries
2024-01-17 19:59:07,608:INFO:Copying training dataset
2024-01-17 19:59:07,608:INFO:Plot type: feature_all
2024-01-17 19:59:08,230:INFO:Visual Rendered Successfully
2024-01-17 19:59:08,451:INFO:plot_model() successfully completed......................................
2024-01-17 19:59:09,828:INFO:Initializing plot_model()
2024-01-17 19:59:09,828:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 19:59:09,831:INFO:Checking exceptions
2024-01-17 19:59:09,834:INFO:Preloading libraries
2024-01-17 19:59:09,836:INFO:Copying training dataset
2024-01-17 19:59:09,836:INFO:Plot type: feature
2024-01-17 19:59:10,369:INFO:Visual Rendered Successfully
2024-01-17 19:59:10,620:INFO:plot_model() successfully completed......................................
2024-01-17 19:59:13,096:INFO:Initializing evaluate_model()
2024-01-17 19:59:13,102:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-17 19:59:13,125:INFO:Initializing plot_model()
2024-01-17 19:59:13,125:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 19:59:13,125:INFO:Checking exceptions
2024-01-17 19:59:13,138:INFO:Preloading libraries
2024-01-17 19:59:13,140:INFO:Copying training dataset
2024-01-17 19:59:13,140:INFO:Plot type: pipeline
2024-01-17 19:59:13,571:INFO:Visual Rendered Successfully
2024-01-17 19:59:13,853:INFO:plot_model() successfully completed......................................
2024-01-17 19:59:13,903:INFO:Initializing predict_model()
2024-01-17 19:59:13,903:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029A0BA96E80>)
2024-01-17 19:59:13,903:INFO:Checking exceptions
2024-01-17 19:59:13,903:INFO:Preloading libraries
2024-01-17 19:59:15,577:INFO:Initializing predict_model()
2024-01-17 19:59:15,577:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029A0EEEEAD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2612, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029A0D6FC4A0>)
2024-01-17 19:59:15,577:INFO:Checking exceptions
2024-01-17 19:59:15,577:INFO:Preloading libraries
2024-01-17 19:59:15,586:INFO:Set up data.
2024-01-17 19:59:15,602:INFO:Set up index.
2024-01-17 20:15:24,195:WARNING:C:\Users\Auditor\AppData\Local\Temp\ipykernel_15924\2409864084.py:4: UserWarning: 

`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

  sns.distplot(target, kde=True, fit=scipy.stats.norm)

2024-01-17 20:15:26,321:WARNING:C:\Users\Auditor\AppData\Local\Temp\ipykernel_15924\2409864084.py:8: UserWarning: 

`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

  sns.distplot(np.log(target), kde=True, fit=scipy.stats.norm)

2024-01-17 20:21:05,165:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\joblib\externals\loky\backend\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2024-01-17 20:40:22,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 20:40:22,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 20:40:22,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 20:40:22,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 21:56:09,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 21:56:09,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 21:56:09,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 21:56:09,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 21:59:54,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 21:59:54,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 21:59:54,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 21:59:54,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 22:06:27,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 22:06:27,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 22:06:27,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 22:06:27,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 22:42:20,599:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\joblib\externals\loky\backend\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2024-01-17 23:14:22,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:14:22,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:14:22,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:14:22,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:14:29,253:INFO:PyCaret ClassificationExperiment
2024-01-17 23:14:29,253:INFO:Logging name: clf-default-name
2024-01-17 23:14:29,253:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-17 23:14:29,253:INFO:version 3.2.0
2024-01-17 23:14:29,253:INFO:Initializing setup()
2024-01-17 23:14:29,253:INFO:self.USI: af2b
2024-01-17 23:14:29,253:INFO:self._variable_keys: {'n_jobs_param', 'fold_shuffle_param', '_available_plots', 'memory', 'fold_groups_param', 'logging_param', 'gpu_param', 'is_multiclass', 'gpu_n_jobs_param', 'fix_imbalance', 'fold_generator', 'y_test', '_ml_usecase', 'exp_name_log', 'idx', 'html_param', 'log_plots_param', 'X_test', 'y_train', 'exp_id', 'y', 'target_param', 'data', 'seed', 'USI', 'X', 'X_train', 'pipeline'}
2024-01-17 23:14:29,253:INFO:Checking environment
2024-01-17 23:14:29,253:INFO:python_version: 3.11.5
2024-01-17 23:14:29,253:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 23:14:29,253:INFO:machine: AMD64
2024-01-17 23:14:29,253:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 23:14:29,253:INFO:Memory: svmem(total=8361132032, available=1951617024, percent=76.7, used=6409515008, free=1951617024)
2024-01-17 23:14:29,253:INFO:Physical Core: 2
2024-01-17 23:14:29,253:INFO:Logical Core: 4
2024-01-17 23:14:29,253:INFO:Checking libraries
2024-01-17 23:14:29,253:INFO:System:
2024-01-17 23:14:29,253:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 23:14:29,253:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 23:14:29,253:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 23:14:29,253:INFO:PyCaret required dependencies:
2024-01-17 23:14:36,834:INFO:                 pip: 23.2.1
2024-01-17 23:14:36,834:INFO:          setuptools: 68.0.0
2024-01-17 23:14:36,834:INFO:             pycaret: 3.2.0
2024-01-17 23:14:36,848:INFO:             IPython: 8.15.0
2024-01-17 23:14:36,848:INFO:          ipywidgets: 8.0.4
2024-01-17 23:14:36,848:INFO:                tqdm: 4.65.0
2024-01-17 23:14:36,848:INFO:               numpy: 1.24.3
2024-01-17 23:14:36,848:INFO:              pandas: 1.5.3
2024-01-17 23:14:36,848:INFO:              jinja2: 3.1.2
2024-01-17 23:14:36,848:INFO:               scipy: 1.10.1
2024-01-17 23:14:36,848:INFO:              joblib: 1.2.0
2024-01-17 23:14:36,848:INFO:             sklearn: 1.2.2
2024-01-17 23:14:36,848:INFO:                pyod: 1.1.2
2024-01-17 23:14:36,848:INFO:            imblearn: 0.10.1
2024-01-17 23:14:36,848:INFO:   category_encoders: 2.6.3
2024-01-17 23:14:36,848:INFO:            lightgbm: 4.2.0
2024-01-17 23:14:36,848:INFO:               numba: 0.57.1
2024-01-17 23:14:36,848:INFO:            requests: 2.31.0
2024-01-17 23:14:36,848:INFO:          matplotlib: 3.6.0
2024-01-17 23:14:36,848:INFO:          scikitplot: 0.3.7
2024-01-17 23:14:36,848:INFO:         yellowbrick: 1.5
2024-01-17 23:14:36,848:INFO:              plotly: 5.9.0
2024-01-17 23:14:36,848:INFO:    plotly-resampler: Not installed
2024-01-17 23:14:36,848:INFO:             kaleido: 0.2.1
2024-01-17 23:14:36,848:INFO:           schemdraw: 0.15
2024-01-17 23:14:36,848:INFO:         statsmodels: 0.14.0
2024-01-17 23:14:36,848:INFO:              sktime: 0.21.1
2024-01-17 23:14:36,848:INFO:               tbats: 1.1.3
2024-01-17 23:14:36,848:INFO:            pmdarima: 2.0.4
2024-01-17 23:14:36,848:INFO:              psutil: 5.9.0
2024-01-17 23:14:36,848:INFO:          markupsafe: 2.1.1
2024-01-17 23:14:36,848:INFO:             pickle5: Not installed
2024-01-17 23:14:36,848:INFO:         cloudpickle: 2.2.1
2024-01-17 23:14:36,848:INFO:         deprecation: 2.1.0
2024-01-17 23:14:36,848:INFO:              xxhash: 2.0.2
2024-01-17 23:14:36,848:INFO:           wurlitzer: Not installed
2024-01-17 23:14:36,848:INFO:PyCaret optional dependencies:
2024-01-17 23:14:37,396:INFO:                shap: Not installed
2024-01-17 23:14:37,396:INFO:           interpret: Not installed
2024-01-17 23:14:37,396:INFO:                umap: Not installed
2024-01-17 23:14:37,396:INFO:     ydata_profiling: Not installed
2024-01-17 23:14:37,396:INFO:  explainerdashboard: Not installed
2024-01-17 23:14:37,396:INFO:             autoviz: Not installed
2024-01-17 23:14:37,396:INFO:           fairlearn: Not installed
2024-01-17 23:14:37,396:INFO:          deepchecks: Not installed
2024-01-17 23:14:37,396:INFO:             xgboost: 2.0.3
2024-01-17 23:14:37,396:INFO:            catboost: 1.2.2
2024-01-17 23:14:37,396:INFO:              kmodes: Not installed
2024-01-17 23:14:37,396:INFO:             mlxtend: Not installed
2024-01-17 23:14:37,396:INFO:       statsforecast: Not installed
2024-01-17 23:14:37,396:INFO:        tune_sklearn: Not installed
2024-01-17 23:14:37,396:INFO:                 ray: Not installed
2024-01-17 23:14:37,396:INFO:            hyperopt: Not installed
2024-01-17 23:14:37,396:INFO:              optuna: 3.5.0
2024-01-17 23:14:37,396:INFO:               skopt: Not installed
2024-01-17 23:14:37,396:INFO:              mlflow: Not installed
2024-01-17 23:14:37,396:INFO:              gradio: Not installed
2024-01-17 23:14:37,396:INFO:             fastapi: Not installed
2024-01-17 23:14:37,396:INFO:             uvicorn: Not installed
2024-01-17 23:14:37,396:INFO:              m2cgen: Not installed
2024-01-17 23:14:37,396:INFO:           evidently: Not installed
2024-01-17 23:14:37,396:INFO:               fugue: Not installed
2024-01-17 23:14:37,396:INFO:           streamlit: Not installed
2024-01-17 23:14:37,396:INFO:             prophet: Not installed
2024-01-17 23:14:37,396:INFO:None
2024-01-17 23:14:37,396:INFO:Set up data.
2024-01-17 23:14:37,427:INFO:Set up folding strategy.
2024-01-17 23:14:37,427:INFO:Set up train/test split.
2024-01-17 23:14:37,443:INFO:Set up index.
2024-01-17 23:14:37,443:INFO:Assigning column types.
2024-01-17 23:14:37,459:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-17 23:14:37,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:14:37,679:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:14:37,961:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:14:37,976:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:14:38,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:14:38,836:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:14:38,916:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:14:38,931:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:14:38,931:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-17 23:14:39,056:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:14:39,150:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:14:39,165:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:14:39,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:14:39,449:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:14:39,449:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:14:39,449:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-17 23:14:39,683:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:14:39,683:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:14:39,918:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:14:39,918:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:14:42,451:INFO:Preparing preprocessing pipeline...
2024-01-17 23:14:42,451:INFO:Set up simple imputation.
2024-01-17 23:14:42,466:INFO:Set up encoding of ordinal features.
2024-01-17 23:14:42,466:INFO:Set up encoding of categorical features.
2024-01-17 23:14:43,202:INFO:Finished creating preprocessing pipeline.
2024-01-17 23:14:43,248:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprec...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-01-17 23:14:43,248:INFO:Creating final display dataframe.
2024-01-17 23:14:44,031:INFO:Setup _display_container:                     Description             Value
0                    Session id              2373
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 13)
5   Transformed train set shape         (623, 13)
6    Transformed test set shape         (268, 13)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 4
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              af2b
2024-01-17 23:14:44,243:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:14:44,247:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:14:44,550:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:14:44,550:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:14:44,550:INFO:setup() successfully completed in 15.5s...............
2024-01-17 23:14:44,579:INFO:Initializing compare_models()
2024-01-17 23:14:44,579:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-17 23:14:44,579:INFO:Checking exceptions
2024-01-17 23:14:44,597:INFO:Preparing display monitor
2024-01-17 23:14:44,673:INFO:Initializing Logistic Regression
2024-01-17 23:14:44,674:INFO:Total runtime is 0.0 minutes
2024-01-17 23:14:44,681:INFO:SubProcess create_model() called ==================================
2024-01-17 23:14:44,689:INFO:Initializing create_model()
2024-01-17 23:14:44,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:14:44,690:INFO:Checking exceptions
2024-01-17 23:14:44,690:INFO:Importing libraries
2024-01-17 23:14:44,690:INFO:Copying training dataset
2024-01-17 23:14:44,705:INFO:Defining folds
2024-01-17 23:14:44,705:INFO:Declaring metric variables
2024-01-17 23:14:44,706:INFO:Importing untrained model
2024-01-17 23:14:44,724:INFO:Logistic Regression Imported successfully
2024-01-17 23:14:44,741:INFO:Starting cross validation
2024-01-17 23:14:44,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:00,264:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 23:15:00,267:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 23:15:01,416:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 23:15:01,653:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 23:15:02,143:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 23:15:02,253:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 23:15:02,425:INFO:Calculating mean and std
2024-01-17 23:15:02,425:INFO:Creating metrics dataframe
2024-01-17 23:15:02,448:INFO:Uploading results into container
2024-01-17 23:15:02,450:INFO:Uploading model into container now
2024-01-17 23:15:02,450:INFO:_master_model_container: 1
2024-01-17 23:15:02,450:INFO:_display_container: 2
2024-01-17 23:15:02,455:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2373, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 23:15:02,455:INFO:create_model() successfully completed......................................
2024-01-17 23:15:02,655:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:02,655:INFO:Creating metrics dataframe
2024-01-17 23:15:02,670:INFO:Initializing K Neighbors Classifier
2024-01-17 23:15:02,670:INFO:Total runtime is 0.29995737473169964 minutes
2024-01-17 23:15:02,694:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:02,694:INFO:Initializing create_model()
2024-01-17 23:15:02,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:02,694:INFO:Checking exceptions
2024-01-17 23:15:02,694:INFO:Importing libraries
2024-01-17 23:15:02,694:INFO:Copying training dataset
2024-01-17 23:15:02,705:INFO:Defining folds
2024-01-17 23:15:02,705:INFO:Declaring metric variables
2024-01-17 23:15:02,719:INFO:Importing untrained model
2024-01-17 23:15:02,727:INFO:K Neighbors Classifier Imported successfully
2024-01-17 23:15:02,739:INFO:Starting cross validation
2024-01-17 23:15:02,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:05,140:INFO:Calculating mean and std
2024-01-17 23:15:05,141:INFO:Creating metrics dataframe
2024-01-17 23:15:05,141:INFO:Uploading results into container
2024-01-17 23:15:05,141:INFO:Uploading model into container now
2024-01-17 23:15:05,153:INFO:_master_model_container: 2
2024-01-17 23:15:05,153:INFO:_display_container: 2
2024-01-17 23:15:05,153:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-17 23:15:05,155:INFO:create_model() successfully completed......................................
2024-01-17 23:15:05,319:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:05,319:INFO:Creating metrics dataframe
2024-01-17 23:15:05,339:INFO:Initializing Naive Bayes
2024-01-17 23:15:05,339:INFO:Total runtime is 0.3444294412930807 minutes
2024-01-17 23:15:05,357:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:05,358:INFO:Initializing create_model()
2024-01-17 23:15:05,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:05,358:INFO:Checking exceptions
2024-01-17 23:15:05,358:INFO:Importing libraries
2024-01-17 23:15:05,359:INFO:Copying training dataset
2024-01-17 23:15:05,367:INFO:Defining folds
2024-01-17 23:15:05,370:INFO:Declaring metric variables
2024-01-17 23:15:05,380:INFO:Importing untrained model
2024-01-17 23:15:05,390:INFO:Naive Bayes Imported successfully
2024-01-17 23:15:05,409:INFO:Starting cross validation
2024-01-17 23:15:05,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:06,956:INFO:Calculating mean and std
2024-01-17 23:15:06,958:INFO:Creating metrics dataframe
2024-01-17 23:15:06,958:INFO:Uploading results into container
2024-01-17 23:15:06,972:INFO:Uploading model into container now
2024-01-17 23:15:06,973:INFO:_master_model_container: 3
2024-01-17 23:15:06,973:INFO:_display_container: 2
2024-01-17 23:15:06,976:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-17 23:15:06,976:INFO:create_model() successfully completed......................................
2024-01-17 23:15:07,108:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:07,108:INFO:Creating metrics dataframe
2024-01-17 23:15:07,145:INFO:Initializing Decision Tree Classifier
2024-01-17 23:15:07,145:INFO:Total runtime is 0.37453086376190187 minutes
2024-01-17 23:15:07,158:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:07,159:INFO:Initializing create_model()
2024-01-17 23:15:07,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:07,160:INFO:Checking exceptions
2024-01-17 23:15:07,160:INFO:Importing libraries
2024-01-17 23:15:07,160:INFO:Copying training dataset
2024-01-17 23:15:07,161:INFO:Defining folds
2024-01-17 23:15:07,170:INFO:Declaring metric variables
2024-01-17 23:15:07,180:INFO:Importing untrained model
2024-01-17 23:15:07,189:INFO:Decision Tree Classifier Imported successfully
2024-01-17 23:15:07,206:INFO:Starting cross validation
2024-01-17 23:15:07,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:08,710:INFO:Calculating mean and std
2024-01-17 23:15:08,710:INFO:Creating metrics dataframe
2024-01-17 23:15:08,733:INFO:Uploading results into container
2024-01-17 23:15:08,733:INFO:Uploading model into container now
2024-01-17 23:15:08,733:INFO:_master_model_container: 4
2024-01-17 23:15:08,733:INFO:_display_container: 2
2024-01-17 23:15:08,739:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2373, splitter='best')
2024-01-17 23:15:08,739:INFO:create_model() successfully completed......................................
2024-01-17 23:15:08,882:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:08,882:INFO:Creating metrics dataframe
2024-01-17 23:15:08,914:INFO:Initializing SVM - Linear Kernel
2024-01-17 23:15:08,914:INFO:Total runtime is 0.4040221412976583 minutes
2024-01-17 23:15:08,924:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:08,924:INFO:Initializing create_model()
2024-01-17 23:15:08,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:08,925:INFO:Checking exceptions
2024-01-17 23:15:08,925:INFO:Importing libraries
2024-01-17 23:15:08,925:INFO:Copying training dataset
2024-01-17 23:15:08,939:INFO:Defining folds
2024-01-17 23:15:08,939:INFO:Declaring metric variables
2024-01-17 23:15:08,946:INFO:Importing untrained model
2024-01-17 23:15:08,955:INFO:SVM - Linear Kernel Imported successfully
2024-01-17 23:15:08,973:INFO:Starting cross validation
2024-01-17 23:15:08,973:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:10,042:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:15:10,042:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:15:10,042:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:15:10,587:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:15:10,594:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:15:10,610:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:15:10,610:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:15:11,003:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:15:11,019:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:15:11,034:INFO:Calculating mean and std
2024-01-17 23:15:11,034:INFO:Creating metrics dataframe
2024-01-17 23:15:11,050:INFO:Uploading results into container
2024-01-17 23:15:11,050:INFO:Uploading model into container now
2024-01-17 23:15:11,050:INFO:_master_model_container: 5
2024-01-17 23:15:11,050:INFO:_display_container: 2
2024-01-17 23:15:11,050:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2373, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-17 23:15:11,050:INFO:create_model() successfully completed......................................
2024-01-17 23:15:11,200:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:11,200:INFO:Creating metrics dataframe
2024-01-17 23:15:11,239:INFO:Initializing Ridge Classifier
2024-01-17 23:15:11,247:INFO:Total runtime is 0.44289528528849287 minutes
2024-01-17 23:15:11,255:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:11,255:INFO:Initializing create_model()
2024-01-17 23:15:11,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:11,255:INFO:Checking exceptions
2024-01-17 23:15:11,255:INFO:Importing libraries
2024-01-17 23:15:11,255:INFO:Copying training dataset
2024-01-17 23:15:11,271:INFO:Defining folds
2024-01-17 23:15:11,272:INFO:Declaring metric variables
2024-01-17 23:15:11,280:INFO:Importing untrained model
2024-01-17 23:15:11,292:INFO:Ridge Classifier Imported successfully
2024-01-17 23:15:11,313:INFO:Starting cross validation
2024-01-17 23:15:11,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:12,087:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,087:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,115:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,131:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,477:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,493:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,493:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,493:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,602:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,602:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:15:12,618:INFO:Calculating mean and std
2024-01-17 23:15:12,618:INFO:Creating metrics dataframe
2024-01-17 23:15:12,618:INFO:Uploading results into container
2024-01-17 23:15:12,618:INFO:Uploading model into container now
2024-01-17 23:15:12,618:INFO:_master_model_container: 6
2024-01-17 23:15:12,618:INFO:_display_container: 2
2024-01-17 23:15:12,618:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2373, solver='auto',
                tol=0.0001)
2024-01-17 23:15:12,618:INFO:create_model() successfully completed......................................
2024-01-17 23:15:12,703:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:12,703:INFO:Creating metrics dataframe
2024-01-17 23:15:12,737:INFO:Initializing Random Forest Classifier
2024-01-17 23:15:12,739:INFO:Total runtime is 0.46777025063832606 minutes
2024-01-17 23:15:12,751:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:12,752:INFO:Initializing create_model()
2024-01-17 23:15:12,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:12,752:INFO:Checking exceptions
2024-01-17 23:15:12,752:INFO:Importing libraries
2024-01-17 23:15:12,755:INFO:Copying training dataset
2024-01-17 23:15:12,765:INFO:Defining folds
2024-01-17 23:15:12,765:INFO:Declaring metric variables
2024-01-17 23:15:12,774:INFO:Importing untrained model
2024-01-17 23:15:12,781:INFO:Random Forest Classifier Imported successfully
2024-01-17 23:15:12,805:INFO:Starting cross validation
2024-01-17 23:15:12,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:16,291:INFO:Calculating mean and std
2024-01-17 23:15:16,291:INFO:Creating metrics dataframe
2024-01-17 23:15:16,291:INFO:Uploading results into container
2024-01-17 23:15:16,306:INFO:Uploading model into container now
2024-01-17 23:15:16,306:INFO:_master_model_container: 7
2024-01-17 23:15:16,306:INFO:_display_container: 2
2024-01-17 23:15:16,312:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2373, verbose=0, warm_start=False)
2024-01-17 23:15:16,312:INFO:create_model() successfully completed......................................
2024-01-17 23:15:16,457:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:16,457:INFO:Creating metrics dataframe
2024-01-17 23:15:16,489:INFO:Initializing Quadratic Discriminant Analysis
2024-01-17 23:15:16,489:INFO:Total runtime is 0.5302768627802531 minutes
2024-01-17 23:15:16,502:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:16,502:INFO:Initializing create_model()
2024-01-17 23:15:16,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:16,505:INFO:Checking exceptions
2024-01-17 23:15:16,505:INFO:Importing libraries
2024-01-17 23:15:16,506:INFO:Copying training dataset
2024-01-17 23:15:16,513:INFO:Defining folds
2024-01-17 23:15:16,513:INFO:Declaring metric variables
2024-01-17 23:15:16,522:INFO:Importing untrained model
2024-01-17 23:15:16,539:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-17 23:15:16,555:INFO:Starting cross validation
2024-01-17 23:15:16,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:22,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:22,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:22,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:22,075:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:22,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:22,640:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:22,645:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:22,657:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:23,095:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:23,095:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:15:23,256:INFO:Calculating mean and std
2024-01-17 23:15:23,258:INFO:Creating metrics dataframe
2024-01-17 23:15:23,264:INFO:Uploading results into container
2024-01-17 23:15:23,273:INFO:Uploading model into container now
2024-01-17 23:15:23,273:INFO:_master_model_container: 8
2024-01-17 23:15:23,273:INFO:_display_container: 2
2024-01-17 23:15:23,273:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-17 23:15:23,273:INFO:create_model() successfully completed......................................
2024-01-17 23:15:23,442:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:23,442:INFO:Creating metrics dataframe
2024-01-17 23:15:23,489:INFO:Initializing Ada Boost Classifier
2024-01-17 23:15:23,489:INFO:Total runtime is 0.6469370206197103 minutes
2024-01-17 23:15:23,502:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:23,502:INFO:Initializing create_model()
2024-01-17 23:15:23,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:23,502:INFO:Checking exceptions
2024-01-17 23:15:23,502:INFO:Importing libraries
2024-01-17 23:15:23,502:INFO:Copying training dataset
2024-01-17 23:15:23,518:INFO:Defining folds
2024-01-17 23:15:23,518:INFO:Declaring metric variables
2024-01-17 23:15:23,528:INFO:Importing untrained model
2024-01-17 23:15:23,537:INFO:Ada Boost Classifier Imported successfully
2024-01-17 23:15:23,545:INFO:Starting cross validation
2024-01-17 23:15:23,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:26,559:INFO:Calculating mean and std
2024-01-17 23:15:26,564:INFO:Creating metrics dataframe
2024-01-17 23:15:26,580:INFO:Uploading results into container
2024-01-17 23:15:26,580:INFO:Uploading model into container now
2024-01-17 23:15:26,580:INFO:_master_model_container: 9
2024-01-17 23:15:26,580:INFO:_display_container: 2
2024-01-17 23:15:26,588:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2373)
2024-01-17 23:15:26,588:INFO:create_model() successfully completed......................................
2024-01-17 23:15:26,756:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:26,756:INFO:Creating metrics dataframe
2024-01-17 23:15:26,791:INFO:Initializing Gradient Boosting Classifier
2024-01-17 23:15:26,791:INFO:Total runtime is 0.7019769271214803 minutes
2024-01-17 23:15:26,806:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:26,824:INFO:Initializing create_model()
2024-01-17 23:15:26,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:26,824:INFO:Checking exceptions
2024-01-17 23:15:26,824:INFO:Importing libraries
2024-01-17 23:15:26,824:INFO:Copying training dataset
2024-01-17 23:15:26,840:INFO:Defining folds
2024-01-17 23:15:26,840:INFO:Declaring metric variables
2024-01-17 23:15:26,855:INFO:Importing untrained model
2024-01-17 23:15:26,865:INFO:Gradient Boosting Classifier Imported successfully
2024-01-17 23:15:26,876:INFO:Starting cross validation
2024-01-17 23:15:26,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:30,378:INFO:Calculating mean and std
2024-01-17 23:15:30,378:INFO:Creating metrics dataframe
2024-01-17 23:15:30,394:INFO:Uploading results into container
2024-01-17 23:15:30,394:INFO:Uploading model into container now
2024-01-17 23:15:30,394:INFO:_master_model_container: 10
2024-01-17 23:15:30,394:INFO:_display_container: 2
2024-01-17 23:15:30,394:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 23:15:30,394:INFO:create_model() successfully completed......................................
2024-01-17 23:15:30,567:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:30,567:INFO:Creating metrics dataframe
2024-01-17 23:15:30,608:INFO:Initializing Linear Discriminant Analysis
2024-01-17 23:15:30,609:INFO:Total runtime is 0.7655984004338582 minutes
2024-01-17 23:15:30,615:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:30,615:INFO:Initializing create_model()
2024-01-17 23:15:30,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:30,621:INFO:Checking exceptions
2024-01-17 23:15:30,622:INFO:Importing libraries
2024-01-17 23:15:30,622:INFO:Copying training dataset
2024-01-17 23:15:30,640:INFO:Defining folds
2024-01-17 23:15:30,641:INFO:Declaring metric variables
2024-01-17 23:15:30,651:INFO:Importing untrained model
2024-01-17 23:15:30,659:INFO:Linear Discriminant Analysis Imported successfully
2024-01-17 23:15:30,682:INFO:Starting cross validation
2024-01-17 23:15:30,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:32,594:INFO:Calculating mean and std
2024-01-17 23:15:32,603:INFO:Creating metrics dataframe
2024-01-17 23:15:32,611:INFO:Uploading results into container
2024-01-17 23:15:32,611:INFO:Uploading model into container now
2024-01-17 23:15:32,611:INFO:_master_model_container: 11
2024-01-17 23:15:32,611:INFO:_display_container: 2
2024-01-17 23:15:32,611:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-17 23:15:32,611:INFO:create_model() successfully completed......................................
2024-01-17 23:15:32,756:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:32,756:INFO:Creating metrics dataframe
2024-01-17 23:15:32,784:INFO:Initializing Extra Trees Classifier
2024-01-17 23:15:32,784:INFO:Total runtime is 0.8018476406733195 minutes
2024-01-17 23:15:32,791:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:32,791:INFO:Initializing create_model()
2024-01-17 23:15:32,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:32,791:INFO:Checking exceptions
2024-01-17 23:15:32,791:INFO:Importing libraries
2024-01-17 23:15:32,791:INFO:Copying training dataset
2024-01-17 23:15:32,808:INFO:Defining folds
2024-01-17 23:15:32,808:INFO:Declaring metric variables
2024-01-17 23:15:32,816:INFO:Importing untrained model
2024-01-17 23:15:32,824:INFO:Extra Trees Classifier Imported successfully
2024-01-17 23:15:32,847:INFO:Starting cross validation
2024-01-17 23:15:32,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:36,756:INFO:Calculating mean and std
2024-01-17 23:15:36,756:INFO:Creating metrics dataframe
2024-01-17 23:15:36,769:INFO:Uploading results into container
2024-01-17 23:15:36,773:INFO:Uploading model into container now
2024-01-17 23:15:36,773:INFO:_master_model_container: 12
2024-01-17 23:15:36,773:INFO:_display_container: 2
2024-01-17 23:15:36,773:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2373, verbose=0, warm_start=False)
2024-01-17 23:15:36,773:INFO:create_model() successfully completed......................................
2024-01-17 23:15:36,888:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:36,888:INFO:Creating metrics dataframe
2024-01-17 23:15:36,929:INFO:Initializing Extreme Gradient Boosting
2024-01-17 23:15:36,929:INFO:Total runtime is 0.8709330002466837 minutes
2024-01-17 23:15:36,939:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:36,939:INFO:Initializing create_model()
2024-01-17 23:15:36,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:36,941:INFO:Checking exceptions
2024-01-17 23:15:36,942:INFO:Importing libraries
2024-01-17 23:15:36,942:INFO:Copying training dataset
2024-01-17 23:15:36,955:INFO:Defining folds
2024-01-17 23:15:36,955:INFO:Declaring metric variables
2024-01-17 23:15:36,958:INFO:Importing untrained model
2024-01-17 23:15:36,973:INFO:Extreme Gradient Boosting Imported successfully
2024-01-17 23:15:36,990:INFO:Starting cross validation
2024-01-17 23:15:36,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:40,126:INFO:Calculating mean and std
2024-01-17 23:15:40,126:INFO:Creating metrics dataframe
2024-01-17 23:15:40,135:INFO:Uploading results into container
2024-01-17 23:15:40,135:INFO:Uploading model into container now
2024-01-17 23:15:40,135:INFO:_master_model_container: 13
2024-01-17 23:15:40,135:INFO:_display_container: 2
2024-01-17 23:15:40,142:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-17 23:15:40,142:INFO:create_model() successfully completed......................................
2024-01-17 23:15:40,281:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:40,281:INFO:Creating metrics dataframe
2024-01-17 23:15:40,322:INFO:Initializing Light Gradient Boosting Machine
2024-01-17 23:15:40,322:INFO:Total runtime is 0.9274809718132019 minutes
2024-01-17 23:15:40,329:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:40,329:INFO:Initializing create_model()
2024-01-17 23:15:40,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:40,329:INFO:Checking exceptions
2024-01-17 23:15:40,329:INFO:Importing libraries
2024-01-17 23:15:40,337:INFO:Copying training dataset
2024-01-17 23:15:40,346:INFO:Defining folds
2024-01-17 23:15:40,346:INFO:Declaring metric variables
2024-01-17 23:15:40,362:INFO:Importing untrained model
2024-01-17 23:15:40,371:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-17 23:15:40,398:INFO:Starting cross validation
2024-01-17 23:15:40,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:15:43,838:INFO:Calculating mean and std
2024-01-17 23:15:43,843:INFO:Creating metrics dataframe
2024-01-17 23:15:43,855:INFO:Uploading results into container
2024-01-17 23:15:43,859:INFO:Uploading model into container now
2024-01-17 23:15:43,860:INFO:_master_model_container: 14
2024-01-17 23:15:43,861:INFO:_display_container: 2
2024-01-17 23:15:43,861:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2373, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-17 23:15:43,861:INFO:create_model() successfully completed......................................
2024-01-17 23:15:43,974:INFO:SubProcess create_model() end ==================================
2024-01-17 23:15:43,974:INFO:Creating metrics dataframe
2024-01-17 23:15:44,004:INFO:Initializing CatBoost Classifier
2024-01-17 23:15:44,004:INFO:Total runtime is 0.988859462738037 minutes
2024-01-17 23:15:44,015:INFO:SubProcess create_model() called ==================================
2024-01-17 23:15:44,015:INFO:Initializing create_model()
2024-01-17 23:15:44,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:15:44,015:INFO:Checking exceptions
2024-01-17 23:15:44,021:INFO:Importing libraries
2024-01-17 23:15:44,021:INFO:Copying training dataset
2024-01-17 23:15:44,038:INFO:Defining folds
2024-01-17 23:15:44,038:INFO:Declaring metric variables
2024-01-17 23:15:44,048:INFO:Importing untrained model
2024-01-17 23:15:44,059:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:15:44,075:INFO:Starting cross validation
2024-01-17 23:15:44,077:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:16:33,734:INFO:Calculating mean and std
2024-01-17 23:16:33,736:INFO:Creating metrics dataframe
2024-01-17 23:16:33,741:INFO:Uploading results into container
2024-01-17 23:16:33,741:INFO:Uploading model into container now
2024-01-17 23:16:33,741:INFO:_master_model_container: 15
2024-01-17 23:16:33,741:INFO:_display_container: 2
2024-01-17 23:16:33,741:INFO:<catboost.core.CatBoostClassifier object at 0x000002911B36FC90>
2024-01-17 23:16:33,741:INFO:create_model() successfully completed......................................
2024-01-17 23:16:33,907:INFO:SubProcess create_model() end ==================================
2024-01-17 23:16:33,907:INFO:Creating metrics dataframe
2024-01-17 23:16:33,939:INFO:Initializing Dummy Classifier
2024-01-17 23:16:33,939:INFO:Total runtime is 1.8211002151171365 minutes
2024-01-17 23:16:33,952:INFO:SubProcess create_model() called ==================================
2024-01-17 23:16:33,953:INFO:Initializing create_model()
2024-01-17 23:16:33,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002911943C290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:16:33,955:INFO:Checking exceptions
2024-01-17 23:16:33,955:INFO:Importing libraries
2024-01-17 23:16:33,955:INFO:Copying training dataset
2024-01-17 23:16:33,968:INFO:Defining folds
2024-01-17 23:16:33,968:INFO:Declaring metric variables
2024-01-17 23:16:33,981:INFO:Importing untrained model
2024-01-17 23:16:33,988:INFO:Dummy Classifier Imported successfully
2024-01-17 23:16:34,008:INFO:Starting cross validation
2024-01-17 23:16:34,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:16:34,556:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:34,563:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:34,568:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:34,574:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:35,053:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:35,061:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:35,063:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:35,141:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:35,342:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:35,342:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:16:35,357:INFO:Calculating mean and std
2024-01-17 23:16:35,357:INFO:Creating metrics dataframe
2024-01-17 23:16:35,373:INFO:Uploading results into container
2024-01-17 23:16:35,373:INFO:Uploading model into container now
2024-01-17 23:16:35,373:INFO:_master_model_container: 16
2024-01-17 23:16:35,373:INFO:_display_container: 2
2024-01-17 23:16:35,373:INFO:DummyClassifier(constant=None, random_state=2373, strategy='prior')
2024-01-17 23:16:35,373:INFO:create_model() successfully completed......................................
2024-01-17 23:16:35,483:INFO:SubProcess create_model() end ==================================
2024-01-17 23:16:35,483:INFO:Creating metrics dataframe
2024-01-17 23:16:35,572:INFO:Initializing create_model()
2024-01-17 23:16:35,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2373, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:16:35,572:INFO:Checking exceptions
2024-01-17 23:16:35,576:INFO:Importing libraries
2024-01-17 23:16:35,576:INFO:Copying training dataset
2024-01-17 23:16:35,580:INFO:Defining folds
2024-01-17 23:16:35,580:INFO:Declaring metric variables
2024-01-17 23:16:35,580:INFO:Importing untrained model
2024-01-17 23:16:35,580:INFO:Declaring custom model
2024-01-17 23:16:35,580:INFO:Logistic Regression Imported successfully
2024-01-17 23:16:35,580:INFO:Cross validation set to False
2024-01-17 23:16:35,580:INFO:Fitting Model
2024-01-17 23:16:36,199:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2373, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 23:16:36,199:INFO:create_model() successfully completed......................................
2024-01-17 23:16:36,447:INFO:_master_model_container: 16
2024-01-17 23:16:36,447:INFO:_display_container: 2
2024-01-17 23:16:36,447:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2373, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 23:16:36,447:INFO:compare_models() successfully completed......................................
2024-01-17 23:16:37,190:INFO:Initializing finalize_model()
2024-01-17 23:16:37,190:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2373, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-17 23:16:37,190:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2373, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 23:16:37,205:INFO:Initializing create_model()
2024-01-17 23:16:37,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000291174658D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2373, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:16:37,205:INFO:Checking exceptions
2024-01-17 23:16:37,205:INFO:Importing libraries
2024-01-17 23:16:37,205:INFO:Copying training dataset
2024-01-17 23:16:37,205:INFO:Defining folds
2024-01-17 23:16:37,205:INFO:Declaring metric variables
2024-01-17 23:16:37,205:INFO:Importing untrained model
2024-01-17 23:16:37,205:INFO:Declaring custom model
2024-01-17 23:16:37,205:INFO:Logistic Regression Imported successfully
2024-01-17 23:16:37,205:INFO:Cross validation set to False
2024-01-17 23:16:37,205:INFO:Fitting Model
2024-01-17 23:16:37,928:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-17 23:16:38,023:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Transforme...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2373,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-01-17 23:16:38,023:INFO:create_model() successfully completed......................................
2024-01-17 23:16:38,184:INFO:_master_model_container: 16
2024-01-17 23:16:38,184:INFO:_display_container: 2
2024-01-17 23:16:38,238:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Transforme...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2373,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-01-17 23:16:38,238:INFO:finalize_model() successfully completed......................................
2024-01-17 23:17:40,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:17:40,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:17:40,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:17:40,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:24:43,069:INFO:PyCaret ClassificationExperiment
2024-01-17 23:24:43,069:INFO:Logging name: clf-default-name
2024-01-17 23:24:43,069:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-17 23:24:43,084:INFO:version 3.2.0
2024-01-17 23:24:43,084:INFO:Initializing setup()
2024-01-17 23:24:43,084:INFO:self.USI: 7fb5
2024-01-17 23:24:43,084:INFO:self._variable_keys: {'seed', 'is_multiclass', 'target_param', 'y_test', 'data', 'exp_id', 'memory', 'gpu_n_jobs_param', 'gpu_param', 'X_train', '_available_plots', 'n_jobs_param', 'pipeline', 'fold_generator', 'X_test', 'X', 'fold_shuffle_param', '_ml_usecase', 'y', 'html_param', 'fix_imbalance', 'logging_param', 'log_plots_param', 'idx', 'y_train', 'fold_groups_param', 'exp_name_log', 'USI'}
2024-01-17 23:24:43,084:INFO:Checking environment
2024-01-17 23:24:43,084:INFO:python_version: 3.11.5
2024-01-17 23:24:43,084:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 23:24:43,084:INFO:machine: AMD64
2024-01-17 23:24:43,084:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 23:24:43,084:INFO:Memory: svmem(total=8361132032, available=1684754432, percent=79.9, used=6676377600, free=1684754432)
2024-01-17 23:24:43,084:INFO:Physical Core: 2
2024-01-17 23:24:43,084:INFO:Logical Core: 4
2024-01-17 23:24:43,084:INFO:Checking libraries
2024-01-17 23:24:43,084:INFO:System:
2024-01-17 23:24:43,084:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 23:24:43,084:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 23:24:43,084:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 23:24:43,084:INFO:PyCaret required dependencies:
2024-01-17 23:24:43,100:INFO:                 pip: 23.2.1
2024-01-17 23:24:43,100:INFO:          setuptools: 68.0.0
2024-01-17 23:24:43,100:INFO:             pycaret: 3.2.0
2024-01-17 23:24:43,100:INFO:             IPython: 8.15.0
2024-01-17 23:24:43,100:INFO:          ipywidgets: 8.0.4
2024-01-17 23:24:43,100:INFO:                tqdm: 4.65.0
2024-01-17 23:24:43,100:INFO:               numpy: 1.24.3
2024-01-17 23:24:43,101:INFO:              pandas: 1.5.3
2024-01-17 23:24:43,101:INFO:              jinja2: 3.1.2
2024-01-17 23:24:43,101:INFO:               scipy: 1.10.1
2024-01-17 23:24:43,101:INFO:              joblib: 1.2.0
2024-01-17 23:24:43,101:INFO:             sklearn: 1.2.2
2024-01-17 23:24:43,101:INFO:                pyod: 1.1.2
2024-01-17 23:24:43,102:INFO:            imblearn: 0.10.1
2024-01-17 23:24:43,102:INFO:   category_encoders: 2.6.3
2024-01-17 23:24:43,103:INFO:            lightgbm: 4.2.0
2024-01-17 23:24:43,103:INFO:               numba: 0.57.1
2024-01-17 23:24:43,103:INFO:            requests: 2.31.0
2024-01-17 23:24:43,103:INFO:          matplotlib: 3.6.0
2024-01-17 23:24:43,103:INFO:          scikitplot: 0.3.7
2024-01-17 23:24:43,103:INFO:         yellowbrick: 1.5
2024-01-17 23:24:43,103:INFO:              plotly: 5.9.0
2024-01-17 23:24:43,104:INFO:    plotly-resampler: Not installed
2024-01-17 23:24:43,104:INFO:             kaleido: 0.2.1
2024-01-17 23:24:43,104:INFO:           schemdraw: 0.15
2024-01-17 23:24:43,104:INFO:         statsmodels: 0.14.0
2024-01-17 23:24:43,104:INFO:              sktime: 0.21.1
2024-01-17 23:24:43,104:INFO:               tbats: 1.1.3
2024-01-17 23:24:43,104:INFO:            pmdarima: 2.0.4
2024-01-17 23:24:43,104:INFO:              psutil: 5.9.0
2024-01-17 23:24:43,104:INFO:          markupsafe: 2.1.1
2024-01-17 23:24:43,104:INFO:             pickle5: Not installed
2024-01-17 23:24:43,104:INFO:         cloudpickle: 2.2.1
2024-01-17 23:24:43,104:INFO:         deprecation: 2.1.0
2024-01-17 23:24:43,104:INFO:              xxhash: 2.0.2
2024-01-17 23:24:43,104:INFO:           wurlitzer: Not installed
2024-01-17 23:24:43,104:INFO:PyCaret optional dependencies:
2024-01-17 23:24:43,160:INFO:                shap: Not installed
2024-01-17 23:24:43,160:INFO:           interpret: Not installed
2024-01-17 23:24:43,160:INFO:                umap: Not installed
2024-01-17 23:24:43,160:INFO:     ydata_profiling: Not installed
2024-01-17 23:24:43,160:INFO:  explainerdashboard: Not installed
2024-01-17 23:24:43,160:INFO:             autoviz: Not installed
2024-01-17 23:24:43,160:INFO:           fairlearn: Not installed
2024-01-17 23:24:43,160:INFO:          deepchecks: Not installed
2024-01-17 23:24:43,160:INFO:             xgboost: 2.0.3
2024-01-17 23:24:43,160:INFO:            catboost: 1.2.2
2024-01-17 23:24:43,160:INFO:              kmodes: Not installed
2024-01-17 23:24:43,160:INFO:             mlxtend: Not installed
2024-01-17 23:24:43,160:INFO:       statsforecast: Not installed
2024-01-17 23:24:43,160:INFO:        tune_sklearn: Not installed
2024-01-17 23:24:43,160:INFO:                 ray: Not installed
2024-01-17 23:24:43,160:INFO:            hyperopt: Not installed
2024-01-17 23:24:43,160:INFO:              optuna: 3.5.0
2024-01-17 23:24:43,164:INFO:               skopt: Not installed
2024-01-17 23:24:43,164:INFO:              mlflow: Not installed
2024-01-17 23:24:43,164:INFO:              gradio: Not installed
2024-01-17 23:24:43,164:INFO:             fastapi: Not installed
2024-01-17 23:24:43,164:INFO:             uvicorn: Not installed
2024-01-17 23:24:43,164:INFO:              m2cgen: Not installed
2024-01-17 23:24:43,164:INFO:           evidently: Not installed
2024-01-17 23:24:43,164:INFO:               fugue: Not installed
2024-01-17 23:24:43,164:INFO:           streamlit: Not installed
2024-01-17 23:24:43,164:INFO:             prophet: Not installed
2024-01-17 23:24:43,166:INFO:None
2024-01-17 23:24:43,166:INFO:Set up data.
2024-01-17 23:24:43,180:INFO:Set up folding strategy.
2024-01-17 23:24:43,180:INFO:Set up train/test split.
2024-01-17 23:24:43,189:INFO:Set up index.
2024-01-17 23:24:43,189:INFO:Assigning column types.
2024-01-17 23:24:43,204:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-17 23:24:43,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:24:43,362:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:24:43,534:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:24:43,565:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:24:43,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:24:43,925:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:24:44,123:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:24:44,155:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:24:44,155:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-17 23:24:44,478:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:24:44,657:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:24:44,667:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:24:45,138:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:24:45,232:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:24:45,248:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:24:45,248:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-17 23:24:45,689:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:24:45,703:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:24:46,174:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:24:46,190:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:24:46,216:INFO:Preparing preprocessing pipeline...
2024-01-17 23:24:46,219:INFO:Set up simple imputation.
2024-01-17 23:24:46,300:INFO:Finished creating preprocessing pipeline.
2024-01-17 23:24:46,331:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-01-17 23:24:46,331:INFO:Creating final display dataframe.
2024-01-17 23:24:46,629:INFO:Setup _display_container:                     Description             Value
0                    Session id              3655
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 11)
5   Transformed train set shape         (623, 11)
6    Transformed test set shape         (268, 11)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7fb5
2024-01-17 23:24:47,051:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:24:47,078:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:24:47,506:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:24:47,537:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:24:47,537:INFO:setup() successfully completed in 4.53s...............
2024-01-17 23:25:08,989:INFO:Initializing compare_models()
2024-01-17 23:25:08,989:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-17 23:25:08,990:INFO:Checking exceptions
2024-01-17 23:25:08,998:INFO:Preparing display monitor
2024-01-17 23:25:09,098:INFO:Initializing Logistic Regression
2024-01-17 23:25:09,099:INFO:Total runtime is 0.0 minutes
2024-01-17 23:25:09,107:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:09,107:INFO:Initializing create_model()
2024-01-17 23:25:09,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:09,107:INFO:Checking exceptions
2024-01-17 23:25:09,107:INFO:Importing libraries
2024-01-17 23:25:09,107:INFO:Copying training dataset
2024-01-17 23:25:09,118:INFO:Defining folds
2024-01-17 23:25:09,118:INFO:Declaring metric variables
2024-01-17 23:25:09,127:INFO:Importing untrained model
2024-01-17 23:25:09,138:INFO:Logistic Regression Imported successfully
2024-01-17 23:25:09,158:INFO:Starting cross validation
2024-01-17 23:25:09,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:15,691:INFO:Calculating mean and std
2024-01-17 23:25:15,691:INFO:Creating metrics dataframe
2024-01-17 23:25:15,702:INFO:Uploading results into container
2024-01-17 23:25:15,704:INFO:Uploading model into container now
2024-01-17 23:25:15,704:INFO:_master_model_container: 1
2024-01-17 23:25:15,704:INFO:_display_container: 2
2024-01-17 23:25:15,705:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3655, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 23:25:15,705:INFO:create_model() successfully completed......................................
2024-01-17 23:25:15,927:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:15,927:INFO:Creating metrics dataframe
2024-01-17 23:25:15,966:INFO:Initializing K Neighbors Classifier
2024-01-17 23:25:15,966:INFO:Total runtime is 0.11447155872980753 minutes
2024-01-17 23:25:15,975:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:15,975:INFO:Initializing create_model()
2024-01-17 23:25:15,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:15,975:INFO:Checking exceptions
2024-01-17 23:25:15,975:INFO:Importing libraries
2024-01-17 23:25:15,981:INFO:Copying training dataset
2024-01-17 23:25:15,984:INFO:Defining folds
2024-01-17 23:25:15,984:INFO:Declaring metric variables
2024-01-17 23:25:15,991:INFO:Importing untrained model
2024-01-17 23:25:15,999:INFO:K Neighbors Classifier Imported successfully
2024-01-17 23:25:16,017:INFO:Starting cross validation
2024-01-17 23:25:16,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:16,272:INFO:Calculating mean and std
2024-01-17 23:25:16,285:INFO:Creating metrics dataframe
2024-01-17 23:25:16,285:INFO:Uploading results into container
2024-01-17 23:25:16,285:INFO:Uploading model into container now
2024-01-17 23:25:16,301:INFO:_master_model_container: 2
2024-01-17 23:25:16,302:INFO:_display_container: 2
2024-01-17 23:25:16,302:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-17 23:25:16,302:INFO:create_model() successfully completed......................................
2024-01-17 23:25:16,522:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:16,522:INFO:Creating metrics dataframe
2024-01-17 23:25:16,552:INFO:Initializing Naive Bayes
2024-01-17 23:25:16,552:INFO:Total runtime is 0.12423322598139445 minutes
2024-01-17 23:25:16,565:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:16,565:INFO:Initializing create_model()
2024-01-17 23:25:16,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:16,565:INFO:Checking exceptions
2024-01-17 23:25:16,567:INFO:Importing libraries
2024-01-17 23:25:16,567:INFO:Copying training dataset
2024-01-17 23:25:16,579:INFO:Defining folds
2024-01-17 23:25:16,581:INFO:Declaring metric variables
2024-01-17 23:25:16,590:INFO:Importing untrained model
2024-01-17 23:25:16,598:INFO:Naive Bayes Imported successfully
2024-01-17 23:25:16,614:INFO:Starting cross validation
2024-01-17 23:25:16,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:16,758:INFO:Calculating mean and std
2024-01-17 23:25:16,764:INFO:Creating metrics dataframe
2024-01-17 23:25:16,774:INFO:Uploading results into container
2024-01-17 23:25:16,774:INFO:Uploading model into container now
2024-01-17 23:25:16,774:INFO:_master_model_container: 3
2024-01-17 23:25:16,774:INFO:_display_container: 2
2024-01-17 23:25:16,781:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-17 23:25:16,781:INFO:create_model() successfully completed......................................
2024-01-17 23:25:17,003:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:17,003:INFO:Creating metrics dataframe
2024-01-17 23:25:17,050:INFO:Initializing Decision Tree Classifier
2024-01-17 23:25:17,050:INFO:Total runtime is 0.13253411849339802 minutes
2024-01-17 23:25:17,050:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:17,050:INFO:Initializing create_model()
2024-01-17 23:25:17,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:17,065:INFO:Checking exceptions
2024-01-17 23:25:17,065:INFO:Importing libraries
2024-01-17 23:25:17,065:INFO:Copying training dataset
2024-01-17 23:25:17,077:INFO:Defining folds
2024-01-17 23:25:17,078:INFO:Declaring metric variables
2024-01-17 23:25:17,089:INFO:Importing untrained model
2024-01-17 23:25:17,090:INFO:Decision Tree Classifier Imported successfully
2024-01-17 23:25:17,105:INFO:Starting cross validation
2024-01-17 23:25:17,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:17,268:INFO:Calculating mean and std
2024-01-17 23:25:17,268:INFO:Creating metrics dataframe
2024-01-17 23:25:17,281:INFO:Uploading results into container
2024-01-17 23:25:17,281:INFO:Uploading model into container now
2024-01-17 23:25:17,281:INFO:_master_model_container: 4
2024-01-17 23:25:17,281:INFO:_display_container: 2
2024-01-17 23:25:17,281:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3655, splitter='best')
2024-01-17 23:25:17,281:INFO:create_model() successfully completed......................................
2024-01-17 23:25:17,520:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:17,536:INFO:Creating metrics dataframe
2024-01-17 23:25:17,552:INFO:Initializing SVM - Linear Kernel
2024-01-17 23:25:17,552:INFO:Total runtime is 0.14089827140172323 minutes
2024-01-17 23:25:17,571:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:17,576:INFO:Initializing create_model()
2024-01-17 23:25:17,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:17,576:INFO:Checking exceptions
2024-01-17 23:25:17,576:INFO:Importing libraries
2024-01-17 23:25:17,576:INFO:Copying training dataset
2024-01-17 23:25:17,589:INFO:Defining folds
2024-01-17 23:25:17,589:INFO:Declaring metric variables
2024-01-17 23:25:17,597:INFO:Importing untrained model
2024-01-17 23:25:17,606:INFO:SVM - Linear Kernel Imported successfully
2024-01-17 23:25:17,624:INFO:Starting cross validation
2024-01-17 23:25:17,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:17,808:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:17,808:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:17,824:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:17,824:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:17,933:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:17,933:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:17,950:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:17,950:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:18,028:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:18,043:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:25:18,075:INFO:Calculating mean and std
2024-01-17 23:25:18,075:INFO:Creating metrics dataframe
2024-01-17 23:25:18,090:INFO:Uploading results into container
2024-01-17 23:25:18,090:INFO:Uploading model into container now
2024-01-17 23:25:18,090:INFO:_master_model_container: 5
2024-01-17 23:25:18,090:INFO:_display_container: 2
2024-01-17 23:25:18,090:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3655, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-17 23:25:18,090:INFO:create_model() successfully completed......................................
2024-01-17 23:25:18,320:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:18,320:INFO:Creating metrics dataframe
2024-01-17 23:25:18,351:INFO:Initializing Ridge Classifier
2024-01-17 23:25:18,351:INFO:Total runtime is 0.15422075986862183 minutes
2024-01-17 23:25:18,367:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:18,367:INFO:Initializing create_model()
2024-01-17 23:25:18,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:18,367:INFO:Checking exceptions
2024-01-17 23:25:18,367:INFO:Importing libraries
2024-01-17 23:25:18,367:INFO:Copying training dataset
2024-01-17 23:25:18,381:INFO:Defining folds
2024-01-17 23:25:18,382:INFO:Declaring metric variables
2024-01-17 23:25:18,391:INFO:Importing untrained model
2024-01-17 23:25:18,399:INFO:Ridge Classifier Imported successfully
2024-01-17 23:25:18,415:INFO:Starting cross validation
2024-01-17 23:25:18,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:18,968:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:18,968:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:19,000:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:19,000:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:19,093:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:19,093:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:19,110:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:19,140:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:19,203:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:19,203:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:25:19,235:INFO:Calculating mean and std
2024-01-17 23:25:19,235:INFO:Creating metrics dataframe
2024-01-17 23:25:19,247:INFO:Uploading results into container
2024-01-17 23:25:19,247:INFO:Uploading model into container now
2024-01-17 23:25:19,247:INFO:_master_model_container: 6
2024-01-17 23:25:19,247:INFO:_display_container: 2
2024-01-17 23:25:19,250:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3655, solver='auto',
                tol=0.0001)
2024-01-17 23:25:19,250:INFO:create_model() successfully completed......................................
2024-01-17 23:25:19,462:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:19,462:INFO:Creating metrics dataframe
2024-01-17 23:25:19,498:INFO:Initializing Random Forest Classifier
2024-01-17 23:25:19,498:INFO:Total runtime is 0.1733255386352539 minutes
2024-01-17 23:25:19,498:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:19,513:INFO:Initializing create_model()
2024-01-17 23:25:19,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:19,515:INFO:Checking exceptions
2024-01-17 23:25:19,515:INFO:Importing libraries
2024-01-17 23:25:19,515:INFO:Copying training dataset
2024-01-17 23:25:19,521:INFO:Defining folds
2024-01-17 23:25:19,521:INFO:Declaring metric variables
2024-01-17 23:25:19,536:INFO:Importing untrained model
2024-01-17 23:25:19,547:INFO:Random Forest Classifier Imported successfully
2024-01-17 23:25:19,565:INFO:Starting cross validation
2024-01-17 23:25:19,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:22,184:INFO:Calculating mean and std
2024-01-17 23:25:22,200:INFO:Creating metrics dataframe
2024-01-17 23:25:22,201:INFO:Uploading results into container
2024-01-17 23:25:22,201:INFO:Uploading model into container now
2024-01-17 23:25:22,201:INFO:_master_model_container: 7
2024-01-17 23:25:22,201:INFO:_display_container: 2
2024-01-17 23:25:22,201:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3655, verbose=0, warm_start=False)
2024-01-17 23:25:22,208:INFO:create_model() successfully completed......................................
2024-01-17 23:25:22,389:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:22,389:INFO:Creating metrics dataframe
2024-01-17 23:25:22,421:INFO:Initializing Quadratic Discriminant Analysis
2024-01-17 23:25:22,421:INFO:Total runtime is 0.22205487887064615 minutes
2024-01-17 23:25:22,436:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:22,436:INFO:Initializing create_model()
2024-01-17 23:25:22,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:22,436:INFO:Checking exceptions
2024-01-17 23:25:22,436:INFO:Importing libraries
2024-01-17 23:25:22,436:INFO:Copying training dataset
2024-01-17 23:25:22,453:INFO:Defining folds
2024-01-17 23:25:22,453:INFO:Declaring metric variables
2024-01-17 23:25:22,460:INFO:Importing untrained model
2024-01-17 23:25:22,468:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-17 23:25:22,481:INFO:Starting cross validation
2024-01-17 23:25:22,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:22,620:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,625:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,629:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,631:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,732:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:25:22,804:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,810:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,820:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,820:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:25:22,844:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,860:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,876:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:25:22,884:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:25:22,916:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:25:22,963:INFO:Calculating mean and std
2024-01-17 23:25:22,963:INFO:Creating metrics dataframe
2024-01-17 23:25:22,978:INFO:Uploading results into container
2024-01-17 23:25:22,978:INFO:Uploading model into container now
2024-01-17 23:25:22,978:INFO:_master_model_container: 8
2024-01-17 23:25:22,978:INFO:_display_container: 2
2024-01-17 23:25:22,978:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-17 23:25:22,978:INFO:create_model() successfully completed......................................
2024-01-17 23:25:23,158:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:23,158:INFO:Creating metrics dataframe
2024-01-17 23:25:23,180:INFO:Initializing Ada Boost Classifier
2024-01-17 23:25:23,180:INFO:Total runtime is 0.23470710118611654 minutes
2024-01-17 23:25:23,180:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:23,180:INFO:Initializing create_model()
2024-01-17 23:25:23,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:23,195:INFO:Checking exceptions
2024-01-17 23:25:23,195:INFO:Importing libraries
2024-01-17 23:25:23,195:INFO:Copying training dataset
2024-01-17 23:25:23,203:INFO:Defining folds
2024-01-17 23:25:23,203:INFO:Declaring metric variables
2024-01-17 23:25:23,211:INFO:Importing untrained model
2024-01-17 23:25:23,218:INFO:Ada Boost Classifier Imported successfully
2024-01-17 23:25:23,251:INFO:Starting cross validation
2024-01-17 23:25:23,251:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:24,720:INFO:Calculating mean and std
2024-01-17 23:25:24,720:INFO:Creating metrics dataframe
2024-01-17 23:25:24,743:INFO:Uploading results into container
2024-01-17 23:25:24,743:INFO:Uploading model into container now
2024-01-17 23:25:24,747:INFO:_master_model_container: 9
2024-01-17 23:25:24,747:INFO:_display_container: 2
2024-01-17 23:25:24,747:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3655)
2024-01-17 23:25:24,747:INFO:create_model() successfully completed......................................
2024-01-17 23:25:24,967:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:24,967:INFO:Creating metrics dataframe
2024-01-17 23:25:25,000:INFO:Initializing Gradient Boosting Classifier
2024-01-17 23:25:25,014:INFO:Total runtime is 0.2650407592455546 minutes
2024-01-17 23:25:25,022:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:25,022:INFO:Initializing create_model()
2024-01-17 23:25:25,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:25,022:INFO:Checking exceptions
2024-01-17 23:25:25,022:INFO:Importing libraries
2024-01-17 23:25:25,022:INFO:Copying training dataset
2024-01-17 23:25:25,035:INFO:Defining folds
2024-01-17 23:25:25,035:INFO:Declaring metric variables
2024-01-17 23:25:25,047:INFO:Importing untrained model
2024-01-17 23:25:25,055:INFO:Gradient Boosting Classifier Imported successfully
2024-01-17 23:25:25,071:INFO:Starting cross validation
2024-01-17 23:25:25,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:26,729:INFO:Calculating mean and std
2024-01-17 23:25:26,729:INFO:Creating metrics dataframe
2024-01-17 23:25:26,729:INFO:Uploading results into container
2024-01-17 23:25:26,745:INFO:Uploading model into container now
2024-01-17 23:25:26,745:INFO:_master_model_container: 10
2024-01-17 23:25:26,745:INFO:_display_container: 2
2024-01-17 23:25:26,745:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3655, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 23:25:26,745:INFO:create_model() successfully completed......................................
2024-01-17 23:25:26,964:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:26,964:INFO:Creating metrics dataframe
2024-01-17 23:25:27,002:INFO:Initializing Linear Discriminant Analysis
2024-01-17 23:25:27,002:INFO:Total runtime is 0.29839878479639687 minutes
2024-01-17 23:25:27,017:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:27,018:INFO:Initializing create_model()
2024-01-17 23:25:27,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:27,018:INFO:Checking exceptions
2024-01-17 23:25:27,018:INFO:Importing libraries
2024-01-17 23:25:27,018:INFO:Copying training dataset
2024-01-17 23:25:27,028:INFO:Defining folds
2024-01-17 23:25:27,028:INFO:Declaring metric variables
2024-01-17 23:25:27,039:INFO:Importing untrained model
2024-01-17 23:25:27,048:INFO:Linear Discriminant Analysis Imported successfully
2024-01-17 23:25:27,065:INFO:Starting cross validation
2024-01-17 23:25:27,073:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:27,451:INFO:Calculating mean and std
2024-01-17 23:25:27,451:INFO:Creating metrics dataframe
2024-01-17 23:25:27,462:INFO:Uploading results into container
2024-01-17 23:25:27,462:INFO:Uploading model into container now
2024-01-17 23:25:27,478:INFO:_master_model_container: 11
2024-01-17 23:25:27,479:INFO:_display_container: 2
2024-01-17 23:25:27,479:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-17 23:25:27,481:INFO:create_model() successfully completed......................................
2024-01-17 23:25:27,692:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:27,692:INFO:Creating metrics dataframe
2024-01-17 23:25:27,746:INFO:Initializing Extra Trees Classifier
2024-01-17 23:25:27,746:INFO:Total runtime is 0.31080029010772703 minutes
2024-01-17 23:25:27,763:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:27,763:INFO:Initializing create_model()
2024-01-17 23:25:27,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:27,763:INFO:Checking exceptions
2024-01-17 23:25:27,763:INFO:Importing libraries
2024-01-17 23:25:27,763:INFO:Copying training dataset
2024-01-17 23:25:27,775:INFO:Defining folds
2024-01-17 23:25:27,780:INFO:Declaring metric variables
2024-01-17 23:25:27,787:INFO:Importing untrained model
2024-01-17 23:25:27,793:INFO:Extra Trees Classifier Imported successfully
2024-01-17 23:25:27,806:INFO:Starting cross validation
2024-01-17 23:25:27,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:30,444:INFO:Calculating mean and std
2024-01-17 23:25:30,447:INFO:Creating metrics dataframe
2024-01-17 23:25:30,452:INFO:Uploading results into container
2024-01-17 23:25:30,452:INFO:Uploading model into container now
2024-01-17 23:25:30,452:INFO:_master_model_container: 12
2024-01-17 23:25:30,452:INFO:_display_container: 2
2024-01-17 23:25:30,460:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3655, verbose=0, warm_start=False)
2024-01-17 23:25:30,460:INFO:create_model() successfully completed......................................
2024-01-17 23:25:30,702:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:30,704:INFO:Creating metrics dataframe
2024-01-17 23:25:30,735:INFO:Initializing Extreme Gradient Boosting
2024-01-17 23:25:30,735:INFO:Total runtime is 0.36061683495839436 minutes
2024-01-17 23:25:30,751:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:30,751:INFO:Initializing create_model()
2024-01-17 23:25:30,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:30,751:INFO:Checking exceptions
2024-01-17 23:25:30,751:INFO:Importing libraries
2024-01-17 23:25:30,751:INFO:Copying training dataset
2024-01-17 23:25:30,759:INFO:Defining folds
2024-01-17 23:25:30,759:INFO:Declaring metric variables
2024-01-17 23:25:30,768:INFO:Importing untrained model
2024-01-17 23:25:30,777:INFO:Extreme Gradient Boosting Imported successfully
2024-01-17 23:25:30,793:INFO:Starting cross validation
2024-01-17 23:25:30,794:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:31,706:INFO:Calculating mean and std
2024-01-17 23:25:31,706:INFO:Creating metrics dataframe
2024-01-17 23:25:31,721:INFO:Uploading results into container
2024-01-17 23:25:31,721:INFO:Uploading model into container now
2024-01-17 23:25:31,725:INFO:_master_model_container: 13
2024-01-17 23:25:31,725:INFO:_display_container: 2
2024-01-17 23:25:31,728:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-17 23:25:31,729:INFO:create_model() successfully completed......................................
2024-01-17 23:25:31,957:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:31,957:INFO:Creating metrics dataframe
2024-01-17 23:25:31,987:INFO:Initializing Light Gradient Boosting Machine
2024-01-17 23:25:31,987:INFO:Total runtime is 0.38147765000661216 minutes
2024-01-17 23:25:31,997:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:31,997:INFO:Initializing create_model()
2024-01-17 23:25:31,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:31,997:INFO:Checking exceptions
2024-01-17 23:25:31,997:INFO:Importing libraries
2024-01-17 23:25:31,997:INFO:Copying training dataset
2024-01-17 23:25:32,011:INFO:Defining folds
2024-01-17 23:25:32,011:INFO:Declaring metric variables
2024-01-17 23:25:32,011:INFO:Importing untrained model
2024-01-17 23:25:32,027:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-17 23:25:32,042:INFO:Starting cross validation
2024-01-17 23:25:32,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:25:33,814:INFO:Calculating mean and std
2024-01-17 23:25:33,819:INFO:Creating metrics dataframe
2024-01-17 23:25:33,831:INFO:Uploading results into container
2024-01-17 23:25:33,832:INFO:Uploading model into container now
2024-01-17 23:25:33,833:INFO:_master_model_container: 14
2024-01-17 23:25:33,835:INFO:_display_container: 2
2024-01-17 23:25:33,836:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3655, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-17 23:25:33,836:INFO:create_model() successfully completed......................................
2024-01-17 23:25:34,009:INFO:SubProcess create_model() end ==================================
2024-01-17 23:25:34,009:INFO:Creating metrics dataframe
2024-01-17 23:25:34,031:INFO:Initializing CatBoost Classifier
2024-01-17 23:25:34,031:INFO:Total runtime is 0.4155527949333191 minutes
2024-01-17 23:25:34,036:INFO:SubProcess create_model() called ==================================
2024-01-17 23:25:34,036:INFO:Initializing create_model()
2024-01-17 23:25:34,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:25:34,036:INFO:Checking exceptions
2024-01-17 23:25:34,036:INFO:Importing libraries
2024-01-17 23:25:34,036:INFO:Copying training dataset
2024-01-17 23:25:34,039:INFO:Defining folds
2024-01-17 23:25:34,039:INFO:Declaring metric variables
2024-01-17 23:25:34,050:INFO:Importing untrained model
2024-01-17 23:25:34,055:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:25:34,071:INFO:Starting cross validation
2024-01-17 23:25:34,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:26:02,659:INFO:Calculating mean and std
2024-01-17 23:26:02,674:INFO:Creating metrics dataframe
2024-01-17 23:26:02,674:INFO:Uploading results into container
2024-01-17 23:26:02,674:INFO:Uploading model into container now
2024-01-17 23:26:02,674:INFO:_master_model_container: 15
2024-01-17 23:26:02,674:INFO:_display_container: 2
2024-01-17 23:26:02,674:INFO:<catboost.core.CatBoostClassifier object at 0x000002123B20FDD0>
2024-01-17 23:26:02,674:INFO:create_model() successfully completed......................................
2024-01-17 23:26:02,910:INFO:SubProcess create_model() end ==================================
2024-01-17 23:26:02,910:INFO:Creating metrics dataframe
2024-01-17 23:26:02,953:INFO:Initializing Dummy Classifier
2024-01-17 23:26:02,953:INFO:Total runtime is 0.8975868980089823 minutes
2024-01-17 23:26:02,963:INFO:SubProcess create_model() called ==================================
2024-01-17 23:26:02,963:INFO:Initializing create_model()
2024-01-17 23:26:02,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212391FA390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:26:02,963:INFO:Checking exceptions
2024-01-17 23:26:02,970:INFO:Importing libraries
2024-01-17 23:26:02,970:INFO:Copying training dataset
2024-01-17 23:26:02,979:INFO:Defining folds
2024-01-17 23:26:02,979:INFO:Declaring metric variables
2024-01-17 23:26:02,990:INFO:Importing untrained model
2024-01-17 23:26:02,997:INFO:Dummy Classifier Imported successfully
2024-01-17 23:26:03,009:INFO:Starting cross validation
2024-01-17 23:26:03,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:26:03,101:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,102:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,107:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,124:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,193:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,208:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,224:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,224:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,287:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,302:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:26:03,302:INFO:Calculating mean and std
2024-01-17 23:26:03,319:INFO:Creating metrics dataframe
2024-01-17 23:26:03,330:INFO:Uploading results into container
2024-01-17 23:26:03,331:INFO:Uploading model into container now
2024-01-17 23:26:03,334:INFO:_master_model_container: 16
2024-01-17 23:26:03,334:INFO:_display_container: 2
2024-01-17 23:26:03,337:INFO:DummyClassifier(constant=None, random_state=3655, strategy='prior')
2024-01-17 23:26:03,337:INFO:create_model() successfully completed......................................
2024-01-17 23:26:03,571:INFO:SubProcess create_model() end ==================================
2024-01-17 23:26:03,571:INFO:Creating metrics dataframe
2024-01-17 23:26:03,652:INFO:Initializing create_model()
2024-01-17 23:26:03,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B20FDD0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:26:03,652:INFO:Checking exceptions
2024-01-17 23:26:03,661:INFO:Importing libraries
2024-01-17 23:26:03,661:INFO:Copying training dataset
2024-01-17 23:26:03,671:INFO:Defining folds
2024-01-17 23:26:03,671:INFO:Declaring metric variables
2024-01-17 23:26:03,671:INFO:Importing untrained model
2024-01-17 23:26:03,671:INFO:Declaring custom model
2024-01-17 23:26:03,671:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:26:03,674:INFO:Cross validation set to False
2024-01-17 23:26:03,674:INFO:Fitting Model
2024-01-17 23:26:10,767:INFO:<catboost.core.CatBoostClassifier object at 0x000002123B210190>
2024-01-17 23:26:10,767:INFO:create_model() successfully completed......................................
2024-01-17 23:26:11,080:INFO:_master_model_container: 16
2024-01-17 23:26:11,080:INFO:_display_container: 2
2024-01-17 23:26:11,080:INFO:<catboost.core.CatBoostClassifier object at 0x000002123B210190>
2024-01-17 23:26:11,080:INFO:compare_models() successfully completed......................................
2024-01-17 23:26:39,837:INFO:Initializing finalize_model()
2024-01-17 23:26:39,837:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B210190>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-17 23:26:39,837:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000002123B210190>
2024-01-17 23:26:39,845:INFO:Initializing create_model()
2024-01-17 23:26:39,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B210190>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:26:39,845:INFO:Checking exceptions
2024-01-17 23:26:39,856:INFO:Importing libraries
2024-01-17 23:26:39,857:INFO:Copying training dataset
2024-01-17 23:26:39,857:INFO:Defining folds
2024-01-17 23:26:39,857:INFO:Declaring metric variables
2024-01-17 23:26:39,857:INFO:Importing untrained model
2024-01-17 23:26:39,857:INFO:Declaring custom model
2024-01-17 23:26:39,857:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:26:39,861:INFO:Cross validation set to False
2024-01-17 23:26:39,861:INFO:Fitting Model
2024-01-17 23:26:44,913:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002123B2BCD50>)],
         verbose=False)
2024-01-17 23:26:44,913:INFO:create_model() successfully completed......................................
2024-01-17 23:26:45,161:INFO:_master_model_container: 16
2024-01-17 23:26:45,161:INFO:_display_container: 2
2024-01-17 23:26:45,182:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002123B2BCD50>)],
         verbose=False)
2024-01-17 23:26:45,182:INFO:finalize_model() successfully completed......................................
2024-01-17 23:26:57,841:INFO:Initializing evaluate_model()
2024-01-17 23:26:57,841:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B210190>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-17 23:26:58,226:INFO:Initializing plot_model()
2024-01-17 23:26:58,226:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B210190>, plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 23:26:58,226:INFO:Checking exceptions
2024-01-17 23:26:58,234:INFO:Preloading libraries
2024-01-17 23:26:58,241:INFO:Copying training dataset
2024-01-17 23:26:58,241:INFO:Plot type: pipeline
2024-01-17 23:27:00,185:INFO:Visual Rendered Successfully
2024-01-17 23:27:00,450:INFO:plot_model() successfully completed......................................
2024-01-17 23:27:08,823:INFO:Initializing predict_model()
2024-01-17 23:27:08,823:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B210190>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002123B8518A0>)
2024-01-17 23:27:08,823:INFO:Checking exceptions
2024-01-17 23:27:08,823:INFO:Preloading libraries
2024-01-17 23:27:13,071:INFO:Initializing plot_model()
2024-01-17 23:27:13,071:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B210190>, plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 23:27:13,071:INFO:Checking exceptions
2024-01-17 23:27:13,079:INFO:Preloading libraries
2024-01-17 23:27:13,080:INFO:Copying training dataset
2024-01-17 23:27:13,080:INFO:Plot type: feature_all
2024-01-17 23:27:13,127:WARNING:No coef_ found. Trying feature_importances_
2024-01-17 23:27:13,677:INFO:Visual Rendered Successfully
2024-01-17 23:27:13,850:INFO:plot_model() successfully completed......................................
2024-01-17 23:28:06,766:INFO:Initializing predict_model()
2024-01-17 23:28:06,766:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B210190>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002123B4AFF60>)
2024-01-17 23:28:06,766:INFO:Checking exceptions
2024-01-17 23:28:06,766:INFO:Preloading libraries
2024-01-17 23:28:06,766:INFO:Set up data.
2024-01-17 23:28:06,782:INFO:Set up index.
2024-01-17 23:29:22,829:INFO:Initializing predict_model()
2024-01-17 23:29:22,829:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021227CCD8D0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B210190>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021241CA76A0>)
2024-01-17 23:29:22,829:INFO:Checking exceptions
2024-01-17 23:29:22,829:INFO:Preloading libraries
2024-01-17 23:29:22,834:INFO:Set up data.
2024-01-17 23:29:22,841:INFO:Set up index.
2024-01-17 23:44:54,252:INFO:PyCaret ClassificationExperiment
2024-01-17 23:44:54,252:INFO:Logging name: clf-default-name
2024-01-17 23:44:54,252:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-17 23:44:54,252:INFO:version 3.2.0
2024-01-17 23:44:54,252:INFO:Initializing setup()
2024-01-17 23:44:54,252:INFO:self.USI: 7535
2024-01-17 23:44:54,252:INFO:self._variable_keys: {'seed', 'is_multiclass', 'target_param', 'y_test', 'data', 'exp_id', 'memory', 'gpu_n_jobs_param', 'gpu_param', 'X_train', '_available_plots', 'n_jobs_param', 'pipeline', 'fold_generator', 'X_test', 'X', 'fold_shuffle_param', '_ml_usecase', 'y', 'html_param', 'fix_imbalance', 'logging_param', 'log_plots_param', 'idx', 'y_train', 'fold_groups_param', 'exp_name_log', 'USI'}
2024-01-17 23:44:54,252:INFO:Checking environment
2024-01-17 23:44:54,252:INFO:python_version: 3.11.5
2024-01-17 23:44:54,252:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 23:44:54,252:INFO:machine: AMD64
2024-01-17 23:44:54,252:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 23:44:54,252:INFO:Memory: svmem(total=8361132032, available=1739935744, percent=79.2, used=6621196288, free=1739935744)
2024-01-17 23:44:54,252:INFO:Physical Core: 2
2024-01-17 23:44:54,252:INFO:Logical Core: 4
2024-01-17 23:44:54,262:INFO:Checking libraries
2024-01-17 23:44:54,263:INFO:System:
2024-01-17 23:44:54,263:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 23:44:54,264:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 23:44:54,264:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 23:44:54,264:INFO:PyCaret required dependencies:
2024-01-17 23:44:54,264:INFO:                 pip: 23.2.1
2024-01-17 23:44:54,264:INFO:          setuptools: 68.0.0
2024-01-17 23:44:54,264:INFO:             pycaret: 3.2.0
2024-01-17 23:44:54,264:INFO:             IPython: 8.15.0
2024-01-17 23:44:54,264:INFO:          ipywidgets: 8.0.4
2024-01-17 23:44:54,264:INFO:                tqdm: 4.65.0
2024-01-17 23:44:54,264:INFO:               numpy: 1.24.3
2024-01-17 23:44:54,264:INFO:              pandas: 1.5.3
2024-01-17 23:44:54,264:INFO:              jinja2: 3.1.2
2024-01-17 23:44:54,264:INFO:               scipy: 1.10.1
2024-01-17 23:44:54,264:INFO:              joblib: 1.2.0
2024-01-17 23:44:54,264:INFO:             sklearn: 1.2.2
2024-01-17 23:44:54,264:INFO:                pyod: 1.1.2
2024-01-17 23:44:54,264:INFO:            imblearn: 0.10.1
2024-01-17 23:44:54,264:INFO:   category_encoders: 2.6.3
2024-01-17 23:44:54,264:INFO:            lightgbm: 4.2.0
2024-01-17 23:44:54,264:INFO:               numba: 0.57.1
2024-01-17 23:44:54,264:INFO:            requests: 2.31.0
2024-01-17 23:44:54,264:INFO:          matplotlib: 3.6.0
2024-01-17 23:44:54,264:INFO:          scikitplot: 0.3.7
2024-01-17 23:44:54,267:INFO:         yellowbrick: 1.5
2024-01-17 23:44:54,267:INFO:              plotly: 5.9.0
2024-01-17 23:44:54,267:INFO:    plotly-resampler: Not installed
2024-01-17 23:44:54,267:INFO:             kaleido: 0.2.1
2024-01-17 23:44:54,267:INFO:           schemdraw: 0.15
2024-01-17 23:44:54,267:INFO:         statsmodels: 0.14.0
2024-01-17 23:44:54,267:INFO:              sktime: 0.21.1
2024-01-17 23:44:54,267:INFO:               tbats: 1.1.3
2024-01-17 23:44:54,267:INFO:            pmdarima: 2.0.4
2024-01-17 23:44:54,267:INFO:              psutil: 5.9.0
2024-01-17 23:44:54,267:INFO:          markupsafe: 2.1.1
2024-01-17 23:44:54,267:INFO:             pickle5: Not installed
2024-01-17 23:44:54,267:INFO:         cloudpickle: 2.2.1
2024-01-17 23:44:54,267:INFO:         deprecation: 2.1.0
2024-01-17 23:44:54,267:INFO:              xxhash: 2.0.2
2024-01-17 23:44:54,267:INFO:           wurlitzer: Not installed
2024-01-17 23:44:54,267:INFO:PyCaret optional dependencies:
2024-01-17 23:44:54,267:INFO:                shap: Not installed
2024-01-17 23:44:54,267:INFO:           interpret: Not installed
2024-01-17 23:44:54,267:INFO:                umap: Not installed
2024-01-17 23:44:54,267:INFO:     ydata_profiling: Not installed
2024-01-17 23:44:54,267:INFO:  explainerdashboard: Not installed
2024-01-17 23:44:54,267:INFO:             autoviz: Not installed
2024-01-17 23:44:54,267:INFO:           fairlearn: Not installed
2024-01-17 23:44:54,267:INFO:          deepchecks: Not installed
2024-01-17 23:44:54,267:INFO:             xgboost: 2.0.3
2024-01-17 23:44:54,267:INFO:            catboost: 1.2.2
2024-01-17 23:44:54,267:INFO:              kmodes: Not installed
2024-01-17 23:44:54,267:INFO:             mlxtend: Not installed
2024-01-17 23:44:54,267:INFO:       statsforecast: Not installed
2024-01-17 23:44:54,267:INFO:        tune_sklearn: Not installed
2024-01-17 23:44:54,271:INFO:                 ray: Not installed
2024-01-17 23:44:54,271:INFO:            hyperopt: Not installed
2024-01-17 23:44:54,271:INFO:              optuna: 3.5.0
2024-01-17 23:44:54,271:INFO:               skopt: Not installed
2024-01-17 23:44:54,271:INFO:              mlflow: Not installed
2024-01-17 23:44:54,271:INFO:              gradio: Not installed
2024-01-17 23:44:54,271:INFO:             fastapi: Not installed
2024-01-17 23:44:54,271:INFO:             uvicorn: Not installed
2024-01-17 23:44:54,271:INFO:              m2cgen: Not installed
2024-01-17 23:44:54,271:INFO:           evidently: Not installed
2024-01-17 23:44:54,271:INFO:               fugue: Not installed
2024-01-17 23:44:54,271:INFO:           streamlit: Not installed
2024-01-17 23:44:54,271:INFO:             prophet: Not installed
2024-01-17 23:44:54,271:INFO:None
2024-01-17 23:44:54,271:INFO:Set up data.
2024-01-17 23:44:54,277:INFO:Set up folding strategy.
2024-01-17 23:44:54,277:INFO:Set up train/test split.
2024-01-17 23:44:54,284:INFO:Set up index.
2024-01-17 23:44:54,284:INFO:Assigning column types.
2024-01-17 23:44:54,312:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-17 23:44:54,460:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:44:54,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:44:54,555:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:44:54,555:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:44:54,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:44:54,713:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:44:54,807:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:44:54,807:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:44:54,822:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-17 23:44:54,966:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:44:55,059:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:44:55,067:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:44:55,218:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:44:55,320:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:44:55,320:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:44:55,320:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-17 23:44:55,525:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:44:55,534:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:44:55,780:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:44:55,780:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:44:55,796:INFO:Preparing preprocessing pipeline...
2024-01-17 23:44:55,796:INFO:Set up simple imputation.
2024-01-17 23:44:55,850:INFO:Finished creating preprocessing pipeline.
2024-01-17 23:44:55,867:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-01-17 23:44:55,867:INFO:Creating final display dataframe.
2024-01-17 23:44:56,041:INFO:Setup _display_container:                     Description             Value
0                    Session id              3383
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 11)
5   Transformed train set shape         (623, 11)
6    Transformed test set shape         (268, 11)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7535
2024-01-17 23:44:56,316:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:44:56,317:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:44:56,580:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:44:56,580:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:44:56,596:INFO:setup() successfully completed in 2.36s...............
2024-01-17 23:44:59,686:INFO:Initializing compare_models()
2024-01-17 23:44:59,686:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-17 23:44:59,686:INFO:Checking exceptions
2024-01-17 23:44:59,701:INFO:Preparing display monitor
2024-01-17 23:44:59,812:INFO:Initializing Logistic Regression
2024-01-17 23:44:59,813:INFO:Total runtime is 1.677274703979492e-05 minutes
2024-01-17 23:44:59,820:INFO:SubProcess create_model() called ==================================
2024-01-17 23:44:59,822:INFO:Initializing create_model()
2024-01-17 23:44:59,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:44:59,822:INFO:Checking exceptions
2024-01-17 23:44:59,822:INFO:Importing libraries
2024-01-17 23:44:59,823:INFO:Copying training dataset
2024-01-17 23:44:59,833:INFO:Defining folds
2024-01-17 23:44:59,833:INFO:Declaring metric variables
2024-01-17 23:44:59,836:INFO:Importing untrained model
2024-01-17 23:44:59,852:INFO:Logistic Regression Imported successfully
2024-01-17 23:44:59,870:INFO:Starting cross validation
2024-01-17 23:44:59,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:05,902:INFO:Calculating mean and std
2024-01-17 23:45:05,908:INFO:Creating metrics dataframe
2024-01-17 23:45:05,909:INFO:Uploading results into container
2024-01-17 23:45:05,909:INFO:Uploading model into container now
2024-01-17 23:45:05,924:INFO:_master_model_container: 1
2024-01-17 23:45:05,924:INFO:_display_container: 2
2024-01-17 23:45:05,925:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3383, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 23:45:05,925:INFO:create_model() successfully completed......................................
2024-01-17 23:45:06,267:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:06,267:INFO:Creating metrics dataframe
2024-01-17 23:45:06,299:INFO:Initializing K Neighbors Classifier
2024-01-17 23:45:06,299:INFO:Total runtime is 0.10811492999394734 minutes
2024-01-17 23:45:06,299:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:06,313:INFO:Initializing create_model()
2024-01-17 23:45:06,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:06,313:INFO:Checking exceptions
2024-01-17 23:45:06,313:INFO:Importing libraries
2024-01-17 23:45:06,313:INFO:Copying training dataset
2024-01-17 23:45:06,320:INFO:Defining folds
2024-01-17 23:45:06,320:INFO:Declaring metric variables
2024-01-17 23:45:06,331:INFO:Importing untrained model
2024-01-17 23:45:06,343:INFO:K Neighbors Classifier Imported successfully
2024-01-17 23:45:06,362:INFO:Starting cross validation
2024-01-17 23:45:06,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:06,670:INFO:Calculating mean and std
2024-01-17 23:45:06,671:INFO:Creating metrics dataframe
2024-01-17 23:45:06,671:INFO:Uploading results into container
2024-01-17 23:45:06,671:INFO:Uploading model into container now
2024-01-17 23:45:06,671:INFO:_master_model_container: 2
2024-01-17 23:45:06,671:INFO:_display_container: 2
2024-01-17 23:45:06,671:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-17 23:45:06,671:INFO:create_model() successfully completed......................................
2024-01-17 23:45:06,955:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:06,955:INFO:Creating metrics dataframe
2024-01-17 23:45:06,993:INFO:Initializing Naive Bayes
2024-01-17 23:45:06,998:INFO:Total runtime is 0.1197698950767517 minutes
2024-01-17 23:45:07,008:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:07,008:INFO:Initializing create_model()
2024-01-17 23:45:07,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:07,008:INFO:Checking exceptions
2024-01-17 23:45:07,008:INFO:Importing libraries
2024-01-17 23:45:07,008:INFO:Copying training dataset
2024-01-17 23:45:07,017:INFO:Defining folds
2024-01-17 23:45:07,017:INFO:Declaring metric variables
2024-01-17 23:45:07,033:INFO:Importing untrained model
2024-01-17 23:45:07,040:INFO:Naive Bayes Imported successfully
2024-01-17 23:45:07,059:INFO:Starting cross validation
2024-01-17 23:45:07,060:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:07,215:INFO:Calculating mean and std
2024-01-17 23:45:07,215:INFO:Creating metrics dataframe
2024-01-17 23:45:07,234:INFO:Uploading results into container
2024-01-17 23:45:07,238:INFO:Uploading model into container now
2024-01-17 23:45:07,239:INFO:_master_model_container: 3
2024-01-17 23:45:07,239:INFO:_display_container: 2
2024-01-17 23:45:07,240:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-17 23:45:07,240:INFO:create_model() successfully completed......................................
2024-01-17 23:45:07,502:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:07,502:INFO:Creating metrics dataframe
2024-01-17 23:45:07,548:INFO:Initializing Decision Tree Classifier
2024-01-17 23:45:07,549:INFO:Total runtime is 0.12896004915237427 minutes
2024-01-17 23:45:07,559:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:07,560:INFO:Initializing create_model()
2024-01-17 23:45:07,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:07,560:INFO:Checking exceptions
2024-01-17 23:45:07,560:INFO:Importing libraries
2024-01-17 23:45:07,560:INFO:Copying training dataset
2024-01-17 23:45:07,570:INFO:Defining folds
2024-01-17 23:45:07,570:INFO:Declaring metric variables
2024-01-17 23:45:07,581:INFO:Importing untrained model
2024-01-17 23:45:07,591:INFO:Decision Tree Classifier Imported successfully
2024-01-17 23:45:07,609:INFO:Starting cross validation
2024-01-17 23:45:07,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:07,767:INFO:Calculating mean and std
2024-01-17 23:45:07,772:INFO:Creating metrics dataframe
2024-01-17 23:45:07,772:INFO:Uploading results into container
2024-01-17 23:45:07,772:INFO:Uploading model into container now
2024-01-17 23:45:07,772:INFO:_master_model_container: 4
2024-01-17 23:45:07,772:INFO:_display_container: 2
2024-01-17 23:45:07,772:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3383, splitter='best')
2024-01-17 23:45:07,772:INFO:create_model() successfully completed......................................
2024-01-17 23:45:08,053:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:08,053:INFO:Creating metrics dataframe
2024-01-17 23:45:08,084:INFO:Initializing SVM - Linear Kernel
2024-01-17 23:45:08,084:INFO:Total runtime is 0.13787129720052083 minutes
2024-01-17 23:45:08,100:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:08,100:INFO:Initializing create_model()
2024-01-17 23:45:08,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:08,100:INFO:Checking exceptions
2024-01-17 23:45:08,100:INFO:Importing libraries
2024-01-17 23:45:08,100:INFO:Copying training dataset
2024-01-17 23:45:08,116:INFO:Defining folds
2024-01-17 23:45:08,116:INFO:Declaring metric variables
2024-01-17 23:45:08,129:INFO:Importing untrained model
2024-01-17 23:45:08,140:INFO:SVM - Linear Kernel Imported successfully
2024-01-17 23:45:08,163:INFO:Starting cross validation
2024-01-17 23:45:08,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:08,252:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,277:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,284:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,308:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,375:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,401:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,401:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,422:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,474:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,485:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:45:08,501:INFO:Calculating mean and std
2024-01-17 23:45:08,501:INFO:Creating metrics dataframe
2024-01-17 23:45:08,524:INFO:Uploading results into container
2024-01-17 23:45:08,527:INFO:Uploading model into container now
2024-01-17 23:45:08,528:INFO:_master_model_container: 5
2024-01-17 23:45:08,528:INFO:_display_container: 2
2024-01-17 23:45:08,528:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3383, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-17 23:45:08,528:INFO:create_model() successfully completed......................................
2024-01-17 23:45:08,805:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:08,805:INFO:Creating metrics dataframe
2024-01-17 23:45:08,836:INFO:Initializing Ridge Classifier
2024-01-17 23:45:08,836:INFO:Total runtime is 0.15040203332901 minutes
2024-01-17 23:45:08,844:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:08,844:INFO:Initializing create_model()
2024-01-17 23:45:08,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:08,844:INFO:Checking exceptions
2024-01-17 23:45:08,844:INFO:Importing libraries
2024-01-17 23:45:08,844:INFO:Copying training dataset
2024-01-17 23:45:08,852:INFO:Defining folds
2024-01-17 23:45:08,852:INFO:Declaring metric variables
2024-01-17 23:45:08,866:INFO:Importing untrained model
2024-01-17 23:45:08,872:INFO:Ridge Classifier Imported successfully
2024-01-17 23:45:08,888:INFO:Starting cross validation
2024-01-17 23:45:08,889:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:08,964:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:45:08,967:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:45:08,980:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:45:08,988:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:45:09,045:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:45:09,053:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:45:09,122:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:45:09,342:INFO:Calculating mean and std
2024-01-17 23:45:09,346:INFO:Creating metrics dataframe
2024-01-17 23:45:09,357:INFO:Uploading results into container
2024-01-17 23:45:09,360:INFO:Uploading model into container now
2024-01-17 23:45:09,360:INFO:_master_model_container: 6
2024-01-17 23:45:09,360:INFO:_display_container: 2
2024-01-17 23:45:09,360:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3383, solver='auto',
                tol=0.0001)
2024-01-17 23:45:09,360:INFO:create_model() successfully completed......................................
2024-01-17 23:45:09,685:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:09,685:INFO:Creating metrics dataframe
2024-01-17 23:45:09,716:INFO:Initializing Random Forest Classifier
2024-01-17 23:45:09,716:INFO:Total runtime is 0.1650769551595052 minutes
2024-01-17 23:45:09,733:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:09,733:INFO:Initializing create_model()
2024-01-17 23:45:09,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:09,733:INFO:Checking exceptions
2024-01-17 23:45:09,733:INFO:Importing libraries
2024-01-17 23:45:09,733:INFO:Copying training dataset
2024-01-17 23:45:09,736:INFO:Defining folds
2024-01-17 23:45:09,736:INFO:Declaring metric variables
2024-01-17 23:45:09,759:INFO:Importing untrained model
2024-01-17 23:45:09,767:INFO:Random Forest Classifier Imported successfully
2024-01-17 23:45:09,783:INFO:Starting cross validation
2024-01-17 23:45:09,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:12,937:INFO:Calculating mean and std
2024-01-17 23:45:12,937:INFO:Creating metrics dataframe
2024-01-17 23:45:12,953:INFO:Uploading results into container
2024-01-17 23:45:12,953:INFO:Uploading model into container now
2024-01-17 23:45:12,967:INFO:_master_model_container: 7
2024-01-17 23:45:12,967:INFO:_display_container: 2
2024-01-17 23:45:12,967:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3383, verbose=0, warm_start=False)
2024-01-17 23:45:12,967:INFO:create_model() successfully completed......................................
2024-01-17 23:45:13,301:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:13,301:INFO:Creating metrics dataframe
2024-01-17 23:45:13,333:INFO:Initializing Quadratic Discriminant Analysis
2024-01-17 23:45:13,333:INFO:Total runtime is 0.22535374561945598 minutes
2024-01-17 23:45:13,340:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:13,340:INFO:Initializing create_model()
2024-01-17 23:45:13,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:13,340:INFO:Checking exceptions
2024-01-17 23:45:13,340:INFO:Importing libraries
2024-01-17 23:45:13,340:INFO:Copying training dataset
2024-01-17 23:45:13,350:INFO:Defining folds
2024-01-17 23:45:13,350:INFO:Declaring metric variables
2024-01-17 23:45:13,364:INFO:Importing untrained model
2024-01-17 23:45:13,369:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-17 23:45:13,389:INFO:Starting cross validation
2024-01-17 23:45:13,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:13,450:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,450:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,474:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,489:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,504:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:13,574:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,574:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,583:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,591:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,639:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:13,654:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:13,674:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,686:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:45:13,733:INFO:Calculating mean and std
2024-01-17 23:45:13,733:INFO:Creating metrics dataframe
2024-01-17 23:45:13,750:INFO:Uploading results into container
2024-01-17 23:45:13,750:INFO:Uploading model into container now
2024-01-17 23:45:13,750:INFO:_master_model_container: 8
2024-01-17 23:45:13,750:INFO:_display_container: 2
2024-01-17 23:45:13,750:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-17 23:45:13,750:INFO:create_model() successfully completed......................................
2024-01-17 23:45:14,082:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:14,082:INFO:Creating metrics dataframe
2024-01-17 23:45:14,114:INFO:Initializing Ada Boost Classifier
2024-01-17 23:45:14,114:INFO:Total runtime is 0.23836750586827596 minutes
2024-01-17 23:45:14,138:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:14,138:INFO:Initializing create_model()
2024-01-17 23:45:14,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:14,138:INFO:Checking exceptions
2024-01-17 23:45:14,138:INFO:Importing libraries
2024-01-17 23:45:14,138:INFO:Copying training dataset
2024-01-17 23:45:14,150:INFO:Defining folds
2024-01-17 23:45:14,150:INFO:Declaring metric variables
2024-01-17 23:45:14,166:INFO:Importing untrained model
2024-01-17 23:45:14,174:INFO:Ada Boost Classifier Imported successfully
2024-01-17 23:45:14,190:INFO:Starting cross validation
2024-01-17 23:45:14,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:15,629:INFO:Calculating mean and std
2024-01-17 23:45:15,629:INFO:Creating metrics dataframe
2024-01-17 23:45:15,645:INFO:Uploading results into container
2024-01-17 23:45:15,653:INFO:Uploading model into container now
2024-01-17 23:45:15,655:INFO:_master_model_container: 9
2024-01-17 23:45:15,656:INFO:_display_container: 2
2024-01-17 23:45:15,656:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3383)
2024-01-17 23:45:15,656:INFO:create_model() successfully completed......................................
2024-01-17 23:45:15,984:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:16,522:INFO:Creating metrics dataframe
2024-01-17 23:45:16,553:INFO:Initializing Gradient Boosting Classifier
2024-01-17 23:45:16,553:INFO:Total runtime is 0.2790289282798767 minutes
2024-01-17 23:45:16,569:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:16,572:INFO:Initializing create_model()
2024-01-17 23:45:16,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:16,572:INFO:Checking exceptions
2024-01-17 23:45:16,572:INFO:Importing libraries
2024-01-17 23:45:16,572:INFO:Copying training dataset
2024-01-17 23:45:16,577:INFO:Defining folds
2024-01-17 23:45:16,585:INFO:Declaring metric variables
2024-01-17 23:45:16,589:INFO:Importing untrained model
2024-01-17 23:45:16,600:INFO:Gradient Boosting Classifier Imported successfully
2024-01-17 23:45:16,616:INFO:Starting cross validation
2024-01-17 23:45:16,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:18,230:INFO:Calculating mean and std
2024-01-17 23:45:18,245:INFO:Creating metrics dataframe
2024-01-17 23:45:18,245:INFO:Uploading results into container
2024-01-17 23:45:18,245:INFO:Uploading model into container now
2024-01-17 23:45:18,262:INFO:_master_model_container: 10
2024-01-17 23:45:18,262:INFO:_display_container: 2
2024-01-17 23:45:18,262:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3383, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 23:45:18,264:INFO:create_model() successfully completed......................................
2024-01-17 23:45:18,584:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:18,584:INFO:Creating metrics dataframe
2024-01-17 23:45:18,615:INFO:Initializing Linear Discriminant Analysis
2024-01-17 23:45:18,615:INFO:Total runtime is 0.3133878151575724 minutes
2024-01-17 23:45:18,632:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:18,632:INFO:Initializing create_model()
2024-01-17 23:45:18,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:18,632:INFO:Checking exceptions
2024-01-17 23:45:18,639:INFO:Importing libraries
2024-01-17 23:45:18,639:INFO:Copying training dataset
2024-01-17 23:45:18,650:INFO:Defining folds
2024-01-17 23:45:18,650:INFO:Declaring metric variables
2024-01-17 23:45:18,656:INFO:Importing untrained model
2024-01-17 23:45:18,669:INFO:Linear Discriminant Analysis Imported successfully
2024-01-17 23:45:18,683:INFO:Starting cross validation
2024-01-17 23:45:18,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:19,016:INFO:Calculating mean and std
2024-01-17 23:45:19,016:INFO:Creating metrics dataframe
2024-01-17 23:45:19,038:INFO:Uploading results into container
2024-01-17 23:45:19,045:INFO:Uploading model into container now
2024-01-17 23:45:19,049:INFO:_master_model_container: 11
2024-01-17 23:45:19,049:INFO:_display_container: 2
2024-01-17 23:45:19,049:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-17 23:45:19,049:INFO:create_model() successfully completed......................................
2024-01-17 23:45:19,382:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:19,382:INFO:Creating metrics dataframe
2024-01-17 23:45:19,415:INFO:Initializing Extra Trees Classifier
2024-01-17 23:45:19,415:INFO:Total runtime is 0.32672861019770305 minutes
2024-01-17 23:45:19,430:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:19,438:INFO:Initializing create_model()
2024-01-17 23:45:19,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:19,438:INFO:Checking exceptions
2024-01-17 23:45:19,438:INFO:Importing libraries
2024-01-17 23:45:19,438:INFO:Copying training dataset
2024-01-17 23:45:19,446:INFO:Defining folds
2024-01-17 23:45:19,446:INFO:Declaring metric variables
2024-01-17 23:45:19,454:INFO:Importing untrained model
2024-01-17 23:45:19,469:INFO:Extra Trees Classifier Imported successfully
2024-01-17 23:45:19,486:INFO:Starting cross validation
2024-01-17 23:45:19,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:22,219:INFO:Calculating mean and std
2024-01-17 23:45:22,219:INFO:Creating metrics dataframe
2024-01-17 23:45:22,237:INFO:Uploading results into container
2024-01-17 23:45:22,237:INFO:Uploading model into container now
2024-01-17 23:45:22,237:INFO:_master_model_container: 12
2024-01-17 23:45:22,237:INFO:_display_container: 2
2024-01-17 23:45:22,237:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3383, verbose=0, warm_start=False)
2024-01-17 23:45:22,237:INFO:create_model() successfully completed......................................
2024-01-17 23:45:22,520:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:22,520:INFO:Creating metrics dataframe
2024-01-17 23:45:22,536:INFO:Initializing Extreme Gradient Boosting
2024-01-17 23:45:22,536:INFO:Total runtime is 0.3787332534790039 minutes
2024-01-17 23:45:22,549:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:22,549:INFO:Initializing create_model()
2024-01-17 23:45:22,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:22,551:INFO:Checking exceptions
2024-01-17 23:45:22,551:INFO:Importing libraries
2024-01-17 23:45:22,551:INFO:Copying training dataset
2024-01-17 23:45:22,560:INFO:Defining folds
2024-01-17 23:45:22,560:INFO:Declaring metric variables
2024-01-17 23:45:22,570:INFO:Importing untrained model
2024-01-17 23:45:22,585:INFO:Extreme Gradient Boosting Imported successfully
2024-01-17 23:45:22,599:INFO:Starting cross validation
2024-01-17 23:45:22,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:23,465:INFO:Calculating mean and std
2024-01-17 23:45:23,465:INFO:Creating metrics dataframe
2024-01-17 23:45:23,488:INFO:Uploading results into container
2024-01-17 23:45:23,490:INFO:Uploading model into container now
2024-01-17 23:45:23,490:INFO:_master_model_container: 13
2024-01-17 23:45:23,490:INFO:_display_container: 2
2024-01-17 23:45:23,490:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-17 23:45:23,490:INFO:create_model() successfully completed......................................
2024-01-17 23:45:23,769:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:23,769:INFO:Creating metrics dataframe
2024-01-17 23:45:23,816:INFO:Initializing Light Gradient Boosting Machine
2024-01-17 23:45:23,816:INFO:Total runtime is 0.4000711560249328 minutes
2024-01-17 23:45:23,826:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:23,826:INFO:Initializing create_model()
2024-01-17 23:45:23,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:23,826:INFO:Checking exceptions
2024-01-17 23:45:23,826:INFO:Importing libraries
2024-01-17 23:45:23,826:INFO:Copying training dataset
2024-01-17 23:45:23,834:INFO:Defining folds
2024-01-17 23:45:23,834:INFO:Declaring metric variables
2024-01-17 23:45:23,854:INFO:Importing untrained model
2024-01-17 23:45:23,869:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-17 23:45:23,882:INFO:Starting cross validation
2024-01-17 23:45:23,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:25,478:INFO:Calculating mean and std
2024-01-17 23:45:25,478:INFO:Creating metrics dataframe
2024-01-17 23:45:25,499:INFO:Uploading results into container
2024-01-17 23:45:25,503:INFO:Uploading model into container now
2024-01-17 23:45:25,503:INFO:_master_model_container: 14
2024-01-17 23:45:25,503:INFO:_display_container: 2
2024-01-17 23:45:25,503:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3383, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-17 23:45:25,503:INFO:create_model() successfully completed......................................
2024-01-17 23:45:25,864:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:25,864:INFO:Creating metrics dataframe
2024-01-17 23:45:25,911:INFO:Initializing CatBoost Classifier
2024-01-17 23:45:25,911:INFO:Total runtime is 0.4349939664204915 minutes
2024-01-17 23:45:25,927:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:25,927:INFO:Initializing create_model()
2024-01-17 23:45:25,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:25,927:INFO:Checking exceptions
2024-01-17 23:45:25,929:INFO:Importing libraries
2024-01-17 23:45:25,929:INFO:Copying training dataset
2024-01-17 23:45:25,935:INFO:Defining folds
2024-01-17 23:45:25,935:INFO:Declaring metric variables
2024-01-17 23:45:25,951:INFO:Importing untrained model
2024-01-17 23:45:25,966:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:45:25,990:INFO:Starting cross validation
2024-01-17 23:45:25,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:51,349:INFO:Calculating mean and std
2024-01-17 23:45:51,349:INFO:Creating metrics dataframe
2024-01-17 23:45:51,365:INFO:Uploading results into container
2024-01-17 23:45:51,365:INFO:Uploading model into container now
2024-01-17 23:45:51,365:INFO:_master_model_container: 15
2024-01-17 23:45:51,365:INFO:_display_container: 2
2024-01-17 23:45:51,365:INFO:<catboost.core.CatBoostClassifier object at 0x000002123B2F8E90>
2024-01-17 23:45:51,365:INFO:create_model() successfully completed......................................
2024-01-17 23:45:51,720:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:51,720:INFO:Creating metrics dataframe
2024-01-17 23:45:51,766:INFO:Initializing Dummy Classifier
2024-01-17 23:45:51,767:INFO:Total runtime is 0.865921417872111 minutes
2024-01-17 23:45:51,773:INFO:SubProcess create_model() called ==================================
2024-01-17 23:45:51,773:INFO:Initializing create_model()
2024-01-17 23:45:51,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241F0BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:51,773:INFO:Checking exceptions
2024-01-17 23:45:51,773:INFO:Importing libraries
2024-01-17 23:45:51,773:INFO:Copying training dataset
2024-01-17 23:45:51,789:INFO:Defining folds
2024-01-17 23:45:51,789:INFO:Declaring metric variables
2024-01-17 23:45:51,799:INFO:Importing untrained model
2024-01-17 23:45:51,806:INFO:Dummy Classifier Imported successfully
2024-01-17 23:45:51,823:INFO:Starting cross validation
2024-01-17 23:45:51,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:45:51,915:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:51,915:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:51,923:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:51,980:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:51,989:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:51,989:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:52,051:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:52,066:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:52,082:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:45:52,098:INFO:Calculating mean and std
2024-01-17 23:45:52,098:INFO:Creating metrics dataframe
2024-01-17 23:45:52,113:INFO:Uploading results into container
2024-01-17 23:45:52,113:INFO:Uploading model into container now
2024-01-17 23:45:52,113:INFO:_master_model_container: 16
2024-01-17 23:45:52,113:INFO:_display_container: 2
2024-01-17 23:45:52,113:INFO:DummyClassifier(constant=None, random_state=3383, strategy='prior')
2024-01-17 23:45:52,113:INFO:create_model() successfully completed......................................
2024-01-17 23:45:52,466:INFO:SubProcess create_model() end ==================================
2024-01-17 23:45:52,466:INFO:Creating metrics dataframe
2024-01-17 23:45:52,533:INFO:Initializing create_model()
2024-01-17 23:45:52,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=<catboost.core.CatBoostClassifier object at 0x000002123B2F8E90>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:45:52,533:INFO:Checking exceptions
2024-01-17 23:45:52,543:INFO:Importing libraries
2024-01-17 23:45:52,543:INFO:Copying training dataset
2024-01-17 23:45:52,548:INFO:Defining folds
2024-01-17 23:45:52,548:INFO:Declaring metric variables
2024-01-17 23:45:52,548:INFO:Importing untrained model
2024-01-17 23:45:52,548:INFO:Declaring custom model
2024-01-17 23:45:52,548:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:45:52,548:INFO:Cross validation set to False
2024-01-17 23:45:52,548:INFO:Fitting Model
2024-01-17 23:45:58,488:INFO:<catboost.core.CatBoostClassifier object at 0x0000021241B888D0>
2024-01-17 23:45:58,488:INFO:create_model() successfully completed......................................
2024-01-17 23:45:58,898:INFO:_master_model_container: 16
2024-01-17 23:45:58,898:INFO:_display_container: 2
2024-01-17 23:45:58,898:INFO:<catboost.core.CatBoostClassifier object at 0x0000021241B888D0>
2024-01-17 23:45:58,898:INFO:compare_models() successfully completed......................................
2024-01-17 23:46:13,995:INFO:Initializing finalize_model()
2024-01-17 23:46:13,995:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021241B888D0>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-17 23:46:13,995:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x0000021241B888D0>
2024-01-17 23:46:14,001:INFO:Initializing create_model()
2024-01-17 23:46:14,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021241B888D0>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:46:14,001:INFO:Checking exceptions
2024-01-17 23:46:14,001:INFO:Importing libraries
2024-01-17 23:46:14,014:INFO:Copying training dataset
2024-01-17 23:46:14,014:INFO:Defining folds
2024-01-17 23:46:14,014:INFO:Declaring metric variables
2024-01-17 23:46:14,014:INFO:Importing untrained model
2024-01-17 23:46:14,014:INFO:Declaring custom model
2024-01-17 23:46:14,014:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:46:14,014:INFO:Cross validation set to False
2024-01-17 23:46:14,014:INFO:Fitting Model
2024-01-17 23:46:21,872:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x0000021241F19D50>)],
         verbose=False)
2024-01-17 23:46:21,872:INFO:create_model() successfully completed......................................
2024-01-17 23:46:22,211:INFO:_master_model_container: 16
2024-01-17 23:46:22,211:INFO:_display_container: 2
2024-01-17 23:46:22,226:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x0000021241F19D50>)],
         verbose=False)
2024-01-17 23:46:22,226:INFO:finalize_model() successfully completed......................................
2024-01-17 23:46:22,587:INFO:Initializing evaluate_model()
2024-01-17 23:46:22,592:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021241B888D0>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-17 23:46:22,615:INFO:Initializing plot_model()
2024-01-17 23:46:22,616:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021241B888D0>, plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 23:46:22,616:INFO:Checking exceptions
2024-01-17 23:46:22,618:INFO:Preloading libraries
2024-01-17 23:46:22,621:INFO:Copying training dataset
2024-01-17 23:46:22,621:INFO:Plot type: pipeline
2024-01-17 23:46:23,015:INFO:Visual Rendered Successfully
2024-01-17 23:46:23,345:INFO:plot_model() successfully completed......................................
2024-01-17 23:46:23,372:INFO:Initializing predict_model()
2024-01-17 23:46:23,372:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021241B888D0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000212421E2F20>)
2024-01-17 23:46:23,372:INFO:Checking exceptions
2024-01-17 23:46:23,372:INFO:Preloading libraries
2024-01-17 23:46:23,905:INFO:Initializing predict_model()
2024-01-17 23:46:23,913:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021241CBAA50>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021241B888D0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000212421E3100>)
2024-01-17 23:46:23,913:INFO:Checking exceptions
2024-01-17 23:46:23,913:INFO:Preloading libraries
2024-01-17 23:46:23,915:INFO:Set up data.
2024-01-17 23:46:23,921:INFO:Set up index.
2024-01-17 23:48:27,976:INFO:PyCaret ClassificationExperiment
2024-01-17 23:48:27,976:INFO:Logging name: clf-default-name
2024-01-17 23:48:27,976:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-17 23:48:27,976:INFO:version 3.2.0
2024-01-17 23:48:27,976:INFO:Initializing setup()
2024-01-17 23:48:27,976:INFO:self.USI: 536a
2024-01-17 23:48:27,976:INFO:self._variable_keys: {'seed', 'is_multiclass', 'target_param', 'y_test', 'data', 'exp_id', 'memory', 'gpu_n_jobs_param', 'gpu_param', 'X_train', '_available_plots', 'n_jobs_param', 'pipeline', 'fold_generator', 'X_test', 'X', 'fold_shuffle_param', '_ml_usecase', 'y', 'html_param', 'fix_imbalance', 'logging_param', 'log_plots_param', 'idx', 'y_train', 'fold_groups_param', 'exp_name_log', 'USI'}
2024-01-17 23:48:27,976:INFO:Checking environment
2024-01-17 23:48:27,976:INFO:python_version: 3.11.5
2024-01-17 23:48:27,976:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 23:48:27,976:INFO:machine: AMD64
2024-01-17 23:48:27,976:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 23:48:27,976:INFO:Memory: svmem(total=8361132032, available=1365028864, percent=83.7, used=6996103168, free=1365028864)
2024-01-17 23:48:27,976:INFO:Physical Core: 2
2024-01-17 23:48:27,976:INFO:Logical Core: 4
2024-01-17 23:48:27,976:INFO:Checking libraries
2024-01-17 23:48:27,976:INFO:System:
2024-01-17 23:48:27,976:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 23:48:27,976:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 23:48:27,976:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 23:48:27,976:INFO:PyCaret required dependencies:
2024-01-17 23:48:27,976:INFO:                 pip: 23.2.1
2024-01-17 23:48:27,976:INFO:          setuptools: 68.0.0
2024-01-17 23:48:27,976:INFO:             pycaret: 3.2.0
2024-01-17 23:48:27,976:INFO:             IPython: 8.15.0
2024-01-17 23:48:27,976:INFO:          ipywidgets: 8.0.4
2024-01-17 23:48:27,976:INFO:                tqdm: 4.65.0
2024-01-17 23:48:27,976:INFO:               numpy: 1.24.3
2024-01-17 23:48:27,976:INFO:              pandas: 1.5.3
2024-01-17 23:48:27,976:INFO:              jinja2: 3.1.2
2024-01-17 23:48:27,976:INFO:               scipy: 1.10.1
2024-01-17 23:48:27,976:INFO:              joblib: 1.2.0
2024-01-17 23:48:27,976:INFO:             sklearn: 1.2.2
2024-01-17 23:48:27,976:INFO:                pyod: 1.1.2
2024-01-17 23:48:27,976:INFO:            imblearn: 0.10.1
2024-01-17 23:48:27,976:INFO:   category_encoders: 2.6.3
2024-01-17 23:48:27,976:INFO:            lightgbm: 4.2.0
2024-01-17 23:48:27,976:INFO:               numba: 0.57.1
2024-01-17 23:48:27,976:INFO:            requests: 2.31.0
2024-01-17 23:48:27,976:INFO:          matplotlib: 3.6.0
2024-01-17 23:48:27,976:INFO:          scikitplot: 0.3.7
2024-01-17 23:48:27,976:INFO:         yellowbrick: 1.5
2024-01-17 23:48:27,976:INFO:              plotly: 5.9.0
2024-01-17 23:48:27,976:INFO:    plotly-resampler: Not installed
2024-01-17 23:48:27,976:INFO:             kaleido: 0.2.1
2024-01-17 23:48:27,976:INFO:           schemdraw: 0.15
2024-01-17 23:48:27,976:INFO:         statsmodels: 0.14.0
2024-01-17 23:48:27,976:INFO:              sktime: 0.21.1
2024-01-17 23:48:27,976:INFO:               tbats: 1.1.3
2024-01-17 23:48:27,976:INFO:            pmdarima: 2.0.4
2024-01-17 23:48:27,976:INFO:              psutil: 5.9.0
2024-01-17 23:48:27,976:INFO:          markupsafe: 2.1.1
2024-01-17 23:48:27,976:INFO:             pickle5: Not installed
2024-01-17 23:48:27,976:INFO:         cloudpickle: 2.2.1
2024-01-17 23:48:27,976:INFO:         deprecation: 2.1.0
2024-01-17 23:48:27,976:INFO:              xxhash: 2.0.2
2024-01-17 23:48:27,976:INFO:           wurlitzer: Not installed
2024-01-17 23:48:27,976:INFO:PyCaret optional dependencies:
2024-01-17 23:48:27,976:INFO:                shap: Not installed
2024-01-17 23:48:27,976:INFO:           interpret: Not installed
2024-01-17 23:48:27,976:INFO:                umap: Not installed
2024-01-17 23:48:27,976:INFO:     ydata_profiling: Not installed
2024-01-17 23:48:27,976:INFO:  explainerdashboard: Not installed
2024-01-17 23:48:27,976:INFO:             autoviz: Not installed
2024-01-17 23:48:27,976:INFO:           fairlearn: Not installed
2024-01-17 23:48:27,976:INFO:          deepchecks: Not installed
2024-01-17 23:48:27,976:INFO:             xgboost: 2.0.3
2024-01-17 23:48:27,976:INFO:            catboost: 1.2.2
2024-01-17 23:48:27,976:INFO:              kmodes: Not installed
2024-01-17 23:48:27,976:INFO:             mlxtend: Not installed
2024-01-17 23:48:27,983:INFO:       statsforecast: Not installed
2024-01-17 23:48:27,983:INFO:        tune_sklearn: Not installed
2024-01-17 23:48:27,983:INFO:                 ray: Not installed
2024-01-17 23:48:27,983:INFO:            hyperopt: Not installed
2024-01-17 23:48:27,983:INFO:              optuna: 3.5.0
2024-01-17 23:48:27,983:INFO:               skopt: Not installed
2024-01-17 23:48:27,983:INFO:              mlflow: Not installed
2024-01-17 23:48:27,983:INFO:              gradio: Not installed
2024-01-17 23:48:27,983:INFO:             fastapi: Not installed
2024-01-17 23:48:27,983:INFO:             uvicorn: Not installed
2024-01-17 23:48:27,983:INFO:              m2cgen: Not installed
2024-01-17 23:48:27,983:INFO:           evidently: Not installed
2024-01-17 23:48:27,983:INFO:               fugue: Not installed
2024-01-17 23:48:27,983:INFO:           streamlit: Not installed
2024-01-17 23:48:27,983:INFO:             prophet: Not installed
2024-01-17 23:48:27,983:INFO:None
2024-01-17 23:48:27,983:INFO:Set up data.
2024-01-17 23:48:28,000:INFO:Set up folding strategy.
2024-01-17 23:48:28,000:INFO:Set up train/test split.
2024-01-17 23:48:28,026:INFO:Set up index.
2024-01-17 23:48:28,027:INFO:Assigning column types.
2024-01-17 23:48:28,037:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-17 23:48:28,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:48:28,211:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:48:28,336:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:48:28,336:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:48:28,477:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:48:28,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:48:28,571:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:48:28,587:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:48:28,587:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-17 23:48:28,728:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:48:28,823:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:48:28,823:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:48:28,964:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:48:29,066:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:48:29,074:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:48:29,074:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-17 23:48:29,303:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:48:29,320:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:48:29,555:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:48:29,555:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:48:29,555:INFO:Preparing preprocessing pipeline...
2024-01-17 23:48:29,570:INFO:Set up simple imputation.
2024-01-17 23:48:29,602:INFO:Finished creating preprocessing pipeline.
2024-01-17 23:48:29,618:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-01-17 23:48:29,618:INFO:Creating final display dataframe.
2024-01-17 23:48:29,783:INFO:Setup _display_container:                     Description             Value
0                    Session id              4778
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 11)
5   Transformed train set shape         (623, 11)
6    Transformed test set shape         (268, 11)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              536a
2024-01-17 23:48:30,191:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:48:30,198:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:48:30,466:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:48:30,466:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:48:30,466:INFO:setup() successfully completed in 2.51s...............
2024-01-17 23:48:32,879:INFO:Initializing compare_models()
2024-01-17 23:48:32,879:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-17 23:48:32,879:INFO:Checking exceptions
2024-01-17 23:48:32,893:INFO:Preparing display monitor
2024-01-17 23:48:33,009:INFO:Initializing Logistic Regression
2024-01-17 23:48:33,009:INFO:Total runtime is 2.6122728983561197e-05 minutes
2024-01-17 23:48:33,017:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:33,018:INFO:Initializing create_model()
2024-01-17 23:48:33,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:33,018:INFO:Checking exceptions
2024-01-17 23:48:33,018:INFO:Importing libraries
2024-01-17 23:48:33,018:INFO:Copying training dataset
2024-01-17 23:48:33,025:INFO:Defining folds
2024-01-17 23:48:33,030:INFO:Declaring metric variables
2024-01-17 23:48:33,032:INFO:Importing untrained model
2024-01-17 23:48:33,049:INFO:Logistic Regression Imported successfully
2024-01-17 23:48:33,065:INFO:Starting cross validation
2024-01-17 23:48:33,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:33,426:INFO:Calculating mean and std
2024-01-17 23:48:33,426:INFO:Creating metrics dataframe
2024-01-17 23:48:33,445:INFO:Uploading results into container
2024-01-17 23:48:33,445:INFO:Uploading model into container now
2024-01-17 23:48:33,450:INFO:_master_model_container: 1
2024-01-17 23:48:33,450:INFO:_display_container: 2
2024-01-17 23:48:33,450:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4778, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 23:48:33,450:INFO:create_model() successfully completed......................................
2024-01-17 23:48:33,829:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:33,829:INFO:Creating metrics dataframe
2024-01-17 23:48:33,860:INFO:Initializing K Neighbors Classifier
2024-01-17 23:48:33,860:INFO:Total runtime is 0.014216033617655437 minutes
2024-01-17 23:48:33,876:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:33,876:INFO:Initializing create_model()
2024-01-17 23:48:33,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:33,877:INFO:Checking exceptions
2024-01-17 23:48:33,877:INFO:Importing libraries
2024-01-17 23:48:33,878:INFO:Copying training dataset
2024-01-17 23:48:33,888:INFO:Defining folds
2024-01-17 23:48:33,888:INFO:Declaring metric variables
2024-01-17 23:48:33,894:INFO:Importing untrained model
2024-01-17 23:48:33,895:INFO:K Neighbors Classifier Imported successfully
2024-01-17 23:48:33,915:INFO:Starting cross validation
2024-01-17 23:48:33,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:34,443:INFO:Calculating mean and std
2024-01-17 23:48:34,443:INFO:Creating metrics dataframe
2024-01-17 23:48:34,463:INFO:Uploading results into container
2024-01-17 23:48:34,463:INFO:Uploading model into container now
2024-01-17 23:48:34,463:INFO:_master_model_container: 2
2024-01-17 23:48:34,465:INFO:_display_container: 2
2024-01-17 23:48:34,466:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-17 23:48:34,466:INFO:create_model() successfully completed......................................
2024-01-17 23:48:34,721:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:34,721:INFO:Creating metrics dataframe
2024-01-17 23:48:34,752:INFO:Initializing Naive Bayes
2024-01-17 23:48:34,752:INFO:Total runtime is 0.02907694975535075 minutes
2024-01-17 23:48:34,763:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:34,763:INFO:Initializing create_model()
2024-01-17 23:48:34,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:34,763:INFO:Checking exceptions
2024-01-17 23:48:34,763:INFO:Importing libraries
2024-01-17 23:48:34,763:INFO:Copying training dataset
2024-01-17 23:48:34,775:INFO:Defining folds
2024-01-17 23:48:34,775:INFO:Declaring metric variables
2024-01-17 23:48:34,783:INFO:Importing untrained model
2024-01-17 23:48:34,791:INFO:Naive Bayes Imported successfully
2024-01-17 23:48:34,807:INFO:Starting cross validation
2024-01-17 23:48:34,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:35,091:INFO:Calculating mean and std
2024-01-17 23:48:35,091:INFO:Creating metrics dataframe
2024-01-17 23:48:35,116:INFO:Uploading results into container
2024-01-17 23:48:35,116:INFO:Uploading model into container now
2024-01-17 23:48:35,116:INFO:_master_model_container: 3
2024-01-17 23:48:35,116:INFO:_display_container: 2
2024-01-17 23:48:35,116:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-17 23:48:35,116:INFO:create_model() successfully completed......................................
2024-01-17 23:48:35,384:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:35,384:INFO:Creating metrics dataframe
2024-01-17 23:48:35,415:INFO:Initializing Decision Tree Classifier
2024-01-17 23:48:35,415:INFO:Total runtime is 0.04013500213623047 minutes
2024-01-17 23:48:35,426:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:35,426:INFO:Initializing create_model()
2024-01-17 23:48:35,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:35,426:INFO:Checking exceptions
2024-01-17 23:48:35,426:INFO:Importing libraries
2024-01-17 23:48:35,426:INFO:Copying training dataset
2024-01-17 23:48:35,439:INFO:Defining folds
2024-01-17 23:48:35,439:INFO:Declaring metric variables
2024-01-17 23:48:35,446:INFO:Importing untrained model
2024-01-17 23:48:35,447:INFO:Decision Tree Classifier Imported successfully
2024-01-17 23:48:35,470:INFO:Starting cross validation
2024-01-17 23:48:35,471:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:35,782:INFO:Calculating mean and std
2024-01-17 23:48:35,782:INFO:Creating metrics dataframe
2024-01-17 23:48:35,782:INFO:Uploading results into container
2024-01-17 23:48:35,782:INFO:Uploading model into container now
2024-01-17 23:48:35,797:INFO:_master_model_container: 4
2024-01-17 23:48:35,797:INFO:_display_container: 2
2024-01-17 23:48:35,799:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4778, splitter='best')
2024-01-17 23:48:35,799:INFO:create_model() successfully completed......................................
2024-01-17 23:48:36,087:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:36,087:INFO:Creating metrics dataframe
2024-01-17 23:48:36,126:INFO:Initializing SVM - Linear Kernel
2024-01-17 23:48:36,126:INFO:Total runtime is 0.05197352170944214 minutes
2024-01-17 23:48:36,135:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:36,135:INFO:Initializing create_model()
2024-01-17 23:48:36,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:36,135:INFO:Checking exceptions
2024-01-17 23:48:36,135:INFO:Importing libraries
2024-01-17 23:48:36,135:INFO:Copying training dataset
2024-01-17 23:48:36,145:INFO:Defining folds
2024-01-17 23:48:36,147:INFO:Declaring metric variables
2024-01-17 23:48:36,154:INFO:Importing untrained model
2024-01-17 23:48:36,162:INFO:SVM - Linear Kernel Imported successfully
2024-01-17 23:48:36,181:INFO:Starting cross validation
2024-01-17 23:48:36,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:36,263:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:48:36,263:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:48:36,275:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:48:36,300:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:48:36,351:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:48:36,366:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:48:36,406:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:48:36,422:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:48:36,437:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:48:36,453:INFO:Calculating mean and std
2024-01-17 23:48:36,468:INFO:Creating metrics dataframe
2024-01-17 23:48:36,477:INFO:Uploading results into container
2024-01-17 23:48:36,477:INFO:Uploading model into container now
2024-01-17 23:48:36,478:INFO:_master_model_container: 5
2024-01-17 23:48:36,478:INFO:_display_container: 2
2024-01-17 23:48:36,478:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4778, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-17 23:48:36,478:INFO:create_model() successfully completed......................................
2024-01-17 23:48:36,754:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:36,801:INFO:Creating metrics dataframe
2024-01-17 23:48:36,832:INFO:Initializing Ridge Classifier
2024-01-17 23:48:36,832:INFO:Total runtime is 0.06374260981877644 minutes
2024-01-17 23:48:36,842:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:36,842:INFO:Initializing create_model()
2024-01-17 23:48:36,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:36,843:INFO:Checking exceptions
2024-01-17 23:48:36,843:INFO:Importing libraries
2024-01-17 23:48:36,843:INFO:Copying training dataset
2024-01-17 23:48:36,849:INFO:Defining folds
2024-01-17 23:48:36,849:INFO:Declaring metric variables
2024-01-17 23:48:36,858:INFO:Importing untrained model
2024-01-17 23:48:36,868:INFO:Ridge Classifier Imported successfully
2024-01-17 23:48:36,886:INFO:Starting cross validation
2024-01-17 23:48:36,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:36,963:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:36,971:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:36,979:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:37,019:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:37,058:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:37,060:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:37,076:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:37,117:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:37,133:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:37,148:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:48:37,179:INFO:Calculating mean and std
2024-01-17 23:48:37,179:INFO:Creating metrics dataframe
2024-01-17 23:48:37,194:INFO:Uploading results into container
2024-01-17 23:48:37,194:INFO:Uploading model into container now
2024-01-17 23:48:37,194:INFO:_master_model_container: 6
2024-01-17 23:48:37,194:INFO:_display_container: 2
2024-01-17 23:48:37,194:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4778, solver='auto',
                tol=0.0001)
2024-01-17 23:48:37,194:INFO:create_model() successfully completed......................................
2024-01-17 23:48:37,510:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:37,510:INFO:Creating metrics dataframe
2024-01-17 23:48:37,550:INFO:Initializing Random Forest Classifier
2024-01-17 23:48:37,550:INFO:Total runtime is 0.075709331035614 minutes
2024-01-17 23:48:37,566:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:37,566:INFO:Initializing create_model()
2024-01-17 23:48:37,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:37,566:INFO:Checking exceptions
2024-01-17 23:48:37,566:INFO:Importing libraries
2024-01-17 23:48:37,566:INFO:Copying training dataset
2024-01-17 23:48:37,582:INFO:Defining folds
2024-01-17 23:48:37,582:INFO:Declaring metric variables
2024-01-17 23:48:37,592:INFO:Importing untrained model
2024-01-17 23:48:37,598:INFO:Random Forest Classifier Imported successfully
2024-01-17 23:48:37,630:INFO:Starting cross validation
2024-01-17 23:48:37,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:40,796:INFO:Calculating mean and std
2024-01-17 23:48:40,796:INFO:Creating metrics dataframe
2024-01-17 23:48:40,812:INFO:Uploading results into container
2024-01-17 23:48:40,812:INFO:Uploading model into container now
2024-01-17 23:48:40,812:INFO:_master_model_container: 7
2024-01-17 23:48:40,812:INFO:_display_container: 2
2024-01-17 23:48:40,826:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4778, verbose=0, warm_start=False)
2024-01-17 23:48:40,826:INFO:create_model() successfully completed......................................
2024-01-17 23:48:41,177:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:41,177:INFO:Creating metrics dataframe
2024-01-17 23:48:41,207:INFO:Initializing Quadratic Discriminant Analysis
2024-01-17 23:48:41,207:INFO:Total runtime is 0.13666171630223592 minutes
2024-01-17 23:48:41,220:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:41,220:INFO:Initializing create_model()
2024-01-17 23:48:41,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:41,220:INFO:Checking exceptions
2024-01-17 23:48:41,220:INFO:Importing libraries
2024-01-17 23:48:41,220:INFO:Copying training dataset
2024-01-17 23:48:41,228:INFO:Defining folds
2024-01-17 23:48:41,228:INFO:Declaring metric variables
2024-01-17 23:48:41,243:INFO:Importing untrained model
2024-01-17 23:48:41,254:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-17 23:48:41,269:INFO:Starting cross validation
2024-01-17 23:48:41,269:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:41,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,334:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,350:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,432:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,438:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,456:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,501:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,548:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:48:41,596:INFO:Calculating mean and std
2024-01-17 23:48:41,596:INFO:Creating metrics dataframe
2024-01-17 23:48:41,623:INFO:Uploading results into container
2024-01-17 23:48:41,623:INFO:Uploading model into container now
2024-01-17 23:48:41,627:INFO:_master_model_container: 8
2024-01-17 23:48:41,627:INFO:_display_container: 2
2024-01-17 23:48:41,628:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-17 23:48:41,628:INFO:create_model() successfully completed......................................
2024-01-17 23:48:41,958:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:41,958:INFO:Creating metrics dataframe
2024-01-17 23:48:41,989:INFO:Initializing Ada Boost Classifier
2024-01-17 23:48:41,989:INFO:Total runtime is 0.14969112475713095 minutes
2024-01-17 23:48:42,000:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:42,000:INFO:Initializing create_model()
2024-01-17 23:48:42,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:42,000:INFO:Checking exceptions
2024-01-17 23:48:42,000:INFO:Importing libraries
2024-01-17 23:48:42,000:INFO:Copying training dataset
2024-01-17 23:48:42,016:INFO:Defining folds
2024-01-17 23:48:42,016:INFO:Declaring metric variables
2024-01-17 23:48:42,024:INFO:Importing untrained model
2024-01-17 23:48:42,034:INFO:Ada Boost Classifier Imported successfully
2024-01-17 23:48:42,048:INFO:Starting cross validation
2024-01-17 23:48:42,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:43,552:INFO:Calculating mean and std
2024-01-17 23:48:43,552:INFO:Creating metrics dataframe
2024-01-17 23:48:43,567:INFO:Uploading results into container
2024-01-17 23:48:43,567:INFO:Uploading model into container now
2024-01-17 23:48:43,567:INFO:_master_model_container: 9
2024-01-17 23:48:43,567:INFO:_display_container: 2
2024-01-17 23:48:43,567:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=4778)
2024-01-17 23:48:43,567:INFO:create_model() successfully completed......................................
2024-01-17 23:48:43,906:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:43,906:INFO:Creating metrics dataframe
2024-01-17 23:48:43,939:INFO:Initializing Gradient Boosting Classifier
2024-01-17 23:48:43,939:INFO:Total runtime is 0.18219471772511803 minutes
2024-01-17 23:48:43,951:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:43,951:INFO:Initializing create_model()
2024-01-17 23:48:43,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:43,951:INFO:Checking exceptions
2024-01-17 23:48:43,951:INFO:Importing libraries
2024-01-17 23:48:43,958:INFO:Copying training dataset
2024-01-17 23:48:43,967:INFO:Defining folds
2024-01-17 23:48:43,967:INFO:Declaring metric variables
2024-01-17 23:48:43,978:INFO:Importing untrained model
2024-01-17 23:48:43,992:INFO:Gradient Boosting Classifier Imported successfully
2024-01-17 23:48:44,013:INFO:Starting cross validation
2024-01-17 23:48:44,013:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:45,528:INFO:Calculating mean and std
2024-01-17 23:48:45,528:INFO:Creating metrics dataframe
2024-01-17 23:48:45,547:INFO:Uploading results into container
2024-01-17 23:48:45,547:INFO:Uploading model into container now
2024-01-17 23:48:45,547:INFO:_master_model_container: 10
2024-01-17 23:48:45,547:INFO:_display_container: 2
2024-01-17 23:48:45,547:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 23:48:45,547:INFO:create_model() successfully completed......................................
2024-01-17 23:48:45,887:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:45,887:INFO:Creating metrics dataframe
2024-01-17 23:48:45,929:INFO:Initializing Linear Discriminant Analysis
2024-01-17 23:48:45,929:INFO:Total runtime is 0.21535600423812867 minutes
2024-01-17 23:48:45,946:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:45,946:INFO:Initializing create_model()
2024-01-17 23:48:45,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:45,946:INFO:Checking exceptions
2024-01-17 23:48:45,946:INFO:Importing libraries
2024-01-17 23:48:45,946:INFO:Copying training dataset
2024-01-17 23:48:45,963:INFO:Defining folds
2024-01-17 23:48:45,963:INFO:Declaring metric variables
2024-01-17 23:48:45,978:INFO:Importing untrained model
2024-01-17 23:48:45,992:INFO:Linear Discriminant Analysis Imported successfully
2024-01-17 23:48:46,049:INFO:Starting cross validation
2024-01-17 23:48:46,049:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:46,362:INFO:Calculating mean and std
2024-01-17 23:48:46,362:INFO:Creating metrics dataframe
2024-01-17 23:48:46,377:INFO:Uploading results into container
2024-01-17 23:48:46,377:INFO:Uploading model into container now
2024-01-17 23:48:46,377:INFO:_master_model_container: 11
2024-01-17 23:48:46,377:INFO:_display_container: 2
2024-01-17 23:48:46,377:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-17 23:48:46,377:INFO:create_model() successfully completed......................................
2024-01-17 23:48:46,732:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:46,732:INFO:Creating metrics dataframe
2024-01-17 23:48:46,763:INFO:Initializing Extra Trees Classifier
2024-01-17 23:48:46,763:INFO:Total runtime is 0.22926383018493654 minutes
2024-01-17 23:48:46,779:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:46,779:INFO:Initializing create_model()
2024-01-17 23:48:46,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:46,784:INFO:Checking exceptions
2024-01-17 23:48:46,784:INFO:Importing libraries
2024-01-17 23:48:46,784:INFO:Copying training dataset
2024-01-17 23:48:46,787:INFO:Defining folds
2024-01-17 23:48:46,791:INFO:Declaring metric variables
2024-01-17 23:48:46,796:INFO:Importing untrained model
2024-01-17 23:48:46,803:INFO:Extra Trees Classifier Imported successfully
2024-01-17 23:48:46,811:INFO:Starting cross validation
2024-01-17 23:48:46,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:49,481:INFO:Calculating mean and std
2024-01-17 23:48:49,481:INFO:Creating metrics dataframe
2024-01-17 23:48:49,502:INFO:Uploading results into container
2024-01-17 23:48:49,502:INFO:Uploading model into container now
2024-01-17 23:48:49,505:INFO:_master_model_container: 12
2024-01-17 23:48:49,505:INFO:_display_container: 2
2024-01-17 23:48:49,507:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4778, verbose=0, warm_start=False)
2024-01-17 23:48:49,507:INFO:create_model() successfully completed......................................
2024-01-17 23:48:49,834:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:49,834:INFO:Creating metrics dataframe
2024-01-17 23:48:49,865:INFO:Initializing Extreme Gradient Boosting
2024-01-17 23:48:49,865:INFO:Total runtime is 0.2809670488039653 minutes
2024-01-17 23:48:49,891:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:49,892:INFO:Initializing create_model()
2024-01-17 23:48:49,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:49,892:INFO:Checking exceptions
2024-01-17 23:48:49,892:INFO:Importing libraries
2024-01-17 23:48:49,892:INFO:Copying training dataset
2024-01-17 23:48:49,906:INFO:Defining folds
2024-01-17 23:48:49,906:INFO:Declaring metric variables
2024-01-17 23:48:49,915:INFO:Importing untrained model
2024-01-17 23:48:49,925:INFO:Extreme Gradient Boosting Imported successfully
2024-01-17 23:48:49,940:INFO:Starting cross validation
2024-01-17 23:48:49,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:50,731:INFO:Calculating mean and std
2024-01-17 23:48:50,747:INFO:Creating metrics dataframe
2024-01-17 23:48:50,758:INFO:Uploading results into container
2024-01-17 23:48:50,760:INFO:Uploading model into container now
2024-01-17 23:48:50,761:INFO:_master_model_container: 13
2024-01-17 23:48:50,761:INFO:_display_container: 2
2024-01-17 23:48:50,764:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-17 23:48:50,764:INFO:create_model() successfully completed......................................
2024-01-17 23:48:51,046:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:51,046:INFO:Creating metrics dataframe
2024-01-17 23:48:51,092:INFO:Initializing Light Gradient Boosting Machine
2024-01-17 23:48:51,092:INFO:Total runtime is 0.3014194925626119 minutes
2024-01-17 23:48:51,116:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:51,116:INFO:Initializing create_model()
2024-01-17 23:48:51,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:51,116:INFO:Checking exceptions
2024-01-17 23:48:51,116:INFO:Importing libraries
2024-01-17 23:48:51,116:INFO:Copying training dataset
2024-01-17 23:48:51,124:INFO:Defining folds
2024-01-17 23:48:51,124:INFO:Declaring metric variables
2024-01-17 23:48:51,139:INFO:Importing untrained model
2024-01-17 23:48:51,149:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-17 23:48:51,167:INFO:Starting cross validation
2024-01-17 23:48:51,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:48:52,666:INFO:Calculating mean and std
2024-01-17 23:48:52,666:INFO:Creating metrics dataframe
2024-01-17 23:48:52,687:INFO:Uploading results into container
2024-01-17 23:48:52,692:INFO:Uploading model into container now
2024-01-17 23:48:52,693:INFO:_master_model_container: 14
2024-01-17 23:48:52,693:INFO:_display_container: 2
2024-01-17 23:48:52,694:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4778, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-17 23:48:52,694:INFO:create_model() successfully completed......................................
2024-01-17 23:48:52,986:INFO:SubProcess create_model() end ==================================
2024-01-17 23:48:52,986:INFO:Creating metrics dataframe
2024-01-17 23:48:53,018:INFO:Initializing CatBoost Classifier
2024-01-17 23:48:53,018:INFO:Total runtime is 0.3335060477256775 minutes
2024-01-17 23:48:53,041:INFO:SubProcess create_model() called ==================================
2024-01-17 23:48:53,041:INFO:Initializing create_model()
2024-01-17 23:48:53,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:48:53,041:INFO:Checking exceptions
2024-01-17 23:48:53,042:INFO:Importing libraries
2024-01-17 23:48:53,042:INFO:Copying training dataset
2024-01-17 23:48:53,050:INFO:Defining folds
2024-01-17 23:48:53,050:INFO:Declaring metric variables
2024-01-17 23:48:53,061:INFO:Importing untrained model
2024-01-17 23:48:53,066:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:48:53,085:INFO:Starting cross validation
2024-01-17 23:48:53,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:49:13,700:INFO:Calculating mean and std
2024-01-17 23:49:13,700:INFO:Creating metrics dataframe
2024-01-17 23:49:13,726:INFO:Uploading results into container
2024-01-17 23:49:13,730:INFO:Uploading model into container now
2024-01-17 23:49:13,732:INFO:_master_model_container: 15
2024-01-17 23:49:13,732:INFO:_display_container: 2
2024-01-17 23:49:13,732:INFO:<catboost.core.CatBoostClassifier object at 0x000002123B3A81D0>
2024-01-17 23:49:13,732:INFO:create_model() successfully completed......................................
2024-01-17 23:49:14,075:INFO:SubProcess create_model() end ==================================
2024-01-17 23:49:14,075:INFO:Creating metrics dataframe
2024-01-17 23:49:14,107:INFO:Initializing Dummy Classifier
2024-01-17 23:49:14,107:INFO:Total runtime is 0.6850033084551493 minutes
2024-01-17 23:49:14,126:INFO:SubProcess create_model() called ==================================
2024-01-17 23:49:14,131:INFO:Initializing create_model()
2024-01-17 23:49:14,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021241D2A390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:49:14,131:INFO:Checking exceptions
2024-01-17 23:49:14,131:INFO:Importing libraries
2024-01-17 23:49:14,131:INFO:Copying training dataset
2024-01-17 23:49:14,134:INFO:Defining folds
2024-01-17 23:49:14,138:INFO:Declaring metric variables
2024-01-17 23:49:14,144:INFO:Importing untrained model
2024-01-17 23:49:14,147:INFO:Dummy Classifier Imported successfully
2024-01-17 23:49:14,170:INFO:Starting cross validation
2024-01-17 23:49:14,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:49:14,241:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,257:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,299:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,330:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,391:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,408:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,413:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,459:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,459:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:49:14,475:INFO:Calculating mean and std
2024-01-17 23:49:14,475:INFO:Creating metrics dataframe
2024-01-17 23:49:14,495:INFO:Uploading results into container
2024-01-17 23:49:14,495:INFO:Uploading model into container now
2024-01-17 23:49:14,495:INFO:_master_model_container: 16
2024-01-17 23:49:14,500:INFO:_display_container: 2
2024-01-17 23:49:14,500:INFO:DummyClassifier(constant=None, random_state=4778, strategy='prior')
2024-01-17 23:49:14,500:INFO:create_model() successfully completed......................................
2024-01-17 23:49:14,864:INFO:SubProcess create_model() end ==================================
2024-01-17 23:49:14,864:INFO:Creating metrics dataframe
2024-01-17 23:49:14,944:INFO:Initializing create_model()
2024-01-17 23:49:14,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:49:14,944:INFO:Checking exceptions
2024-01-17 23:49:14,949:INFO:Importing libraries
2024-01-17 23:49:14,949:INFO:Copying training dataset
2024-01-17 23:49:14,951:INFO:Defining folds
2024-01-17 23:49:14,954:INFO:Declaring metric variables
2024-01-17 23:49:14,954:INFO:Importing untrained model
2024-01-17 23:49:14,954:INFO:Declaring custom model
2024-01-17 23:49:14,954:INFO:Gradient Boosting Classifier Imported successfully
2024-01-17 23:49:14,957:INFO:Cross validation set to False
2024-01-17 23:49:14,958:INFO:Fitting Model
2024-01-17 23:49:15,276:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 23:49:15,276:INFO:create_model() successfully completed......................................
2024-01-17 23:49:15,729:INFO:_master_model_container: 16
2024-01-17 23:49:15,731:INFO:_display_container: 2
2024-01-17 23:49:15,731:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 23:49:15,731:INFO:compare_models() successfully completed......................................
2024-01-17 23:49:19,540:INFO:Initializing finalize_model()
2024-01-17 23:49:19,540:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-17 23:49:19,540:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 23:49:19,547:INFO:Initializing create_model()
2024-01-17 23:49:19,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:49:19,547:INFO:Checking exceptions
2024-01-17 23:49:19,557:INFO:Importing libraries
2024-01-17 23:49:19,557:INFO:Copying training dataset
2024-01-17 23:49:19,557:INFO:Defining folds
2024-01-17 23:49:19,557:INFO:Declaring metric variables
2024-01-17 23:49:19,557:INFO:Importing untrained model
2024-01-17 23:49:19,557:INFO:Declaring custom model
2024-01-17 23:49:19,563:INFO:Gradient Boosting Classifier Imported successfully
2024-01-17 23:49:19,563:INFO:Cross validation set to False
2024-01-17 23:49:19,563:INFO:Fitting Model
2024-01-17 23:49:20,008:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=4778, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-01-17 23:49:20,008:INFO:create_model() successfully completed......................................
2024-01-17 23:49:20,337:INFO:_master_model_container: 16
2024-01-17 23:49:20,337:INFO:_display_container: 2
2024-01-17 23:49:20,353:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=4778, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-01-17 23:49:20,353:INFO:finalize_model() successfully completed......................................
2024-01-17 23:49:21,173:INFO:Initializing evaluate_model()
2024-01-17 23:49:21,173:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-17 23:49:21,209:INFO:Initializing plot_model()
2024-01-17 23:49:21,209:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 23:49:21,209:INFO:Checking exceptions
2024-01-17 23:49:21,568:INFO:Preloading libraries
2024-01-17 23:49:21,723:INFO:Copying training dataset
2024-01-17 23:49:21,723:INFO:Plot type: pipeline
2024-01-17 23:49:22,179:INFO:Visual Rendered Successfully
2024-01-17 23:49:22,477:INFO:plot_model() successfully completed......................................
2024-01-17 23:49:22,518:INFO:Initializing predict_model()
2024-01-17 23:49:22,518:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021241F3FBA0>)
2024-01-17 23:49:22,519:INFO:Checking exceptions
2024-01-17 23:49:22,519:INFO:Preloading libraries
2024-01-17 23:49:23,881:INFO:Initializing predict_model()
2024-01-17 23:49:23,881:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002123B35DC10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4778, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021241F3FD80>)
2024-01-17 23:49:23,881:INFO:Checking exceptions
2024-01-17 23:49:23,881:INFO:Preloading libraries
2024-01-17 23:49:23,886:INFO:Set up data.
2024-01-17 23:49:23,896:INFO:Set up index.
2024-01-17 23:55:16,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:55:16,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:55:16,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:55:16,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-17 23:56:16,654:INFO:PyCaret ClassificationExperiment
2024-01-17 23:56:16,654:INFO:Logging name: clf-default-name
2024-01-17 23:56:16,654:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-17 23:56:16,654:INFO:version 3.2.0
2024-01-17 23:56:16,654:INFO:Initializing setup()
2024-01-17 23:56:16,654:INFO:self.USI: 8191
2024-01-17 23:56:16,654:INFO:self._variable_keys: {'seed', '_ml_usecase', 'log_plots_param', 'gpu_n_jobs_param', 'X', 'exp_id', 'gpu_param', 'y_train', 'USI', 'fold_shuffle_param', 'data', 'fold_groups_param', 'n_jobs_param', 'fix_imbalance', 'is_multiclass', '_available_plots', 'X_test', 'html_param', 'pipeline', 'y_test', 'logging_param', 'fold_generator', 'memory', 'idx', 'X_train', 'exp_name_log', 'target_param', 'y'}
2024-01-17 23:56:16,654:INFO:Checking environment
2024-01-17 23:56:16,654:INFO:python_version: 3.11.5
2024-01-17 23:56:16,654:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-17 23:56:16,654:INFO:machine: AMD64
2024-01-17 23:56:16,654:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-17 23:56:16,654:INFO:Memory: svmem(total=8361132032, available=1822257152, percent=78.2, used=6538874880, free=1822257152)
2024-01-17 23:56:16,654:INFO:Physical Core: 2
2024-01-17 23:56:16,654:INFO:Logical Core: 4
2024-01-17 23:56:16,662:INFO:Checking libraries
2024-01-17 23:56:16,662:INFO:System:
2024-01-17 23:56:16,662:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-17 23:56:16,662:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-17 23:56:16,662:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-17 23:56:16,662:INFO:PyCaret required dependencies:
2024-01-17 23:56:16,664:INFO:                 pip: 23.2.1
2024-01-17 23:56:16,664:INFO:          setuptools: 68.0.0
2024-01-17 23:56:16,664:INFO:             pycaret: 3.2.0
2024-01-17 23:56:16,664:INFO:             IPython: 8.15.0
2024-01-17 23:56:16,664:INFO:          ipywidgets: 8.0.4
2024-01-17 23:56:16,664:INFO:                tqdm: 4.65.0
2024-01-17 23:56:16,664:INFO:               numpy: 1.24.3
2024-01-17 23:56:16,664:INFO:              pandas: 1.5.3
2024-01-17 23:56:16,664:INFO:              jinja2: 3.1.2
2024-01-17 23:56:16,664:INFO:               scipy: 1.10.1
2024-01-17 23:56:16,664:INFO:              joblib: 1.2.0
2024-01-17 23:56:16,664:INFO:             sklearn: 1.2.2
2024-01-17 23:56:16,664:INFO:                pyod: 1.1.2
2024-01-17 23:56:16,673:INFO:            imblearn: 0.10.1
2024-01-17 23:56:16,673:INFO:   category_encoders: 2.6.3
2024-01-17 23:56:16,673:INFO:            lightgbm: 4.2.0
2024-01-17 23:56:16,674:INFO:               numba: 0.57.1
2024-01-17 23:56:16,674:INFO:            requests: 2.31.0
2024-01-17 23:56:16,674:INFO:          matplotlib: 3.6.0
2024-01-17 23:56:16,674:INFO:          scikitplot: 0.3.7
2024-01-17 23:56:16,674:INFO:         yellowbrick: 1.5
2024-01-17 23:56:16,674:INFO:              plotly: 5.9.0
2024-01-17 23:56:16,674:INFO:    plotly-resampler: Not installed
2024-01-17 23:56:16,674:INFO:             kaleido: 0.2.1
2024-01-17 23:56:16,674:INFO:           schemdraw: 0.15
2024-01-17 23:56:16,674:INFO:         statsmodels: 0.14.0
2024-01-17 23:56:16,674:INFO:              sktime: 0.21.1
2024-01-17 23:56:16,674:INFO:               tbats: 1.1.3
2024-01-17 23:56:16,674:INFO:            pmdarima: 2.0.4
2024-01-17 23:56:16,674:INFO:              psutil: 5.9.0
2024-01-17 23:56:16,674:INFO:          markupsafe: 2.1.1
2024-01-17 23:56:16,674:INFO:             pickle5: Not installed
2024-01-17 23:56:16,674:INFO:         cloudpickle: 2.2.1
2024-01-17 23:56:16,674:INFO:         deprecation: 2.1.0
2024-01-17 23:56:16,674:INFO:              xxhash: 2.0.2
2024-01-17 23:56:16,674:INFO:           wurlitzer: Not installed
2024-01-17 23:56:16,674:INFO:PyCaret optional dependencies:
2024-01-17 23:56:16,748:INFO:                shap: Not installed
2024-01-17 23:56:16,750:INFO:           interpret: Not installed
2024-01-17 23:56:16,750:INFO:                umap: Not installed
2024-01-17 23:56:16,750:INFO:     ydata_profiling: Not installed
2024-01-17 23:56:16,750:INFO:  explainerdashboard: Not installed
2024-01-17 23:56:16,750:INFO:             autoviz: Not installed
2024-01-17 23:56:16,750:INFO:           fairlearn: Not installed
2024-01-17 23:56:16,750:INFO:          deepchecks: Not installed
2024-01-17 23:56:16,750:INFO:             xgboost: 2.0.3
2024-01-17 23:56:16,750:INFO:            catboost: 1.2.2
2024-01-17 23:56:16,750:INFO:              kmodes: Not installed
2024-01-17 23:56:16,750:INFO:             mlxtend: Not installed
2024-01-17 23:56:16,750:INFO:       statsforecast: Not installed
2024-01-17 23:56:16,750:INFO:        tune_sklearn: Not installed
2024-01-17 23:56:16,750:INFO:                 ray: Not installed
2024-01-17 23:56:16,750:INFO:            hyperopt: Not installed
2024-01-17 23:56:16,750:INFO:              optuna: 3.5.0
2024-01-17 23:56:16,750:INFO:               skopt: Not installed
2024-01-17 23:56:16,753:INFO:              mlflow: Not installed
2024-01-17 23:56:16,753:INFO:              gradio: Not installed
2024-01-17 23:56:16,753:INFO:             fastapi: Not installed
2024-01-17 23:56:16,753:INFO:             uvicorn: Not installed
2024-01-17 23:56:16,753:INFO:              m2cgen: Not installed
2024-01-17 23:56:16,753:INFO:           evidently: Not installed
2024-01-17 23:56:16,753:INFO:               fugue: Not installed
2024-01-17 23:56:16,753:INFO:           streamlit: Not installed
2024-01-17 23:56:16,753:INFO:             prophet: Not installed
2024-01-17 23:56:16,754:INFO:None
2024-01-17 23:56:16,754:INFO:Set up data.
2024-01-17 23:56:16,773:INFO:Set up folding strategy.
2024-01-17 23:56:16,773:INFO:Set up train/test split.
2024-01-17 23:56:16,793:INFO:Set up index.
2024-01-17 23:56:16,796:INFO:Assigning column types.
2024-01-17 23:56:16,802:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-17 23:56:16,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:56:16,959:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:56:17,242:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:56:17,242:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:56:17,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-17 23:56:17,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:56:17,492:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:56:17,492:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:56:17,492:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-17 23:56:17,650:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:56:17,744:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:56:17,752:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:56:17,887:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-17 23:56:17,975:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:56:17,990:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:56:17,990:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-17 23:56:18,242:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:56:18,257:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:56:18,461:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:56:18,461:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:56:18,478:INFO:Preparing preprocessing pipeline...
2024-01-17 23:56:18,478:INFO:Set up simple imputation.
2024-01-17 23:56:18,508:INFO:Finished creating preprocessing pipeline.
2024-01-17 23:56:18,524:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-01-17 23:56:18,524:INFO:Creating final display dataframe.
2024-01-17 23:56:18,681:INFO:Setup _display_container:                     Description             Value
0                    Session id              3515
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 11)
5   Transformed train set shape         (623, 11)
6    Transformed test set shape         (268, 11)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              8191
2024-01-17 23:56:18,963:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:56:18,963:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:56:19,183:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-17 23:56:19,183:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-17 23:56:19,183:INFO:setup() successfully completed in 2.54s...............
2024-01-17 23:56:25,965:INFO:Initializing compare_models()
2024-01-17 23:56:25,965:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-17 23:56:25,965:INFO:Checking exceptions
2024-01-17 23:56:25,973:INFO:Preparing display monitor
2024-01-17 23:56:26,060:INFO:Initializing Logistic Regression
2024-01-17 23:56:26,060:INFO:Total runtime is 8.988380432128907e-06 minutes
2024-01-17 23:56:26,082:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:26,084:INFO:Initializing create_model()
2024-01-17 23:56:26,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:26,084:INFO:Checking exceptions
2024-01-17 23:56:26,084:INFO:Importing libraries
2024-01-17 23:56:26,085:INFO:Copying training dataset
2024-01-17 23:56:26,095:INFO:Defining folds
2024-01-17 23:56:26,096:INFO:Declaring metric variables
2024-01-17 23:56:26,104:INFO:Importing untrained model
2024-01-17 23:56:26,113:INFO:Logistic Regression Imported successfully
2024-01-17 23:56:26,127:INFO:Starting cross validation
2024-01-17 23:56:26,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:32,384:INFO:Calculating mean and std
2024-01-17 23:56:32,400:INFO:Creating metrics dataframe
2024-01-17 23:56:32,410:INFO:Uploading results into container
2024-01-17 23:56:32,410:INFO:Uploading model into container now
2024-01-17 23:56:32,416:INFO:_master_model_container: 1
2024-01-17 23:56:32,416:INFO:_display_container: 2
2024-01-17 23:56:32,416:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3515, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-17 23:56:32,416:INFO:create_model() successfully completed......................................
2024-01-17 23:56:32,591:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:32,591:INFO:Creating metrics dataframe
2024-01-17 23:56:32,614:INFO:Initializing K Neighbors Classifier
2024-01-17 23:56:32,614:INFO:Total runtime is 0.10923488537470499 minutes
2024-01-17 23:56:32,622:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:32,622:INFO:Initializing create_model()
2024-01-17 23:56:32,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:32,622:INFO:Checking exceptions
2024-01-17 23:56:32,622:INFO:Importing libraries
2024-01-17 23:56:32,622:INFO:Copying training dataset
2024-01-17 23:56:32,629:INFO:Defining folds
2024-01-17 23:56:32,638:INFO:Declaring metric variables
2024-01-17 23:56:32,639:INFO:Importing untrained model
2024-01-17 23:56:32,650:INFO:K Neighbors Classifier Imported successfully
2024-01-17 23:56:32,668:INFO:Starting cross validation
2024-01-17 23:56:32,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:32,916:INFO:Calculating mean and std
2024-01-17 23:56:32,916:INFO:Creating metrics dataframe
2024-01-17 23:56:32,933:INFO:Uploading results into container
2024-01-17 23:56:32,933:INFO:Uploading model into container now
2024-01-17 23:56:32,933:INFO:_master_model_container: 2
2024-01-17 23:56:32,933:INFO:_display_container: 2
2024-01-17 23:56:32,939:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-17 23:56:32,939:INFO:create_model() successfully completed......................................
2024-01-17 23:56:33,098:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:33,098:INFO:Creating metrics dataframe
2024-01-17 23:56:33,123:INFO:Initializing Naive Bayes
2024-01-17 23:56:33,123:INFO:Total runtime is 0.11771901448567708 minutes
2024-01-17 23:56:33,130:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:33,130:INFO:Initializing create_model()
2024-01-17 23:56:33,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:33,130:INFO:Checking exceptions
2024-01-17 23:56:33,130:INFO:Importing libraries
2024-01-17 23:56:33,138:INFO:Copying training dataset
2024-01-17 23:56:33,143:INFO:Defining folds
2024-01-17 23:56:33,143:INFO:Declaring metric variables
2024-01-17 23:56:33,156:INFO:Importing untrained model
2024-01-17 23:56:33,164:INFO:Naive Bayes Imported successfully
2024-01-17 23:56:33,174:INFO:Starting cross validation
2024-01-17 23:56:33,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:33,372:INFO:Calculating mean and std
2024-01-17 23:56:33,372:INFO:Creating metrics dataframe
2024-01-17 23:56:33,380:INFO:Uploading results into container
2024-01-17 23:56:33,380:INFO:Uploading model into container now
2024-01-17 23:56:33,380:INFO:_master_model_container: 3
2024-01-17 23:56:33,380:INFO:_display_container: 2
2024-01-17 23:56:33,388:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-17 23:56:33,388:INFO:create_model() successfully completed......................................
2024-01-17 23:56:33,564:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:33,564:INFO:Creating metrics dataframe
2024-01-17 23:56:33,591:INFO:Initializing Decision Tree Classifier
2024-01-17 23:56:33,591:INFO:Total runtime is 0.12551171779632567 minutes
2024-01-17 23:56:33,606:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:33,606:INFO:Initializing create_model()
2024-01-17 23:56:33,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:33,606:INFO:Checking exceptions
2024-01-17 23:56:33,606:INFO:Importing libraries
2024-01-17 23:56:33,606:INFO:Copying training dataset
2024-01-17 23:56:33,619:INFO:Defining folds
2024-01-17 23:56:33,619:INFO:Declaring metric variables
2024-01-17 23:56:33,627:INFO:Importing untrained model
2024-01-17 23:56:33,635:INFO:Decision Tree Classifier Imported successfully
2024-01-17 23:56:33,652:INFO:Starting cross validation
2024-01-17 23:56:33,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:33,806:INFO:Calculating mean and std
2024-01-17 23:56:33,810:INFO:Creating metrics dataframe
2024-01-17 23:56:33,823:INFO:Uploading results into container
2024-01-17 23:56:33,823:INFO:Uploading model into container now
2024-01-17 23:56:33,823:INFO:_master_model_container: 4
2024-01-17 23:56:33,823:INFO:_display_container: 2
2024-01-17 23:56:33,823:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3515, splitter='best')
2024-01-17 23:56:33,823:INFO:create_model() successfully completed......................................
2024-01-17 23:56:33,989:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:33,989:INFO:Creating metrics dataframe
2024-01-17 23:56:34,022:INFO:Initializing SVM - Linear Kernel
2024-01-17 23:56:34,022:INFO:Total runtime is 0.1327081282933553 minutes
2024-01-17 23:56:34,029:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:34,029:INFO:Initializing create_model()
2024-01-17 23:56:34,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:34,029:INFO:Checking exceptions
2024-01-17 23:56:34,038:INFO:Importing libraries
2024-01-17 23:56:34,038:INFO:Copying training dataset
2024-01-17 23:56:34,046:INFO:Defining folds
2024-01-17 23:56:34,046:INFO:Declaring metric variables
2024-01-17 23:56:34,056:INFO:Importing untrained model
2024-01-17 23:56:34,068:INFO:SVM - Linear Kernel Imported successfully
2024-01-17 23:56:34,089:INFO:Starting cross validation
2024-01-17 23:56:34,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:34,156:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:56:34,172:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:56:34,211:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:56:34,211:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:56:34,227:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:56:34,227:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:56:34,290:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:56:34,290:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-17 23:56:34,313:INFO:Calculating mean and std
2024-01-17 23:56:34,321:INFO:Creating metrics dataframe
2024-01-17 23:56:34,321:INFO:Uploading results into container
2024-01-17 23:56:34,321:INFO:Uploading model into container now
2024-01-17 23:56:34,321:INFO:_master_model_container: 5
2024-01-17 23:56:34,321:INFO:_display_container: 2
2024-01-17 23:56:34,337:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3515, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-17 23:56:34,337:INFO:create_model() successfully completed......................................
2024-01-17 23:56:34,474:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:34,474:INFO:Creating metrics dataframe
2024-01-17 23:56:34,513:INFO:Initializing Ridge Classifier
2024-01-17 23:56:34,513:INFO:Total runtime is 0.14089093605677286 minutes
2024-01-17 23:56:34,526:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:34,526:INFO:Initializing create_model()
2024-01-17 23:56:34,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:34,526:INFO:Checking exceptions
2024-01-17 23:56:34,526:INFO:Importing libraries
2024-01-17 23:56:34,526:INFO:Copying training dataset
2024-01-17 23:56:34,546:INFO:Defining folds
2024-01-17 23:56:34,546:INFO:Declaring metric variables
2024-01-17 23:56:34,558:INFO:Importing untrained model
2024-01-17 23:56:34,562:INFO:Ridge Classifier Imported successfully
2024-01-17 23:56:34,589:INFO:Starting cross validation
2024-01-17 23:56:34,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:34,672:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,673:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,683:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,690:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,761:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,761:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,792:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,808:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,808:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,823:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-17 23:56:34,858:INFO:Calculating mean and std
2024-01-17 23:56:34,858:INFO:Creating metrics dataframe
2024-01-17 23:56:34,858:INFO:Uploading results into container
2024-01-17 23:56:34,871:INFO:Uploading model into container now
2024-01-17 23:56:34,871:INFO:_master_model_container: 6
2024-01-17 23:56:34,871:INFO:_display_container: 2
2024-01-17 23:56:34,871:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3515, solver='auto',
                tol=0.0001)
2024-01-17 23:56:34,871:INFO:create_model() successfully completed......................................
2024-01-17 23:56:35,008:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:35,008:INFO:Creating metrics dataframe
2024-01-17 23:56:35,041:INFO:Initializing Random Forest Classifier
2024-01-17 23:56:35,041:INFO:Total runtime is 0.1496820370356242 minutes
2024-01-17 23:56:35,050:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:35,056:INFO:Initializing create_model()
2024-01-17 23:56:35,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:35,056:INFO:Checking exceptions
2024-01-17 23:56:35,056:INFO:Importing libraries
2024-01-17 23:56:35,056:INFO:Copying training dataset
2024-01-17 23:56:35,064:INFO:Defining folds
2024-01-17 23:56:35,064:INFO:Declaring metric variables
2024-01-17 23:56:35,075:INFO:Importing untrained model
2024-01-17 23:56:35,084:INFO:Random Forest Classifier Imported successfully
2024-01-17 23:56:35,092:INFO:Starting cross validation
2024-01-17 23:56:35,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:37,561:INFO:Calculating mean and std
2024-01-17 23:56:37,561:INFO:Creating metrics dataframe
2024-01-17 23:56:37,574:INFO:Uploading results into container
2024-01-17 23:56:37,574:INFO:Uploading model into container now
2024-01-17 23:56:37,574:INFO:_master_model_container: 7
2024-01-17 23:56:37,574:INFO:_display_container: 2
2024-01-17 23:56:37,574:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3515, verbose=0, warm_start=False)
2024-01-17 23:56:37,574:INFO:create_model() successfully completed......................................
2024-01-17 23:56:37,722:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:37,722:INFO:Creating metrics dataframe
2024-01-17 23:56:37,762:INFO:Initializing Quadratic Discriminant Analysis
2024-01-17 23:56:37,762:INFO:Total runtime is 0.19504209756851196 minutes
2024-01-17 23:56:37,772:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:37,778:INFO:Initializing create_model()
2024-01-17 23:56:37,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:37,778:INFO:Checking exceptions
2024-01-17 23:56:37,778:INFO:Importing libraries
2024-01-17 23:56:37,778:INFO:Copying training dataset
2024-01-17 23:56:37,789:INFO:Defining folds
2024-01-17 23:56:37,792:INFO:Declaring metric variables
2024-01-17 23:56:37,795:INFO:Importing untrained model
2024-01-17 23:56:37,810:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-17 23:56:37,825:INFO:Starting cross validation
2024-01-17 23:56:37,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:37,880:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:37,897:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:37,897:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:37,914:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:56:37,924:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:37,973:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:37,980:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:38,026:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:38,026:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:38,042:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:38,058:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-17 23:56:38,073:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:56:38,090:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:56:38,105:INFO:Calculating mean and std
2024-01-17 23:56:38,105:INFO:Creating metrics dataframe
2024-01-17 23:56:38,120:INFO:Uploading results into container
2024-01-17 23:56:38,120:INFO:Uploading model into container now
2024-01-17 23:56:38,120:INFO:_master_model_container: 8
2024-01-17 23:56:38,120:INFO:_display_container: 2
2024-01-17 23:56:38,120:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-17 23:56:38,120:INFO:create_model() successfully completed......................................
2024-01-17 23:56:38,275:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:38,275:INFO:Creating metrics dataframe
2024-01-17 23:56:38,299:INFO:Initializing Ada Boost Classifier
2024-01-17 23:56:38,299:INFO:Total runtime is 0.20398550828297932 minutes
2024-01-17 23:56:38,314:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:38,314:INFO:Initializing create_model()
2024-01-17 23:56:38,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:38,314:INFO:Checking exceptions
2024-01-17 23:56:38,314:INFO:Importing libraries
2024-01-17 23:56:38,314:INFO:Copying training dataset
2024-01-17 23:56:38,322:INFO:Defining folds
2024-01-17 23:56:38,322:INFO:Declaring metric variables
2024-01-17 23:56:38,333:INFO:Importing untrained model
2024-01-17 23:56:38,338:INFO:Ada Boost Classifier Imported successfully
2024-01-17 23:56:38,346:INFO:Starting cross validation
2024-01-17 23:56:38,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:39,860:INFO:Calculating mean and std
2024-01-17 23:56:39,860:INFO:Creating metrics dataframe
2024-01-17 23:56:39,884:INFO:Uploading results into container
2024-01-17 23:56:39,891:INFO:Uploading model into container now
2024-01-17 23:56:39,891:INFO:_master_model_container: 9
2024-01-17 23:56:39,891:INFO:_display_container: 2
2024-01-17 23:56:39,891:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3515)
2024-01-17 23:56:39,891:INFO:create_model() successfully completed......................................
2024-01-17 23:56:40,060:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:40,060:INFO:Creating metrics dataframe
2024-01-17 23:56:40,097:INFO:Initializing Gradient Boosting Classifier
2024-01-17 23:56:40,097:INFO:Total runtime is 0.2339540680249532 minutes
2024-01-17 23:56:40,106:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:40,106:INFO:Initializing create_model()
2024-01-17 23:56:40,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:40,106:INFO:Checking exceptions
2024-01-17 23:56:40,106:INFO:Importing libraries
2024-01-17 23:56:40,106:INFO:Copying training dataset
2024-01-17 23:56:40,116:INFO:Defining folds
2024-01-17 23:56:40,116:INFO:Declaring metric variables
2024-01-17 23:56:40,122:INFO:Importing untrained model
2024-01-17 23:56:40,139:INFO:Gradient Boosting Classifier Imported successfully
2024-01-17 23:56:40,155:INFO:Starting cross validation
2024-01-17 23:56:40,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:41,786:INFO:Calculating mean and std
2024-01-17 23:56:41,786:INFO:Creating metrics dataframe
2024-01-17 23:56:41,801:INFO:Uploading results into container
2024-01-17 23:56:41,801:INFO:Uploading model into container now
2024-01-17 23:56:41,801:INFO:_master_model_container: 10
2024-01-17 23:56:41,801:INFO:_display_container: 2
2024-01-17 23:56:41,801:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3515, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-17 23:56:41,801:INFO:create_model() successfully completed......................................
2024-01-17 23:56:41,969:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:41,969:INFO:Creating metrics dataframe
2024-01-17 23:56:41,994:INFO:Initializing Linear Discriminant Analysis
2024-01-17 23:56:41,994:INFO:Total runtime is 0.26557646195093787 minutes
2024-01-17 23:56:42,005:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:42,010:INFO:Initializing create_model()
2024-01-17 23:56:42,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:42,010:INFO:Checking exceptions
2024-01-17 23:56:42,011:INFO:Importing libraries
2024-01-17 23:56:42,011:INFO:Copying training dataset
2024-01-17 23:56:42,018:INFO:Defining folds
2024-01-17 23:56:42,018:INFO:Declaring metric variables
2024-01-17 23:56:42,030:INFO:Importing untrained model
2024-01-17 23:56:42,055:INFO:Linear Discriminant Analysis Imported successfully
2024-01-17 23:56:42,082:INFO:Starting cross validation
2024-01-17 23:56:42,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:42,444:INFO:Calculating mean and std
2024-01-17 23:56:42,452:INFO:Creating metrics dataframe
2024-01-17 23:56:42,459:INFO:Uploading results into container
2024-01-17 23:56:42,466:INFO:Uploading model into container now
2024-01-17 23:56:42,466:INFO:_master_model_container: 11
2024-01-17 23:56:42,466:INFO:_display_container: 2
2024-01-17 23:56:42,466:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-17 23:56:42,466:INFO:create_model() successfully completed......................................
2024-01-17 23:56:42,656:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:42,656:INFO:Creating metrics dataframe
2024-01-17 23:56:42,706:INFO:Initializing Extra Trees Classifier
2024-01-17 23:56:42,706:INFO:Total runtime is 0.27743671337763465 minutes
2024-01-17 23:56:42,714:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:42,714:INFO:Initializing create_model()
2024-01-17 23:56:42,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:42,722:INFO:Checking exceptions
2024-01-17 23:56:42,722:INFO:Importing libraries
2024-01-17 23:56:42,722:INFO:Copying training dataset
2024-01-17 23:56:42,727:INFO:Defining folds
2024-01-17 23:56:42,727:INFO:Declaring metric variables
2024-01-17 23:56:42,746:INFO:Importing untrained model
2024-01-17 23:56:42,756:INFO:Extra Trees Classifier Imported successfully
2024-01-17 23:56:42,770:INFO:Starting cross validation
2024-01-17 23:56:42,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:45,429:INFO:Calculating mean and std
2024-01-17 23:56:45,429:INFO:Creating metrics dataframe
2024-01-17 23:56:45,443:INFO:Uploading results into container
2024-01-17 23:56:45,449:INFO:Uploading model into container now
2024-01-17 23:56:45,450:INFO:_master_model_container: 12
2024-01-17 23:56:45,452:INFO:_display_container: 2
2024-01-17 23:56:45,452:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3515, verbose=0, warm_start=False)
2024-01-17 23:56:45,452:INFO:create_model() successfully completed......................................
2024-01-17 23:56:45,624:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:45,624:INFO:Creating metrics dataframe
2024-01-17 23:56:45,655:INFO:Initializing Extreme Gradient Boosting
2024-01-17 23:56:45,655:INFO:Total runtime is 0.3265868624051412 minutes
2024-01-17 23:56:45,672:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:45,672:INFO:Initializing create_model()
2024-01-17 23:56:45,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:45,672:INFO:Checking exceptions
2024-01-17 23:56:45,672:INFO:Importing libraries
2024-01-17 23:56:45,672:INFO:Copying training dataset
2024-01-17 23:56:45,682:INFO:Defining folds
2024-01-17 23:56:45,682:INFO:Declaring metric variables
2024-01-17 23:56:45,695:INFO:Importing untrained model
2024-01-17 23:56:45,707:INFO:Extreme Gradient Boosting Imported successfully
2024-01-17 23:56:45,722:INFO:Starting cross validation
2024-01-17 23:56:45,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:46,619:INFO:Calculating mean and std
2024-01-17 23:56:46,619:INFO:Creating metrics dataframe
2024-01-17 23:56:46,634:INFO:Uploading results into container
2024-01-17 23:56:46,634:INFO:Uploading model into container now
2024-01-17 23:56:46,634:INFO:_master_model_container: 13
2024-01-17 23:56:46,634:INFO:_display_container: 2
2024-01-17 23:56:46,634:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-17 23:56:46,634:INFO:create_model() successfully completed......................................
2024-01-17 23:56:46,818:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:46,818:INFO:Creating metrics dataframe
2024-01-17 23:56:46,855:INFO:Initializing Light Gradient Boosting Machine
2024-01-17 23:56:46,855:INFO:Total runtime is 0.3465877612431844 minutes
2024-01-17 23:56:46,872:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:46,872:INFO:Initializing create_model()
2024-01-17 23:56:46,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:46,872:INFO:Checking exceptions
2024-01-17 23:56:46,872:INFO:Importing libraries
2024-01-17 23:56:46,872:INFO:Copying training dataset
2024-01-17 23:56:46,879:INFO:Defining folds
2024-01-17 23:56:46,883:INFO:Declaring metric variables
2024-01-17 23:56:46,889:INFO:Importing untrained model
2024-01-17 23:56:46,889:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-17 23:56:46,921:INFO:Starting cross validation
2024-01-17 23:56:46,922:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:56:48,836:INFO:Calculating mean and std
2024-01-17 23:56:48,851:INFO:Creating metrics dataframe
2024-01-17 23:56:48,851:INFO:Uploading results into container
2024-01-17 23:56:48,866:INFO:Uploading model into container now
2024-01-17 23:56:48,866:INFO:_master_model_container: 14
2024-01-17 23:56:48,866:INFO:_display_container: 2
2024-01-17 23:56:48,866:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3515, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-17 23:56:48,866:INFO:create_model() successfully completed......................................
2024-01-17 23:56:49,024:INFO:SubProcess create_model() end ==================================
2024-01-17 23:56:49,024:INFO:Creating metrics dataframe
2024-01-17 23:56:49,072:INFO:Initializing CatBoost Classifier
2024-01-17 23:56:49,072:INFO:Total runtime is 0.38354315360387164 minutes
2024-01-17 23:56:49,086:INFO:SubProcess create_model() called ==================================
2024-01-17 23:56:49,088:INFO:Initializing create_model()
2024-01-17 23:56:49,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:56:49,088:INFO:Checking exceptions
2024-01-17 23:56:49,088:INFO:Importing libraries
2024-01-17 23:56:49,088:INFO:Copying training dataset
2024-01-17 23:56:49,091:INFO:Defining folds
2024-01-17 23:56:49,097:INFO:Declaring metric variables
2024-01-17 23:56:49,106:INFO:Importing untrained model
2024-01-17 23:56:49,114:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:56:49,130:INFO:Starting cross validation
2024-01-17 23:56:49,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:57:13,713:INFO:Calculating mean and std
2024-01-17 23:57:13,729:INFO:Creating metrics dataframe
2024-01-17 23:57:13,743:INFO:Uploading results into container
2024-01-17 23:57:13,745:INFO:Uploading model into container now
2024-01-17 23:57:13,746:INFO:_master_model_container: 15
2024-01-17 23:57:13,746:INFO:_display_container: 2
2024-01-17 23:57:13,746:INFO:<catboost.core.CatBoostClassifier object at 0x000001FA0A5C4250>
2024-01-17 23:57:13,746:INFO:create_model() successfully completed......................................
2024-01-17 23:57:13,922:INFO:SubProcess create_model() end ==================================
2024-01-17 23:57:13,922:INFO:Creating metrics dataframe
2024-01-17 23:57:13,961:INFO:Initializing Dummy Classifier
2024-01-17 23:57:13,961:INFO:Total runtime is 0.7983611385027567 minutes
2024-01-17 23:57:13,975:INFO:SubProcess create_model() called ==================================
2024-01-17 23:57:13,975:INFO:Initializing create_model()
2024-01-17 23:57:13,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA79045090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:57:13,975:INFO:Checking exceptions
2024-01-17 23:57:13,975:INFO:Importing libraries
2024-01-17 23:57:13,975:INFO:Copying training dataset
2024-01-17 23:57:13,982:INFO:Defining folds
2024-01-17 23:57:13,988:INFO:Declaring metric variables
2024-01-17 23:57:13,994:INFO:Importing untrained model
2024-01-17 23:57:14,000:INFO:Dummy Classifier Imported successfully
2024-01-17 23:57:14,014:INFO:Starting cross validation
2024-01-17 23:57:14,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-17 23:57:14,091:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,120:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,121:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,143:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,175:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,206:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,206:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,238:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,286:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-17 23:57:14,301:INFO:Calculating mean and std
2024-01-17 23:57:14,301:INFO:Creating metrics dataframe
2024-01-17 23:57:14,324:INFO:Uploading results into container
2024-01-17 23:57:14,332:INFO:Uploading model into container now
2024-01-17 23:57:14,332:INFO:_master_model_container: 16
2024-01-17 23:57:14,332:INFO:_display_container: 2
2024-01-17 23:57:14,332:INFO:DummyClassifier(constant=None, random_state=3515, strategy='prior')
2024-01-17 23:57:14,332:INFO:create_model() successfully completed......................................
2024-01-17 23:57:14,497:INFO:SubProcess create_model() end ==================================
2024-01-17 23:57:14,497:INFO:Creating metrics dataframe
2024-01-17 23:57:14,569:INFO:Initializing create_model()
2024-01-17 23:57:14,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5C4250>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:57:14,569:INFO:Checking exceptions
2024-01-17 23:57:14,576:INFO:Importing libraries
2024-01-17 23:57:14,576:INFO:Copying training dataset
2024-01-17 23:57:14,585:INFO:Defining folds
2024-01-17 23:57:14,585:INFO:Declaring metric variables
2024-01-17 23:57:14,585:INFO:Importing untrained model
2024-01-17 23:57:14,585:INFO:Declaring custom model
2024-01-17 23:57:14,585:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:57:14,585:INFO:Cross validation set to False
2024-01-17 23:57:14,585:INFO:Fitting Model
2024-01-17 23:57:23,031:INFO:<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>
2024-01-17 23:57:23,031:INFO:create_model() successfully completed......................................
2024-01-17 23:57:23,264:INFO:_master_model_container: 16
2024-01-17 23:57:23,264:INFO:_display_container: 2
2024-01-17 23:57:23,264:INFO:<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>
2024-01-17 23:57:23,264:INFO:compare_models() successfully completed......................................
2024-01-17 23:57:33,688:INFO:Initializing finalize_model()
2024-01-17 23:57:33,688:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-17 23:57:33,689:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>
2024-01-17 23:57:33,689:INFO:Initializing create_model()
2024-01-17 23:57:33,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-17 23:57:33,689:INFO:Checking exceptions
2024-01-17 23:57:33,704:INFO:Importing libraries
2024-01-17 23:57:33,704:INFO:Copying training dataset
2024-01-17 23:57:33,704:INFO:Defining folds
2024-01-17 23:57:33,704:INFO:Declaring metric variables
2024-01-17 23:57:33,704:INFO:Importing untrained model
2024-01-17 23:57:33,704:INFO:Declaring custom model
2024-01-17 23:57:33,704:INFO:CatBoost Classifier Imported successfully
2024-01-17 23:57:33,704:INFO:Cross validation set to False
2024-01-17 23:57:33,704:INFO:Fitting Model
2024-01-17 23:57:40,577:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001FA0A60BE50>)],
         verbose=False)
2024-01-17 23:57:40,577:INFO:create_model() successfully completed......................................
2024-01-17 23:57:40,749:INFO:_master_model_container: 16
2024-01-17 23:57:40,749:INFO:_display_container: 2
2024-01-17 23:57:40,749:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Sex_female', 'Sex_male',
                                             'Embarked_C', 'Embarked_Q',
                                             'Embarked_S'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001FA0A60BE50>)],
         verbose=False)
2024-01-17 23:57:40,749:INFO:finalize_model() successfully completed......................................
2024-01-17 23:57:52,605:INFO:Initializing evaluate_model()
2024-01-17 23:57:52,605:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-17 23:57:52,643:INFO:Initializing plot_model()
2024-01-17 23:57:52,643:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-17 23:57:52,643:INFO:Checking exceptions
2024-01-17 23:57:52,648:INFO:Preloading libraries
2024-01-17 23:57:52,648:INFO:Copying training dataset
2024-01-17 23:57:52,648:INFO:Plot type: pipeline
2024-01-17 23:57:53,301:INFO:Visual Rendered Successfully
2024-01-17 23:57:53,458:INFO:plot_model() successfully completed......................................
2024-01-17 23:57:54,505:INFO:Initializing predict_model()
2024-01-17 23:57:54,505:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA0A701BC0>)
2024-01-17 23:57:54,505:INFO:Checking exceptions
2024-01-17 23:57:54,505:INFO:Preloading libraries
2024-01-17 23:57:55,994:INFO:Initializing predict_model()
2024-01-17 23:57:55,994:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA0A701A80>)
2024-01-17 23:57:55,994:INFO:Checking exceptions
2024-01-17 23:57:55,994:INFO:Preloading libraries
2024-01-17 23:57:56,000:INFO:Set up data.
2024-01-17 23:57:56,006:INFO:Set up index.
2024-01-18 00:00:50,070:INFO:Initializing plot_model()
2024-01-18 00:00:50,070:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 00:00:50,070:INFO:Checking exceptions
2024-01-18 00:01:04,510:INFO:Initializing plot_model()
2024-01-18 00:01:04,511:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 00:01:04,511:INFO:Checking exceptions
2024-01-18 00:01:04,514:INFO:Preloading libraries
2024-01-18 00:01:04,516:INFO:Copying training dataset
2024-01-18 00:01:04,516:INFO:Plot type: pipeline
2024-01-18 00:01:04,742:INFO:Visual Rendered Successfully
2024-01-18 00:01:04,879:INFO:plot_model() successfully completed......................................
2024-01-18 00:01:11,451:INFO:Initializing plot_model()
2024-01-18 00:01:11,452:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 00:01:11,452:INFO:Checking exceptions
2024-01-18 00:01:11,456:INFO:Preloading libraries
2024-01-18 00:01:11,457:INFO:Copying training dataset
2024-01-18 00:01:11,457:INFO:Plot type: feature_all
2024-01-18 00:01:11,487:WARNING:No coef_ found. Trying feature_importances_
2024-01-18 00:01:11,833:INFO:Visual Rendered Successfully
2024-01-18 00:01:11,943:INFO:plot_model() successfully completed......................................
2024-01-18 00:01:17,834:INFO:Initializing plot_model()
2024-01-18 00:01:17,834:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 00:01:17,835:INFO:Checking exceptions
2024-01-18 00:01:17,839:INFO:Preloading libraries
2024-01-18 00:01:17,841:INFO:Copying training dataset
2024-01-18 00:01:17,841:INFO:Plot type: pr
2024-01-18 00:01:17,912:INFO:Fitting Model
2024-01-18 00:01:18,185:INFO:Scoring test/hold-out set
2024-01-18 00:01:18,542:INFO:Visual Rendered Successfully
2024-01-18 00:01:18,674:INFO:plot_model() successfully completed......................................
2024-01-18 00:01:22,319:INFO:Initializing plot_model()
2024-01-18 00:01:22,320:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 00:01:22,320:INFO:Checking exceptions
2024-01-18 00:01:22,324:INFO:Preloading libraries
2024-01-18 00:01:22,326:INFO:Copying training dataset
2024-01-18 00:01:22,326:INFO:Plot type: gain
2024-01-18 00:01:22,327:INFO:Generating predictions / predict_proba on X_test
2024-01-18 00:01:22,683:INFO:Visual Rendered Successfully
2024-01-18 00:01:22,794:INFO:plot_model() successfully completed......................................
2024-01-18 00:01:27,614:INFO:Initializing plot_model()
2024-01-18 00:01:27,614:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, plot=vc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 00:01:27,614:INFO:Checking exceptions
2024-01-18 00:01:27,617:INFO:Preloading libraries
2024-01-18 00:01:27,618:INFO:Copying training dataset
2024-01-18 00:01:27,618:INFO:Plot type: vc
2024-01-18 00:01:27,619:INFO:Determining param_name
2024-01-18 00:01:27,677:INFO:param_name: depth
2024-01-18 00:01:27,857:INFO:Fitting Model
2024-01-18 00:03:24,746:INFO:Visual Rendered Successfully
2024-01-18 00:03:24,876:INFO:plot_model() successfully completed......................................
2024-01-18 00:03:24,902:INFO:Initializing plot_model()
2024-01-18 00:03:24,903:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, plot=class_report, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 00:03:24,903:INFO:Checking exceptions
2024-01-18 00:03:24,905:INFO:Preloading libraries
2024-01-18 00:03:24,907:INFO:Copying training dataset
2024-01-18 00:03:24,907:INFO:Plot type: class_report
2024-01-18 00:03:24,988:INFO:Fitting Model
2024-01-18 00:03:24,989:INFO:Scoring test/hold-out set
2024-01-18 00:03:25,385:INFO:Visual Rendered Successfully
2024-01-18 00:03:25,506:INFO:plot_model() successfully completed......................................
2024-01-18 00:03:42,224:INFO:Initializing plot_model()
2024-01-18 00:03:42,225:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA0A5EF090>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FA0A5B5ED0>, plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 00:03:42,225:INFO:Checking exceptions
2024-01-18 00:03:42,230:INFO:Preloading libraries
2024-01-18 00:03:42,231:INFO:Copying training dataset
2024-01-18 00:03:42,231:INFO:Plot type: pipeline
2024-01-18 00:03:42,469:INFO:Visual Rendered Successfully
2024-01-18 00:03:42,625:INFO:plot_model() successfully completed......................................
2024-01-18 10:48:30,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 10:48:30,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 10:48:30,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 10:48:30,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 11:03:24,943:INFO:PyCaret ClassificationExperiment
2024-01-18 11:03:24,943:INFO:Logging name: clf-default-name
2024-01-18 11:03:24,943:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:03:24,943:INFO:version 3.2.0
2024-01-18 11:03:24,943:INFO:Initializing setup()
2024-01-18 11:03:24,943:INFO:self.USI: e403
2024-01-18 11:03:24,943:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:03:24,943:INFO:Checking environment
2024-01-18 11:03:24,943:INFO:python_version: 3.11.5
2024-01-18 11:03:24,943:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:03:24,943:INFO:machine: AMD64
2024-01-18 11:03:24,943:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:03:24,943:INFO:Memory: svmem(total=8361132032, available=1567399936, percent=81.3, used=6793732096, free=1567399936)
2024-01-18 11:03:24,943:INFO:Physical Core: 2
2024-01-18 11:03:24,943:INFO:Logical Core: 4
2024-01-18 11:03:24,943:INFO:Checking libraries
2024-01-18 11:03:24,943:INFO:System:
2024-01-18 11:03:24,943:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:03:24,943:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:03:24,943:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:03:24,943:INFO:PyCaret required dependencies:
2024-01-18 11:03:24,959:INFO:                 pip: 23.2.1
2024-01-18 11:03:24,959:INFO:          setuptools: 68.0.0
2024-01-18 11:03:24,959:INFO:             pycaret: 3.2.0
2024-01-18 11:03:24,959:INFO:             IPython: 8.15.0
2024-01-18 11:03:24,959:INFO:          ipywidgets: 8.0.4
2024-01-18 11:03:24,959:INFO:                tqdm: 4.65.0
2024-01-18 11:03:24,959:INFO:               numpy: 1.24.3
2024-01-18 11:03:24,959:INFO:              pandas: 1.5.3
2024-01-18 11:03:24,959:INFO:              jinja2: 3.1.2
2024-01-18 11:03:24,959:INFO:               scipy: 1.10.1
2024-01-18 11:03:24,959:INFO:              joblib: 1.2.0
2024-01-18 11:03:24,959:INFO:             sklearn: 1.2.2
2024-01-18 11:03:24,959:INFO:                pyod: 1.1.2
2024-01-18 11:03:24,959:INFO:            imblearn: 0.10.1
2024-01-18 11:03:24,959:INFO:   category_encoders: 2.6.3
2024-01-18 11:03:24,959:INFO:            lightgbm: 4.2.0
2024-01-18 11:03:24,959:INFO:               numba: 0.57.1
2024-01-18 11:03:24,959:INFO:            requests: 2.31.0
2024-01-18 11:03:24,959:INFO:          matplotlib: 3.6.0
2024-01-18 11:03:24,959:INFO:          scikitplot: 0.3.7
2024-01-18 11:03:24,959:INFO:         yellowbrick: 1.5
2024-01-18 11:03:24,959:INFO:              plotly: 5.9.0
2024-01-18 11:03:24,959:INFO:    plotly-resampler: Not installed
2024-01-18 11:03:24,959:INFO:             kaleido: 0.2.1
2024-01-18 11:03:24,959:INFO:           schemdraw: 0.15
2024-01-18 11:03:24,959:INFO:         statsmodels: 0.14.0
2024-01-18 11:03:24,959:INFO:              sktime: 0.21.1
2024-01-18 11:03:24,959:INFO:               tbats: 1.1.3
2024-01-18 11:03:24,959:INFO:            pmdarima: 2.0.4
2024-01-18 11:03:24,959:INFO:              psutil: 5.9.0
2024-01-18 11:03:24,959:INFO:          markupsafe: 2.1.1
2024-01-18 11:03:24,959:INFO:             pickle5: Not installed
2024-01-18 11:03:24,959:INFO:         cloudpickle: 2.2.1
2024-01-18 11:03:24,959:INFO:         deprecation: 2.1.0
2024-01-18 11:03:24,959:INFO:              xxhash: 2.0.2
2024-01-18 11:03:24,959:INFO:           wurlitzer: Not installed
2024-01-18 11:03:24,959:INFO:PyCaret optional dependencies:
2024-01-18 11:03:24,990:INFO:                shap: Not installed
2024-01-18 11:03:24,990:INFO:           interpret: Not installed
2024-01-18 11:03:24,990:INFO:                umap: Not installed
2024-01-18 11:03:24,990:INFO:     ydata_profiling: Not installed
2024-01-18 11:03:24,990:INFO:  explainerdashboard: Not installed
2024-01-18 11:03:24,990:INFO:             autoviz: Not installed
2024-01-18 11:03:24,990:INFO:           fairlearn: Not installed
2024-01-18 11:03:24,990:INFO:          deepchecks: Not installed
2024-01-18 11:03:24,990:INFO:             xgboost: 2.0.3
2024-01-18 11:03:24,990:INFO:            catboost: 1.2.2
2024-01-18 11:03:24,990:INFO:              kmodes: Not installed
2024-01-18 11:03:24,990:INFO:             mlxtend: Not installed
2024-01-18 11:03:24,990:INFO:       statsforecast: Not installed
2024-01-18 11:03:24,990:INFO:        tune_sklearn: Not installed
2024-01-18 11:03:24,990:INFO:                 ray: Not installed
2024-01-18 11:03:24,990:INFO:            hyperopt: Not installed
2024-01-18 11:03:24,990:INFO:              optuna: 3.5.0
2024-01-18 11:03:24,990:INFO:               skopt: Not installed
2024-01-18 11:03:24,990:INFO:              mlflow: Not installed
2024-01-18 11:03:24,990:INFO:              gradio: Not installed
2024-01-18 11:03:24,990:INFO:             fastapi: Not installed
2024-01-18 11:03:24,990:INFO:             uvicorn: Not installed
2024-01-18 11:03:24,990:INFO:              m2cgen: Not installed
2024-01-18 11:03:24,990:INFO:           evidently: Not installed
2024-01-18 11:03:24,990:INFO:               fugue: Not installed
2024-01-18 11:03:24,990:INFO:           streamlit: Not installed
2024-01-18 11:03:24,990:INFO:             prophet: Not installed
2024-01-18 11:03:24,990:INFO:None
2024-01-18 11:03:24,990:INFO:Set up data.
2024-01-18 11:03:25,027:INFO:Set up folding strategy.
2024-01-18 11:03:25,027:INFO:Set up train/test split.
2024-01-18 11:03:25,038:INFO:Set up index.
2024-01-18 11:03:25,038:INFO:Assigning column types.
2024-01-18 11:03:25,038:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 11:03:25,086:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:03:25,112:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:03:25,282:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:03:25,282:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:03:25,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:03:25,360:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:03:25,392:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:03:25,408:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:03:25,408:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 11:03:25,470:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:03:25,501:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:03:25,501:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:03:25,580:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:03:25,627:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:03:25,627:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:03:25,627:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 11:03:25,810:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:03:25,813:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:03:25,888:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:03:26,207:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:03:26,301:INFO:Preparing preprocessing pipeline...
2024-01-18 11:03:26,332:INFO:Set up simple imputation.
2024-01-18 11:03:26,348:INFO:Set up column name cleaning.
2024-01-18 11:03:26,395:INFO:Finished creating preprocessing pipeline.
2024-01-18 11:03:26,450:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CryoSleep', 'Age', 'VIP',
                                             'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck',
                                             'HomePlanet_Earth',
                                             'HomePlanet_Europa',
                                             'HomePlanet_Mars',
                                             'Destination_55 Cancri e',
                                             'Destination_PSO J318.5-22',
                                             'Destination_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 11:03:26,450:INFO:Creating final display dataframe.
2024-01-18 11:03:26,581:INFO:Setup _display_container:                     Description             Value
0                    Session id              2956
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Numeric features                14
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e403
2024-01-18 11:03:26,688:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:03:26,693:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:03:26,797:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:03:26,801:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:03:26,804:INFO:setup() successfully completed in 2.06s...............
2024-01-18 11:03:39,495:INFO:Initializing compare_models()
2024-01-18 11:03:39,495:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-18 11:03:39,495:INFO:Checking exceptions
2024-01-18 11:03:39,506:INFO:Preparing display monitor
2024-01-18 11:03:39,549:INFO:Initializing Logistic Regression
2024-01-18 11:03:39,550:INFO:Total runtime is 0.0 minutes
2024-01-18 11:03:39,564:INFO:SubProcess create_model() called ==================================
2024-01-18 11:03:39,565:INFO:Initializing create_model()
2024-01-18 11:03:39,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:03:39,567:INFO:Checking exceptions
2024-01-18 11:03:39,567:INFO:Importing libraries
2024-01-18 11:03:39,567:INFO:Copying training dataset
2024-01-18 11:03:39,578:INFO:Defining folds
2024-01-18 11:03:39,578:INFO:Declaring metric variables
2024-01-18 11:03:39,594:INFO:Importing untrained model
2024-01-18 11:03:39,603:INFO:Logistic Regression Imported successfully
2024-01-18 11:03:39,617:INFO:Starting cross validation
2024-01-18 11:03:39,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:35,203:INFO:Calculating mean and std
2024-01-18 11:04:35,206:INFO:Creating metrics dataframe
2024-01-18 11:04:35,212:INFO:Uploading results into container
2024-01-18 11:04:35,214:INFO:Uploading model into container now
2024-01-18 11:04:35,216:INFO:_master_model_container: 1
2024-01-18 11:04:35,216:INFO:_display_container: 2
2024-01-18 11:04:35,217:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2956, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-18 11:04:35,217:INFO:create_model() successfully completed......................................
2024-01-18 11:04:35,374:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:35,375:INFO:Creating metrics dataframe
2024-01-18 11:04:35,391:INFO:Initializing K Neighbors Classifier
2024-01-18 11:04:35,391:INFO:Total runtime is 0.9307047486305237 minutes
2024-01-18 11:04:35,391:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:35,391:INFO:Initializing create_model()
2024-01-18 11:04:35,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:35,391:INFO:Checking exceptions
2024-01-18 11:04:35,391:INFO:Importing libraries
2024-01-18 11:04:35,391:INFO:Copying training dataset
2024-01-18 11:04:35,410:INFO:Defining folds
2024-01-18 11:04:35,410:INFO:Declaring metric variables
2024-01-18 11:04:35,410:INFO:Importing untrained model
2024-01-18 11:04:35,422:INFO:K Neighbors Classifier Imported successfully
2024-01-18 11:04:35,436:INFO:Starting cross validation
2024-01-18 11:04:35,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:36,381:INFO:Calculating mean and std
2024-01-18 11:04:36,381:INFO:Creating metrics dataframe
2024-01-18 11:04:36,381:INFO:Uploading results into container
2024-01-18 11:04:36,381:INFO:Uploading model into container now
2024-01-18 11:04:36,381:INFO:_master_model_container: 2
2024-01-18 11:04:36,381:INFO:_display_container: 2
2024-01-18 11:04:36,381:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-18 11:04:36,381:INFO:create_model() successfully completed......................................
2024-01-18 11:04:36,521:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:36,521:INFO:Creating metrics dataframe
2024-01-18 11:04:36,543:INFO:Initializing Naive Bayes
2024-01-18 11:04:36,544:INFO:Total runtime is 0.9499180912971497 minutes
2024-01-18 11:04:36,549:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:36,550:INFO:Initializing create_model()
2024-01-18 11:04:36,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:36,550:INFO:Checking exceptions
2024-01-18 11:04:36,551:INFO:Importing libraries
2024-01-18 11:04:36,551:INFO:Copying training dataset
2024-01-18 11:04:36,561:INFO:Defining folds
2024-01-18 11:04:36,561:INFO:Declaring metric variables
2024-01-18 11:04:36,568:INFO:Importing untrained model
2024-01-18 11:04:36,585:INFO:Naive Bayes Imported successfully
2024-01-18 11:04:36,598:INFO:Starting cross validation
2024-01-18 11:04:36,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:36,797:INFO:Calculating mean and std
2024-01-18 11:04:36,799:INFO:Creating metrics dataframe
2024-01-18 11:04:36,805:INFO:Uploading results into container
2024-01-18 11:04:36,808:INFO:Uploading model into container now
2024-01-18 11:04:36,808:INFO:_master_model_container: 3
2024-01-18 11:04:36,808:INFO:_display_container: 2
2024-01-18 11:04:36,808:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-18 11:04:36,808:INFO:create_model() successfully completed......................................
2024-01-18 11:04:36,944:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:36,944:INFO:Creating metrics dataframe
2024-01-18 11:04:36,967:INFO:Initializing Decision Tree Classifier
2024-01-18 11:04:36,967:INFO:Total runtime is 0.9569695234298706 minutes
2024-01-18 11:04:36,974:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:36,974:INFO:Initializing create_model()
2024-01-18 11:04:36,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:36,989:INFO:Checking exceptions
2024-01-18 11:04:36,989:INFO:Importing libraries
2024-01-18 11:04:36,989:INFO:Copying training dataset
2024-01-18 11:04:37,004:INFO:Defining folds
2024-01-18 11:04:37,004:INFO:Declaring metric variables
2024-01-18 11:04:37,010:INFO:Importing untrained model
2024-01-18 11:04:37,017:INFO:Decision Tree Classifier Imported successfully
2024-01-18 11:04:37,064:INFO:Starting cross validation
2024-01-18 11:04:37,064:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:37,391:INFO:Calculating mean and std
2024-01-18 11:04:37,393:INFO:Creating metrics dataframe
2024-01-18 11:04:37,399:INFO:Uploading results into container
2024-01-18 11:04:37,400:INFO:Uploading model into container now
2024-01-18 11:04:37,401:INFO:_master_model_container: 4
2024-01-18 11:04:37,401:INFO:_display_container: 2
2024-01-18 11:04:37,402:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2956, splitter='best')
2024-01-18 11:04:37,402:INFO:create_model() successfully completed......................................
2024-01-18 11:04:37,543:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:37,543:INFO:Creating metrics dataframe
2024-01-18 11:04:37,563:INFO:Initializing SVM - Linear Kernel
2024-01-18 11:04:37,564:INFO:Total runtime is 0.9669216950734456 minutes
2024-01-18 11:04:37,570:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:37,571:INFO:Initializing create_model()
2024-01-18 11:04:37,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:37,571:INFO:Checking exceptions
2024-01-18 11:04:37,571:INFO:Importing libraries
2024-01-18 11:04:37,572:INFO:Copying training dataset
2024-01-18 11:04:37,592:INFO:Defining folds
2024-01-18 11:04:37,593:INFO:Declaring metric variables
2024-01-18 11:04:37,600:INFO:Importing untrained model
2024-01-18 11:04:37,613:INFO:SVM - Linear Kernel Imported successfully
2024-01-18 11:04:37,626:INFO:Starting cross validation
2024-01-18 11:04:37,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:38,107:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,107:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,107:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,154:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,217:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,217:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,217:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,232:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,297:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,306:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:04:38,315:INFO:Calculating mean and std
2024-01-18 11:04:38,329:INFO:Creating metrics dataframe
2024-01-18 11:04:38,336:INFO:Uploading results into container
2024-01-18 11:04:38,338:INFO:Uploading model into container now
2024-01-18 11:04:38,339:INFO:_master_model_container: 5
2024-01-18 11:04:38,339:INFO:_display_container: 2
2024-01-18 11:04:38,339:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2956, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-18 11:04:38,339:INFO:create_model() successfully completed......................................
2024-01-18 11:04:38,469:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:38,469:INFO:Creating metrics dataframe
2024-01-18 11:04:38,499:INFO:Initializing Ridge Classifier
2024-01-18 11:04:38,499:INFO:Total runtime is 0.9824977954228719 minutes
2024-01-18 11:04:38,506:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:38,506:INFO:Initializing create_model()
2024-01-18 11:04:38,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:38,506:INFO:Checking exceptions
2024-01-18 11:04:38,507:INFO:Importing libraries
2024-01-18 11:04:38,507:INFO:Copying training dataset
2024-01-18 11:04:38,521:INFO:Defining folds
2024-01-18 11:04:38,521:INFO:Declaring metric variables
2024-01-18 11:04:38,529:INFO:Importing untrained model
2024-01-18 11:04:38,534:INFO:Ridge Classifier Imported successfully
2024-01-18 11:04:38,550:INFO:Starting cross validation
2024-01-18 11:04:38,552:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:44,031:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:04:44,031:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:04:44,031:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:04:44,036:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:04:44,082:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:04:44,082:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:04:44,082:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:04:44,130:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:04:44,130:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:04:44,145:INFO:Calculating mean and std
2024-01-18 11:04:44,145:INFO:Creating metrics dataframe
2024-01-18 11:04:44,145:INFO:Uploading results into container
2024-01-18 11:04:44,145:INFO:Uploading model into container now
2024-01-18 11:04:44,145:INFO:_master_model_container: 6
2024-01-18 11:04:44,145:INFO:_display_container: 2
2024-01-18 11:04:44,145:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2956, solver='auto',
                tol=0.0001)
2024-01-18 11:04:44,145:INFO:create_model() successfully completed......................................
2024-01-18 11:04:44,271:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:44,271:INFO:Creating metrics dataframe
2024-01-18 11:04:44,286:INFO:Initializing Random Forest Classifier
2024-01-18 11:04:44,286:INFO:Total runtime is 1.0789471387863159 minutes
2024-01-18 11:04:44,297:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:44,298:INFO:Initializing create_model()
2024-01-18 11:04:44,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:44,298:INFO:Checking exceptions
2024-01-18 11:04:44,298:INFO:Importing libraries
2024-01-18 11:04:44,298:INFO:Copying training dataset
2024-01-18 11:04:44,307:INFO:Defining folds
2024-01-18 11:04:44,307:INFO:Declaring metric variables
2024-01-18 11:04:44,312:INFO:Importing untrained model
2024-01-18 11:04:44,319:INFO:Random Forest Classifier Imported successfully
2024-01-18 11:04:44,334:INFO:Starting cross validation
2024-01-18 11:04:44,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:47,252:INFO:Calculating mean and std
2024-01-18 11:04:47,252:INFO:Creating metrics dataframe
2024-01-18 11:04:47,264:INFO:Uploading results into container
2024-01-18 11:04:47,266:INFO:Uploading model into container now
2024-01-18 11:04:47,267:INFO:_master_model_container: 7
2024-01-18 11:04:47,267:INFO:_display_container: 2
2024-01-18 11:04:47,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2956, verbose=0, warm_start=False)
2024-01-18 11:04:47,269:INFO:create_model() successfully completed......................................
2024-01-18 11:04:47,404:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:47,404:INFO:Creating metrics dataframe
2024-01-18 11:04:47,423:INFO:Initializing Quadratic Discriminant Analysis
2024-01-18 11:04:47,423:INFO:Total runtime is 1.1312354365984598 minutes
2024-01-18 11:04:47,428:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:47,429:INFO:Initializing create_model()
2024-01-18 11:04:47,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:47,429:INFO:Checking exceptions
2024-01-18 11:04:47,429:INFO:Importing libraries
2024-01-18 11:04:47,430:INFO:Copying training dataset
2024-01-18 11:04:47,439:INFO:Defining folds
2024-01-18 11:04:47,439:INFO:Declaring metric variables
2024-01-18 11:04:47,447:INFO:Importing untrained model
2024-01-18 11:04:47,454:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-18 11:04:47,463:INFO:Starting cross validation
2024-01-18 11:04:47,463:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:53,927:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:04:53,927:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:04:54,021:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:04:54,036:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:04:54,037:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:04:54,037:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:04:54,068:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:04:54,083:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-18 11:04:54,083:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:04:54,099:INFO:Calculating mean and std
2024-01-18 11:04:54,099:INFO:Creating metrics dataframe
2024-01-18 11:04:54,118:INFO:Uploading results into container
2024-01-18 11:04:54,118:INFO:Uploading model into container now
2024-01-18 11:04:54,119:INFO:_master_model_container: 8
2024-01-18 11:04:54,120:INFO:_display_container: 2
2024-01-18 11:04:54,121:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-18 11:04:54,121:INFO:create_model() successfully completed......................................
2024-01-18 11:04:54,250:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:54,250:INFO:Creating metrics dataframe
2024-01-18 11:04:54,273:INFO:Initializing Ada Boost Classifier
2024-01-18 11:04:54,273:INFO:Total runtime is 1.2453998963038126 minutes
2024-01-18 11:04:54,273:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:54,273:INFO:Initializing create_model()
2024-01-18 11:04:54,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:54,273:INFO:Checking exceptions
2024-01-18 11:04:54,273:INFO:Importing libraries
2024-01-18 11:04:54,273:INFO:Copying training dataset
2024-01-18 11:04:54,273:INFO:Defining folds
2024-01-18 11:04:54,273:INFO:Declaring metric variables
2024-01-18 11:04:54,288:INFO:Importing untrained model
2024-01-18 11:04:54,292:INFO:Ada Boost Classifier Imported successfully
2024-01-18 11:04:54,300:INFO:Starting cross validation
2024-01-18 11:04:54,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:55,687:INFO:Calculating mean and std
2024-01-18 11:04:55,687:INFO:Creating metrics dataframe
2024-01-18 11:04:55,705:INFO:Uploading results into container
2024-01-18 11:04:55,706:INFO:Uploading model into container now
2024-01-18 11:04:55,707:INFO:_master_model_container: 9
2024-01-18 11:04:55,707:INFO:_display_container: 2
2024-01-18 11:04:55,708:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2956)
2024-01-18 11:04:55,709:INFO:create_model() successfully completed......................................
2024-01-18 11:04:55,834:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:55,834:INFO:Creating metrics dataframe
2024-01-18 11:04:55,866:INFO:Initializing Gradient Boosting Classifier
2024-01-18 11:04:55,867:INFO:Total runtime is 1.2719670414924622 minutes
2024-01-18 11:04:55,872:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:55,872:INFO:Initializing create_model()
2024-01-18 11:04:55,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:55,873:INFO:Checking exceptions
2024-01-18 11:04:55,873:INFO:Importing libraries
2024-01-18 11:04:55,873:INFO:Copying training dataset
2024-01-18 11:04:55,880:INFO:Defining folds
2024-01-18 11:04:55,880:INFO:Declaring metric variables
2024-01-18 11:04:55,885:INFO:Importing untrained model
2024-01-18 11:04:55,892:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 11:04:55,904:INFO:Starting cross validation
2024-01-18 11:04:55,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:59,026:INFO:Calculating mean and std
2024-01-18 11:04:59,026:INFO:Creating metrics dataframe
2024-01-18 11:04:59,026:INFO:Uploading results into container
2024-01-18 11:04:59,026:INFO:Uploading model into container now
2024-01-18 11:04:59,026:INFO:_master_model_container: 10
2024-01-18 11:04:59,026:INFO:_display_container: 2
2024-01-18 11:04:59,026:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 11:04:59,041:INFO:create_model() successfully completed......................................
2024-01-18 11:04:59,166:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:59,166:INFO:Creating metrics dataframe
2024-01-18 11:04:59,166:INFO:Initializing Linear Discriminant Analysis
2024-01-18 11:04:59,166:INFO:Total runtime is 1.3269572218259176 minutes
2024-01-18 11:04:59,183:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:59,183:INFO:Initializing create_model()
2024-01-18 11:04:59,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:59,183:INFO:Checking exceptions
2024-01-18 11:04:59,183:INFO:Importing libraries
2024-01-18 11:04:59,183:INFO:Copying training dataset
2024-01-18 11:04:59,199:INFO:Defining folds
2024-01-18 11:04:59,199:INFO:Declaring metric variables
2024-01-18 11:04:59,204:INFO:Importing untrained model
2024-01-18 11:04:59,209:INFO:Linear Discriminant Analysis Imported successfully
2024-01-18 11:04:59,218:INFO:Starting cross validation
2024-01-18 11:04:59,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:04:59,528:INFO:Calculating mean and std
2024-01-18 11:04:59,528:INFO:Creating metrics dataframe
2024-01-18 11:04:59,537:INFO:Uploading results into container
2024-01-18 11:04:59,538:INFO:Uploading model into container now
2024-01-18 11:04:59,538:INFO:_master_model_container: 11
2024-01-18 11:04:59,538:INFO:_display_container: 2
2024-01-18 11:04:59,538:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-18 11:04:59,538:INFO:create_model() successfully completed......................................
2024-01-18 11:04:59,652:INFO:SubProcess create_model() end ==================================
2024-01-18 11:04:59,652:INFO:Creating metrics dataframe
2024-01-18 11:04:59,683:INFO:Initializing Extra Trees Classifier
2024-01-18 11:04:59,683:INFO:Total runtime is 1.3355690360069274 minutes
2024-01-18 11:04:59,693:INFO:SubProcess create_model() called ==================================
2024-01-18 11:04:59,693:INFO:Initializing create_model()
2024-01-18 11:04:59,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:04:59,694:INFO:Checking exceptions
2024-01-18 11:04:59,694:INFO:Importing libraries
2024-01-18 11:04:59,694:INFO:Copying training dataset
2024-01-18 11:04:59,707:INFO:Defining folds
2024-01-18 11:04:59,707:INFO:Declaring metric variables
2024-01-18 11:04:59,717:INFO:Importing untrained model
2024-01-18 11:04:59,729:INFO:Extra Trees Classifier Imported successfully
2024-01-18 11:04:59,739:INFO:Starting cross validation
2024-01-18 11:04:59,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:05:02,178:INFO:Calculating mean and std
2024-01-18 11:05:02,178:INFO:Creating metrics dataframe
2024-01-18 11:05:02,178:INFO:Uploading results into container
2024-01-18 11:05:02,178:INFO:Uploading model into container now
2024-01-18 11:05:02,178:INFO:_master_model_container: 12
2024-01-18 11:05:02,178:INFO:_display_container: 2
2024-01-18 11:05:02,178:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2956, verbose=0, warm_start=False)
2024-01-18 11:05:02,178:INFO:create_model() successfully completed......................................
2024-01-18 11:05:02,306:INFO:SubProcess create_model() end ==================================
2024-01-18 11:05:02,306:INFO:Creating metrics dataframe
2024-01-18 11:05:02,338:INFO:Initializing Extreme Gradient Boosting
2024-01-18 11:05:02,338:INFO:Total runtime is 1.3798216978708902 minutes
2024-01-18 11:05:02,338:INFO:SubProcess create_model() called ==================================
2024-01-18 11:05:02,338:INFO:Initializing create_model()
2024-01-18 11:05:02,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:05:02,338:INFO:Checking exceptions
2024-01-18 11:05:02,338:INFO:Importing libraries
2024-01-18 11:05:02,338:INFO:Copying training dataset
2024-01-18 11:05:02,358:INFO:Defining folds
2024-01-18 11:05:02,359:INFO:Declaring metric variables
2024-01-18 11:05:02,365:INFO:Importing untrained model
2024-01-18 11:05:02,374:INFO:Extreme Gradient Boosting Imported successfully
2024-01-18 11:05:02,384:INFO:Starting cross validation
2024-01-18 11:05:02,385:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:05:05,300:INFO:Calculating mean and std
2024-01-18 11:05:05,300:INFO:Creating metrics dataframe
2024-01-18 11:05:05,315:INFO:Uploading results into container
2024-01-18 11:05:05,317:INFO:Uploading model into container now
2024-01-18 11:05:05,318:INFO:_master_model_container: 13
2024-01-18 11:05:05,318:INFO:_display_container: 2
2024-01-18 11:05:05,320:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-18 11:05:05,321:INFO:create_model() successfully completed......................................
2024-01-18 11:05:05,464:INFO:SubProcess create_model() end ==================================
2024-01-18 11:05:05,464:INFO:Creating metrics dataframe
2024-01-18 11:05:05,485:INFO:Initializing Light Gradient Boosting Machine
2024-01-18 11:05:05,485:INFO:Total runtime is 1.4322665135065713 minutes
2024-01-18 11:05:05,490:INFO:SubProcess create_model() called ==================================
2024-01-18 11:05:05,491:INFO:Initializing create_model()
2024-01-18 11:05:05,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:05:05,491:INFO:Checking exceptions
2024-01-18 11:05:05,491:INFO:Importing libraries
2024-01-18 11:05:05,491:INFO:Copying training dataset
2024-01-18 11:05:05,498:INFO:Defining folds
2024-01-18 11:05:05,498:INFO:Declaring metric variables
2024-01-18 11:05:05,503:INFO:Importing untrained model
2024-01-18 11:05:05,510:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 11:05:05,511:INFO:Starting cross validation
2024-01-18 11:05:05,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:05:07,212:INFO:Calculating mean and std
2024-01-18 11:05:07,212:INFO:Creating metrics dataframe
2024-01-18 11:05:07,212:INFO:Uploading results into container
2024-01-18 11:05:07,212:INFO:Uploading model into container now
2024-01-18 11:05:07,212:INFO:_master_model_container: 14
2024-01-18 11:05:07,212:INFO:_display_container: 2
2024-01-18 11:05:07,212:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2956, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 11:05:07,212:INFO:create_model() successfully completed......................................
2024-01-18 11:05:07,335:INFO:SubProcess create_model() end ==================================
2024-01-18 11:05:07,335:INFO:Creating metrics dataframe
2024-01-18 11:05:07,366:INFO:Initializing CatBoost Classifier
2024-01-18 11:05:07,366:INFO:Total runtime is 1.4636109232902526 minutes
2024-01-18 11:05:07,373:INFO:SubProcess create_model() called ==================================
2024-01-18 11:05:07,373:INFO:Initializing create_model()
2024-01-18 11:05:07,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:05:07,374:INFO:Checking exceptions
2024-01-18 11:05:07,374:INFO:Importing libraries
2024-01-18 11:05:07,374:INFO:Copying training dataset
2024-01-18 11:05:07,385:INFO:Defining folds
2024-01-18 11:05:07,386:INFO:Declaring metric variables
2024-01-18 11:05:07,391:INFO:Importing untrained model
2024-01-18 11:05:07,399:INFO:CatBoost Classifier Imported successfully
2024-01-18 11:05:07,410:INFO:Starting cross validation
2024-01-18 11:05:07,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True'2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.p2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:36,278:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

= _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,735:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,750:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,750:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,750:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,750:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,750:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,750:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:45,750:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:05:56,209:INFO:Calculating mean and std
2024-01-18 11:05:56,209:INFO:Creating metrics dataframe
2024-01-18 11:05:56,209:INFO:Uploading results into container
2024-01-18 11:05:56,209:INFO:Uploading model into container now
2024-01-18 11:05:56,209:INFO:_master_model_container: 15
2024-01-18 11:05:56,209:INFO:_display_container: 2
2024-01-18 11:05:56,209:INFO:<catboost.core.CatBoostClassifier object at 0x000001C740956090>
2024-01-18 11:05:56,209:INFO:create_model() successfully completed......................................
2024-01-18 11:05:56,333:INFO:SubProcess create_model() end ==================================
2024-01-18 11:05:56,333:INFO:Creating metrics dataframe
2024-01-18 11:05:56,364:INFO:Initializing Dummy Classifier
2024-01-18 11:05:56,364:INFO:Total runtime is 2.280252754688263 minutes
2024-01-18 11:05:56,364:INFO:SubProcess create_model() called ==================================
2024-01-18 11:05:56,364:INFO:Initializing create_model()
2024-01-18 11:05:56,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C740926E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:05:56,364:INFO:Checking exceptions
2024-01-18 11:05:56,364:INFO:Importing libraries
2024-01-18 11:05:56,364:INFO:Copying training dataset
2024-01-18 11:05:56,383:INFO:Defining folds
2024-01-18 11:05:56,384:INFO:Declaring metric variables
2024-01-18 11:05:56,388:INFO:Importing untrained model
2024-01-18 11:05:56,395:INFO:Dummy Classifier Imported successfully
2024-01-18 11:05:56,404:INFO:Starting cross validation
2024-01-18 11:05:56,406:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:05:56,584:INFO:Calculating mean and std
2024-01-18 11:05:56,584:INFO:Creating metrics dataframe
2024-01-18 11:05:56,584:INFO:Uploading results into container
2024-01-18 11:05:56,584:INFO:Uploading model into container now
2024-01-18 11:05:56,600:INFO:_master_model_container: 16
2024-01-18 11:05:56,600:INFO:_display_container: 2
2024-01-18 11:05:56,601:INFO:DummyClassifier(constant=None, random_state=2956, strategy='prior')
2024-01-18 11:05:56,601:INFO:create_model() successfully completed......................................
2024-01-18 11:05:56,715:INFO:SubProcess create_model() end ==================================
2024-01-18 11:05:56,715:INFO:Creating metrics dataframe
2024-01-18 11:05:56,751:INFO:Initializing create_model()
2024-01-18 11:05:56,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:05:56,752:INFO:Checking exceptions
2024-01-18 11:05:56,754:INFO:Importing libraries
2024-01-18 11:05:56,754:INFO:Copying training dataset
2024-01-18 11:05:56,761:INFO:Defining folds
2024-01-18 11:05:56,761:INFO:Declaring metric variables
2024-01-18 11:05:56,762:INFO:Importing untrained model
2024-01-18 11:05:56,762:INFO:Declaring custom model
2024-01-18 11:05:56,763:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 11:05:56,763:INFO:Cross validation set to False
2024-01-18 11:05:56,764:INFO:Fitting Model
2024-01-18 11:05:57,667:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 11:05:57,667:INFO:create_model() successfully completed......................................
2024-01-18 11:05:57,860:INFO:_master_model_container: 16
2024-01-18 11:05:57,860:INFO:_display_container: 2
2024-01-18 11:05:57,863:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 11:05:57,863:INFO:compare_models() successfully completed......................................
2024-01-18 11:06:43,564:INFO:Initializing finalize_model()
2024-01-18 11:06:43,564:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-18 11:06:43,565:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 11:06:43,571:INFO:Initializing create_model()
2024-01-18 11:06:43,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:06:43,571:INFO:Checking exceptions
2024-01-18 11:06:43,574:INFO:Importing libraries
2024-01-18 11:06:43,574:INFO:Copying training dataset
2024-01-18 11:06:43,575:INFO:Defining folds
2024-01-18 11:06:43,575:INFO:Declaring metric variables
2024-01-18 11:06:43,575:INFO:Importing untrained model
2024-01-18 11:06:43,575:INFO:Declaring custom model
2024-01-18 11:06:43,576:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 11:06:43,578:INFO:Cross validation set to False
2024-01-18 11:06:43,578:INFO:Fitting Model
2024-01-18 11:06:44,969:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CryoSleep', 'Age', 'VIP',
                                             'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck',
                                             'HomePlanet_Earth',
                                             'HomePlanet_Europa',
                                             'HomePlanet_Mars',
                                             'Destination_55 Cancri e',
                                             'Destination_PSO J318.5-22',
                                             'Destination_TRAPPIST-1e'],
                                    transformer=SimpleImputer(ad...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=2956, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-01-18 11:06:44,969:INFO:create_model() successfully completed......................................
2024-01-18 11:06:45,085:INFO:_master_model_container: 16
2024-01-18 11:06:45,085:INFO:_display_container: 2
2024-01-18 11:06:45,093:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CryoSleep', 'Age', 'VIP',
                                             'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck',
                                             'HomePlanet_Earth',
                                             'HomePlanet_Europa',
                                             'HomePlanet_Mars',
                                             'Destination_55 Cancri e',
                                             'Destination_PSO J318.5-22',
                                             'Destination_TRAPPIST-1e'],
                                    transformer=SimpleImputer(ad...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=2956, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-01-18 11:06:45,093:INFO:finalize_model() successfully completed......................................
2024-01-18 11:06:52,904:INFO:Initializing evaluate_model()
2024-01-18 11:06:52,905:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-18 11:06:53,253:INFO:Initializing plot_model()
2024-01-18 11:06:53,253:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 11:06:53,253:INFO:Checking exceptions
2024-01-18 11:06:53,301:INFO:Preloading libraries
2024-01-18 11:06:53,379:INFO:Copying training dataset
2024-01-18 11:06:53,379:INFO:Plot type: pipeline
2024-01-18 11:06:55,134:INFO:Visual Rendered Successfully
2024-01-18 11:06:55,270:INFO:plot_model() successfully completed......................................
2024-01-18 11:07:01,125:INFO:Initializing predict_model()
2024-01-18 11:07:01,126:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C73EAB7F60>)
2024-01-18 11:07:01,126:INFO:Checking exceptions
2024-01-18 11:07:01,126:INFO:Preloading libraries
2024-01-18 11:07:32,641:INFO:Initializing predict_model()
2024-01-18 11:07:32,641:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C72D390750>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2956, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C73EAB7740>)
2024-01-18 11:07:32,642:INFO:Checking exceptions
2024-01-18 11:07:32,642:INFO:Preloading libraries
2024-01-18 11:07:32,644:INFO:Set up data.
2024-01-18 11:07:32,650:INFO:Set up index.
2024-01-18 11:26:07,234:INFO:PyCaret ClassificationExperiment
2024-01-18 11:26:07,234:INFO:Logging name: clf-default-name
2024-01-18 11:26:07,234:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:26:07,234:INFO:version 3.2.0
2024-01-18 11:26:07,234:INFO:Initializing setup()
2024-01-18 11:26:07,234:INFO:self.USI: a661
2024-01-18 11:26:07,234:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:26:07,234:INFO:Checking environment
2024-01-18 11:26:07,234:INFO:python_version: 3.11.5
2024-01-18 11:26:07,234:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:26:07,234:INFO:machine: AMD64
2024-01-18 11:26:07,234:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:26:07,234:INFO:Memory: svmem(total=8361132032, available=1785450496, percent=78.6, used=6575681536, free=1785450496)
2024-01-18 11:26:07,234:INFO:Physical Core: 2
2024-01-18 11:26:07,234:INFO:Logical Core: 4
2024-01-18 11:26:07,234:INFO:Checking libraries
2024-01-18 11:26:07,234:INFO:System:
2024-01-18 11:26:07,234:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:26:07,234:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:26:07,234:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:26:07,234:INFO:PyCaret required dependencies:
2024-01-18 11:26:07,234:INFO:                 pip: 23.2.1
2024-01-18 11:26:07,234:INFO:          setuptools: 68.0.0
2024-01-18 11:26:07,234:INFO:             pycaret: 3.2.0
2024-01-18 11:26:07,234:INFO:             IPython: 8.15.0
2024-01-18 11:26:07,234:INFO:          ipywidgets: 8.0.4
2024-01-18 11:26:07,234:INFO:                tqdm: 4.65.0
2024-01-18 11:26:07,234:INFO:               numpy: 1.24.3
2024-01-18 11:26:07,234:INFO:              pandas: 1.5.3
2024-01-18 11:26:07,234:INFO:              jinja2: 3.1.2
2024-01-18 11:26:07,234:INFO:               scipy: 1.10.1
2024-01-18 11:26:07,234:INFO:              joblib: 1.2.0
2024-01-18 11:26:07,234:INFO:             sklearn: 1.2.2
2024-01-18 11:26:07,234:INFO:                pyod: 1.1.2
2024-01-18 11:26:07,234:INFO:            imblearn: 0.10.1
2024-01-18 11:26:07,234:INFO:   category_encoders: 2.6.3
2024-01-18 11:26:07,234:INFO:            lightgbm: 4.2.0
2024-01-18 11:26:07,234:INFO:               numba: 0.57.1
2024-01-18 11:26:07,234:INFO:            requests: 2.31.0
2024-01-18 11:26:07,234:INFO:          matplotlib: 3.6.0
2024-01-18 11:26:07,234:INFO:          scikitplot: 0.3.7
2024-01-18 11:26:07,234:INFO:         yellowbrick: 1.5
2024-01-18 11:26:07,234:INFO:              plotly: 5.9.0
2024-01-18 11:26:07,234:INFO:    plotly-resampler: Not installed
2024-01-18 11:26:07,234:INFO:             kaleido: 0.2.1
2024-01-18 11:26:07,234:INFO:           schemdraw: 0.15
2024-01-18 11:26:07,234:INFO:         statsmodels: 0.14.0
2024-01-18 11:26:07,234:INFO:              sktime: 0.21.1
2024-01-18 11:26:07,234:INFO:               tbats: 1.1.3
2024-01-18 11:26:07,234:INFO:            pmdarima: 2.0.4
2024-01-18 11:26:07,234:INFO:              psutil: 5.9.0
2024-01-18 11:26:07,234:INFO:          markupsafe: 2.1.1
2024-01-18 11:26:07,234:INFO:             pickle5: Not installed
2024-01-18 11:26:07,234:INFO:         cloudpickle: 2.2.1
2024-01-18 11:26:07,234:INFO:         deprecation: 2.1.0
2024-01-18 11:26:07,234:INFO:              xxhash: 2.0.2
2024-01-18 11:26:07,234:INFO:           wurlitzer: Not installed
2024-01-18 11:26:07,234:INFO:PyCaret optional dependencies:
2024-01-18 11:26:07,234:INFO:                shap: Not installed
2024-01-18 11:26:07,234:INFO:           interpret: Not installed
2024-01-18 11:26:07,234:INFO:                umap: Not installed
2024-01-18 11:26:07,234:INFO:     ydata_profiling: Not installed
2024-01-18 11:26:07,234:INFO:  explainerdashboard: Not installed
2024-01-18 11:26:07,234:INFO:             autoviz: Not installed
2024-01-18 11:26:07,234:INFO:           fairlearn: Not installed
2024-01-18 11:26:07,234:INFO:          deepchecks: Not installed
2024-01-18 11:26:07,234:INFO:             xgboost: 2.0.3
2024-01-18 11:26:07,234:INFO:            catboost: 1.2.2
2024-01-18 11:26:07,234:INFO:              kmodes: Not installed
2024-01-18 11:26:07,234:INFO:             mlxtend: Not installed
2024-01-18 11:26:07,234:INFO:       statsforecast: Not installed
2024-01-18 11:26:07,234:INFO:        tune_sklearn: Not installed
2024-01-18 11:26:07,234:INFO:                 ray: Not installed
2024-01-18 11:26:07,234:INFO:            hyperopt: Not installed
2024-01-18 11:26:07,234:INFO:              optuna: 3.5.0
2024-01-18 11:26:07,234:INFO:               skopt: Not installed
2024-01-18 11:26:07,234:INFO:              mlflow: Not installed
2024-01-18 11:26:07,234:INFO:              gradio: Not installed
2024-01-18 11:26:07,234:INFO:             fastapi: Not installed
2024-01-18 11:26:07,234:INFO:             uvicorn: Not installed
2024-01-18 11:26:07,234:INFO:              m2cgen: Not installed
2024-01-18 11:26:07,234:INFO:           evidently: Not installed
2024-01-18 11:26:07,234:INFO:               fugue: Not installed
2024-01-18 11:26:07,234:INFO:           streamlit: Not installed
2024-01-18 11:26:07,234:INFO:             prophet: Not installed
2024-01-18 11:26:07,234:INFO:None
2024-01-18 11:26:07,234:INFO:Set up data.
2024-01-18 11:26:07,250:INFO:Set up folding strategy.
2024-01-18 11:26:07,265:INFO:Set up train/test split.
2024-01-18 11:26:07,265:INFO:Set up index.
2024-01-18 11:26:07,265:INFO:Assigning column types.
2024-01-18 11:32:59,185:INFO:PyCaret ClassificationExperiment
2024-01-18 11:32:59,185:INFO:Logging name: clf-default-name
2024-01-18 11:32:59,185:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:32:59,185:INFO:version 3.2.0
2024-01-18 11:32:59,185:INFO:Initializing setup()
2024-01-18 11:32:59,185:INFO:self.USI: 0d34
2024-01-18 11:32:59,185:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:32:59,185:INFO:Checking environment
2024-01-18 11:32:59,185:INFO:python_version: 3.11.5
2024-01-18 11:32:59,185:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:32:59,185:INFO:machine: AMD64
2024-01-18 11:32:59,185:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:32:59,185:INFO:Memory: svmem(total=8361132032, available=1947672576, percent=76.7, used=6413459456, free=1947672576)
2024-01-18 11:32:59,185:INFO:Physical Core: 2
2024-01-18 11:32:59,185:INFO:Logical Core: 4
2024-01-18 11:32:59,185:INFO:Checking libraries
2024-01-18 11:32:59,185:INFO:System:
2024-01-18 11:32:59,185:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:32:59,185:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:32:59,185:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:32:59,185:INFO:PyCaret required dependencies:
2024-01-18 11:32:59,185:INFO:                 pip: 23.2.1
2024-01-18 11:32:59,185:INFO:          setuptools: 68.0.0
2024-01-18 11:32:59,185:INFO:             pycaret: 3.2.0
2024-01-18 11:32:59,185:INFO:             IPython: 8.15.0
2024-01-18 11:32:59,185:INFO:          ipywidgets: 8.0.4
2024-01-18 11:32:59,185:INFO:                tqdm: 4.65.0
2024-01-18 11:32:59,185:INFO:               numpy: 1.24.3
2024-01-18 11:32:59,185:INFO:              pandas: 1.5.3
2024-01-18 11:32:59,185:INFO:              jinja2: 3.1.2
2024-01-18 11:32:59,185:INFO:               scipy: 1.10.1
2024-01-18 11:32:59,185:INFO:              joblib: 1.2.0
2024-01-18 11:32:59,185:INFO:             sklearn: 1.2.2
2024-01-18 11:32:59,185:INFO:                pyod: 1.1.2
2024-01-18 11:32:59,185:INFO:            imblearn: 0.10.1
2024-01-18 11:32:59,185:INFO:   category_encoders: 2.6.3
2024-01-18 11:32:59,185:INFO:            lightgbm: 4.2.0
2024-01-18 11:32:59,185:INFO:               numba: 0.57.1
2024-01-18 11:32:59,185:INFO:            requests: 2.31.0
2024-01-18 11:32:59,185:INFO:          matplotlib: 3.6.0
2024-01-18 11:32:59,185:INFO:          scikitplot: 0.3.7
2024-01-18 11:32:59,185:INFO:         yellowbrick: 1.5
2024-01-18 11:32:59,185:INFO:              plotly: 5.9.0
2024-01-18 11:32:59,185:INFO:    plotly-resampler: Not installed
2024-01-18 11:32:59,185:INFO:             kaleido: 0.2.1
2024-01-18 11:32:59,185:INFO:           schemdraw: 0.15
2024-01-18 11:32:59,185:INFO:         statsmodels: 0.14.0
2024-01-18 11:32:59,185:INFO:              sktime: 0.21.1
2024-01-18 11:32:59,185:INFO:               tbats: 1.1.3
2024-01-18 11:32:59,185:INFO:            pmdarima: 2.0.4
2024-01-18 11:32:59,185:INFO:              psutil: 5.9.0
2024-01-18 11:32:59,185:INFO:          markupsafe: 2.1.1
2024-01-18 11:32:59,185:INFO:             pickle5: Not installed
2024-01-18 11:32:59,185:INFO:         cloudpickle: 2.2.1
2024-01-18 11:32:59,185:INFO:         deprecation: 2.1.0
2024-01-18 11:32:59,185:INFO:              xxhash: 2.0.2
2024-01-18 11:32:59,185:INFO:           wurlitzer: Not installed
2024-01-18 11:32:59,185:INFO:PyCaret optional dependencies:
2024-01-18 11:32:59,185:INFO:                shap: Not installed
2024-01-18 11:32:59,185:INFO:           interpret: Not installed
2024-01-18 11:32:59,185:INFO:                umap: Not installed
2024-01-18 11:32:59,185:INFO:     ydata_profiling: Not installed
2024-01-18 11:32:59,185:INFO:  explainerdashboard: Not installed
2024-01-18 11:32:59,185:INFO:             autoviz: Not installed
2024-01-18 11:32:59,185:INFO:           fairlearn: Not installed
2024-01-18 11:32:59,185:INFO:          deepchecks: Not installed
2024-01-18 11:32:59,185:INFO:             xgboost: 2.0.3
2024-01-18 11:32:59,185:INFO:            catboost: 1.2.2
2024-01-18 11:32:59,185:INFO:              kmodes: Not installed
2024-01-18 11:32:59,185:INFO:             mlxtend: Not installed
2024-01-18 11:32:59,185:INFO:       statsforecast: Not installed
2024-01-18 11:32:59,185:INFO:        tune_sklearn: Not installed
2024-01-18 11:32:59,185:INFO:                 ray: Not installed
2024-01-18 11:32:59,185:INFO:            hyperopt: Not installed
2024-01-18 11:32:59,185:INFO:              optuna: 3.5.0
2024-01-18 11:32:59,185:INFO:               skopt: Not installed
2024-01-18 11:32:59,185:INFO:              mlflow: Not installed
2024-01-18 11:32:59,185:INFO:              gradio: Not installed
2024-01-18 11:32:59,185:INFO:             fastapi: Not installed
2024-01-18 11:32:59,185:INFO:             uvicorn: Not installed
2024-01-18 11:32:59,185:INFO:              m2cgen: Not installed
2024-01-18 11:32:59,185:INFO:           evidently: Not installed
2024-01-18 11:32:59,185:INFO:               fugue: Not installed
2024-01-18 11:32:59,185:INFO:           streamlit: Not installed
2024-01-18 11:32:59,185:INFO:             prophet: Not installed
2024-01-18 11:32:59,185:INFO:None
2024-01-18 11:32:59,185:INFO:Set up data.
2024-01-18 11:32:59,201:INFO:Set up folding strategy.
2024-01-18 11:32:59,201:INFO:Set up train/test split.
2024-01-18 11:32:59,216:INFO:Set up index.
2024-01-18 11:32:59,216:INFO:Assigning column types.
2024-01-18 11:34:44,578:INFO:PyCaret ClassificationExperiment
2024-01-18 11:34:44,578:INFO:Logging name: clf-default-name
2024-01-18 11:34:44,578:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:34:44,578:INFO:version 3.2.0
2024-01-18 11:34:44,578:INFO:Initializing setup()
2024-01-18 11:34:44,578:INFO:self.USI: e7f4
2024-01-18 11:34:44,578:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:34:44,578:INFO:Checking environment
2024-01-18 11:34:44,578:INFO:python_version: 3.11.5
2024-01-18 11:34:44,578:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:34:44,578:INFO:machine: AMD64
2024-01-18 11:34:44,578:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:34:44,578:INFO:Memory: svmem(total=8361132032, available=1900417024, percent=77.3, used=6460715008, free=1900417024)
2024-01-18 11:34:44,578:INFO:Physical Core: 2
2024-01-18 11:34:44,578:INFO:Logical Core: 4
2024-01-18 11:34:44,578:INFO:Checking libraries
2024-01-18 11:34:44,578:INFO:System:
2024-01-18 11:34:44,578:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:34:44,578:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:34:44,578:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:34:44,578:INFO:PyCaret required dependencies:
2024-01-18 11:34:44,578:INFO:                 pip: 23.2.1
2024-01-18 11:34:44,578:INFO:          setuptools: 68.0.0
2024-01-18 11:34:44,578:INFO:             pycaret: 3.2.0
2024-01-18 11:34:44,578:INFO:             IPython: 8.15.0
2024-01-18 11:34:44,578:INFO:          ipywidgets: 8.0.4
2024-01-18 11:34:44,578:INFO:                tqdm: 4.65.0
2024-01-18 11:34:44,578:INFO:               numpy: 1.24.3
2024-01-18 11:34:44,578:INFO:              pandas: 1.5.3
2024-01-18 11:34:44,578:INFO:              jinja2: 3.1.2
2024-01-18 11:34:44,578:INFO:               scipy: 1.10.1
2024-01-18 11:34:44,578:INFO:              joblib: 1.2.0
2024-01-18 11:34:44,578:INFO:             sklearn: 1.2.2
2024-01-18 11:34:44,578:INFO:                pyod: 1.1.2
2024-01-18 11:34:44,578:INFO:            imblearn: 0.10.1
2024-01-18 11:34:44,578:INFO:   category_encoders: 2.6.3
2024-01-18 11:34:44,578:INFO:            lightgbm: 4.2.0
2024-01-18 11:34:44,578:INFO:               numba: 0.57.1
2024-01-18 11:34:44,578:INFO:            requests: 2.31.0
2024-01-18 11:34:44,578:INFO:          matplotlib: 3.6.0
2024-01-18 11:34:44,578:INFO:          scikitplot: 0.3.7
2024-01-18 11:34:44,578:INFO:         yellowbrick: 1.5
2024-01-18 11:34:44,578:INFO:              plotly: 5.9.0
2024-01-18 11:34:44,578:INFO:    plotly-resampler: Not installed
2024-01-18 11:34:44,578:INFO:             kaleido: 0.2.1
2024-01-18 11:34:44,578:INFO:           schemdraw: 0.15
2024-01-18 11:34:44,578:INFO:         statsmodels: 0.14.0
2024-01-18 11:34:44,578:INFO:              sktime: 0.21.1
2024-01-18 11:34:44,578:INFO:               tbats: 1.1.3
2024-01-18 11:34:44,578:INFO:            pmdarima: 2.0.4
2024-01-18 11:34:44,578:INFO:              psutil: 5.9.0
2024-01-18 11:34:44,578:INFO:          markupsafe: 2.1.1
2024-01-18 11:34:44,578:INFO:             pickle5: Not installed
2024-01-18 11:34:44,578:INFO:         cloudpickle: 2.2.1
2024-01-18 11:34:44,578:INFO:         deprecation: 2.1.0
2024-01-18 11:34:44,578:INFO:              xxhash: 2.0.2
2024-01-18 11:34:44,578:INFO:           wurlitzer: Not installed
2024-01-18 11:34:44,578:INFO:PyCaret optional dependencies:
2024-01-18 11:34:44,593:INFO:                shap: Not installed
2024-01-18 11:34:44,593:INFO:           interpret: Not installed
2024-01-18 11:34:44,593:INFO:                umap: Not installed
2024-01-18 11:34:44,593:INFO:     ydata_profiling: Not installed
2024-01-18 11:34:44,593:INFO:  explainerdashboard: Not installed
2024-01-18 11:34:44,593:INFO:             autoviz: Not installed
2024-01-18 11:34:44,593:INFO:           fairlearn: Not installed
2024-01-18 11:34:44,593:INFO:          deepchecks: Not installed
2024-01-18 11:34:44,593:INFO:             xgboost: 2.0.3
2024-01-18 11:34:44,593:INFO:            catboost: 1.2.2
2024-01-18 11:34:44,593:INFO:              kmodes: Not installed
2024-01-18 11:34:44,593:INFO:             mlxtend: Not installed
2024-01-18 11:34:44,593:INFO:       statsforecast: Not installed
2024-01-18 11:34:44,593:INFO:        tune_sklearn: Not installed
2024-01-18 11:34:44,593:INFO:                 ray: Not installed
2024-01-18 11:34:44,593:INFO:            hyperopt: Not installed
2024-01-18 11:34:44,593:INFO:              optuna: 3.5.0
2024-01-18 11:34:44,593:INFO:               skopt: Not installed
2024-01-18 11:34:44,593:INFO:              mlflow: Not installed
2024-01-18 11:34:44,593:INFO:              gradio: Not installed
2024-01-18 11:34:44,593:INFO:             fastapi: Not installed
2024-01-18 11:34:44,593:INFO:             uvicorn: Not installed
2024-01-18 11:34:44,593:INFO:              m2cgen: Not installed
2024-01-18 11:34:44,593:INFO:           evidently: Not installed
2024-01-18 11:34:44,593:INFO:               fugue: Not installed
2024-01-18 11:34:44,593:INFO:           streamlit: Not installed
2024-01-18 11:34:44,593:INFO:             prophet: Not installed
2024-01-18 11:34:44,593:INFO:None
2024-01-18 11:34:44,593:INFO:Set up data.
2024-01-18 11:34:45,423:INFO:PyCaret ClassificationExperiment
2024-01-18 11:34:45,423:INFO:Logging name: clf-default-name
2024-01-18 11:34:45,423:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:34:45,423:INFO:version 3.2.0
2024-01-18 11:34:45,423:INFO:Initializing setup()
2024-01-18 11:34:45,423:INFO:self.USI: 57d4
2024-01-18 11:34:45,423:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:34:45,423:INFO:Checking environment
2024-01-18 11:34:45,423:INFO:python_version: 3.11.5
2024-01-18 11:34:45,424:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:34:45,424:INFO:machine: AMD64
2024-01-18 11:34:45,424:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:34:45,424:INFO:Memory: svmem(total=8361132032, available=1859403776, percent=77.8, used=6501728256, free=1859403776)
2024-01-18 11:34:45,424:INFO:Physical Core: 2
2024-01-18 11:34:45,424:INFO:Logical Core: 4
2024-01-18 11:34:45,424:INFO:Checking libraries
2024-01-18 11:34:45,424:INFO:System:
2024-01-18 11:34:45,424:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:34:45,424:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:34:45,424:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:34:45,424:INFO:PyCaret required dependencies:
2024-01-18 11:34:45,424:INFO:                 pip: 23.2.1
2024-01-18 11:34:45,424:INFO:          setuptools: 68.0.0
2024-01-18 11:34:45,424:INFO:             pycaret: 3.2.0
2024-01-18 11:34:45,424:INFO:             IPython: 8.15.0
2024-01-18 11:34:45,424:INFO:          ipywidgets: 8.0.4
2024-01-18 11:34:45,424:INFO:                tqdm: 4.65.0
2024-01-18 11:34:45,425:INFO:               numpy: 1.24.3
2024-01-18 11:34:45,425:INFO:              pandas: 1.5.3
2024-01-18 11:34:45,425:INFO:              jinja2: 3.1.2
2024-01-18 11:34:45,425:INFO:               scipy: 1.10.1
2024-01-18 11:34:45,425:INFO:              joblib: 1.2.0
2024-01-18 11:34:45,425:INFO:             sklearn: 1.2.2
2024-01-18 11:34:45,425:INFO:                pyod: 1.1.2
2024-01-18 11:34:45,425:INFO:            imblearn: 0.10.1
2024-01-18 11:34:45,425:INFO:   category_encoders: 2.6.3
2024-01-18 11:34:45,425:INFO:            lightgbm: 4.2.0
2024-01-18 11:34:45,425:INFO:               numba: 0.57.1
2024-01-18 11:34:45,425:INFO:            requests: 2.31.0
2024-01-18 11:34:45,425:INFO:          matplotlib: 3.6.0
2024-01-18 11:34:45,425:INFO:          scikitplot: 0.3.7
2024-01-18 11:34:45,425:INFO:         yellowbrick: 1.5
2024-01-18 11:34:45,425:INFO:              plotly: 5.9.0
2024-01-18 11:34:45,425:INFO:    plotly-resampler: Not installed
2024-01-18 11:34:45,425:INFO:             kaleido: 0.2.1
2024-01-18 11:34:45,425:INFO:           schemdraw: 0.15
2024-01-18 11:34:45,425:INFO:         statsmodels: 0.14.0
2024-01-18 11:34:45,425:INFO:              sktime: 0.21.1
2024-01-18 11:34:45,426:INFO:               tbats: 1.1.3
2024-01-18 11:34:45,426:INFO:            pmdarima: 2.0.4
2024-01-18 11:34:45,426:INFO:              psutil: 5.9.0
2024-01-18 11:34:45,426:INFO:          markupsafe: 2.1.1
2024-01-18 11:34:45,426:INFO:             pickle5: Not installed
2024-01-18 11:34:45,426:INFO:         cloudpickle: 2.2.1
2024-01-18 11:34:45,426:INFO:         deprecation: 2.1.0
2024-01-18 11:34:45,426:INFO:              xxhash: 2.0.2
2024-01-18 11:34:45,426:INFO:           wurlitzer: Not installed
2024-01-18 11:34:45,426:INFO:PyCaret optional dependencies:
2024-01-18 11:34:45,426:INFO:                shap: Not installed
2024-01-18 11:34:45,426:INFO:           interpret: Not installed
2024-01-18 11:34:45,426:INFO:                umap: Not installed
2024-01-18 11:34:45,426:INFO:     ydata_profiling: Not installed
2024-01-18 11:34:45,426:INFO:  explainerdashboard: Not installed
2024-01-18 11:34:45,426:INFO:             autoviz: Not installed
2024-01-18 11:34:45,426:INFO:           fairlearn: Not installed
2024-01-18 11:34:45,426:INFO:          deepchecks: Not installed
2024-01-18 11:34:45,426:INFO:             xgboost: 2.0.3
2024-01-18 11:34:45,426:INFO:            catboost: 1.2.2
2024-01-18 11:34:45,427:INFO:              kmodes: Not installed
2024-01-18 11:34:45,427:INFO:             mlxtend: Not installed
2024-01-18 11:34:45,427:INFO:       statsforecast: Not installed
2024-01-18 11:34:45,427:INFO:        tune_sklearn: Not installed
2024-01-18 11:34:45,427:INFO:                 ray: Not installed
2024-01-18 11:34:45,427:INFO:            hyperopt: Not installed
2024-01-18 11:34:45,427:INFO:              optuna: 3.5.0
2024-01-18 11:34:45,427:INFO:               skopt: Not installed
2024-01-18 11:34:45,427:INFO:              mlflow: Not installed
2024-01-18 11:34:45,427:INFO:              gradio: Not installed
2024-01-18 11:34:45,427:INFO:             fastapi: Not installed
2024-01-18 11:34:45,427:INFO:             uvicorn: Not installed
2024-01-18 11:34:45,427:INFO:              m2cgen: Not installed
2024-01-18 11:34:45,427:INFO:           evidently: Not installed
2024-01-18 11:34:45,427:INFO:               fugue: Not installed
2024-01-18 11:34:45,427:INFO:           streamlit: Not installed
2024-01-18 11:34:45,427:INFO:             prophet: Not installed
2024-01-18 11:34:45,428:INFO:None
2024-01-18 11:34:45,428:INFO:Set up data.
2024-01-18 11:38:09,965:INFO:PyCaret ClassificationExperiment
2024-01-18 11:38:09,965:INFO:Logging name: clf-default-name
2024-01-18 11:38:09,966:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:38:09,966:INFO:version 3.2.0
2024-01-18 11:38:09,966:INFO:Initializing setup()
2024-01-18 11:38:09,966:INFO:self.USI: 784d
2024-01-18 11:38:09,966:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:38:09,966:INFO:Checking environment
2024-01-18 11:38:09,966:INFO:python_version: 3.11.5
2024-01-18 11:38:09,966:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:38:09,966:INFO:machine: AMD64
2024-01-18 11:38:09,966:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:38:09,966:INFO:Memory: svmem(total=8361132032, available=1934151680, percent=76.9, used=6426980352, free=1934151680)
2024-01-18 11:38:09,966:INFO:Physical Core: 2
2024-01-18 11:38:09,966:INFO:Logical Core: 4
2024-01-18 11:38:09,966:INFO:Checking libraries
2024-01-18 11:38:09,966:INFO:System:
2024-01-18 11:38:09,966:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:38:09,967:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:38:09,967:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:38:09,967:INFO:PyCaret required dependencies:
2024-01-18 11:38:09,967:INFO:                 pip: 23.2.1
2024-01-18 11:38:09,967:INFO:          setuptools: 68.0.0
2024-01-18 11:38:09,967:INFO:             pycaret: 3.2.0
2024-01-18 11:38:09,967:INFO:             IPython: 8.15.0
2024-01-18 11:38:09,967:INFO:          ipywidgets: 8.0.4
2024-01-18 11:38:09,967:INFO:                tqdm: 4.65.0
2024-01-18 11:38:09,967:INFO:               numpy: 1.24.3
2024-01-18 11:38:09,967:INFO:              pandas: 1.5.3
2024-01-18 11:38:09,967:INFO:              jinja2: 3.1.2
2024-01-18 11:38:09,967:INFO:               scipy: 1.10.1
2024-01-18 11:38:09,967:INFO:              joblib: 1.2.0
2024-01-18 11:38:09,967:INFO:             sklearn: 1.2.2
2024-01-18 11:38:09,967:INFO:                pyod: 1.1.2
2024-01-18 11:38:09,967:INFO:            imblearn: 0.10.1
2024-01-18 11:38:09,967:INFO:   category_encoders: 2.6.3
2024-01-18 11:38:09,967:INFO:            lightgbm: 4.2.0
2024-01-18 11:38:09,967:INFO:               numba: 0.57.1
2024-01-18 11:38:09,968:INFO:            requests: 2.31.0
2024-01-18 11:38:09,968:INFO:          matplotlib: 3.6.0
2024-01-18 11:38:09,968:INFO:          scikitplot: 0.3.7
2024-01-18 11:38:09,968:INFO:         yellowbrick: 1.5
2024-01-18 11:38:09,968:INFO:              plotly: 5.9.0
2024-01-18 11:38:09,968:INFO:    plotly-resampler: Not installed
2024-01-18 11:38:09,968:INFO:             kaleido: 0.2.1
2024-01-18 11:38:09,968:INFO:           schemdraw: 0.15
2024-01-18 11:38:09,968:INFO:         statsmodels: 0.14.0
2024-01-18 11:38:09,968:INFO:              sktime: 0.21.1
2024-01-18 11:38:09,968:INFO:               tbats: 1.1.3
2024-01-18 11:38:09,968:INFO:            pmdarima: 2.0.4
2024-01-18 11:38:09,968:INFO:              psutil: 5.9.0
2024-01-18 11:38:09,968:INFO:          markupsafe: 2.1.1
2024-01-18 11:38:09,968:INFO:             pickle5: Not installed
2024-01-18 11:38:09,968:INFO:         cloudpickle: 2.2.1
2024-01-18 11:38:09,968:INFO:         deprecation: 2.1.0
2024-01-18 11:38:09,968:INFO:              xxhash: 2.0.2
2024-01-18 11:38:09,968:INFO:           wurlitzer: Not installed
2024-01-18 11:38:09,968:INFO:PyCaret optional dependencies:
2024-01-18 11:38:09,968:INFO:                shap: Not installed
2024-01-18 11:38:09,968:INFO:           interpret: Not installed
2024-01-18 11:38:09,968:INFO:                umap: Not installed
2024-01-18 11:38:09,969:INFO:     ydata_profiling: Not installed
2024-01-18 11:38:09,969:INFO:  explainerdashboard: Not installed
2024-01-18 11:38:09,969:INFO:             autoviz: Not installed
2024-01-18 11:38:09,969:INFO:           fairlearn: Not installed
2024-01-18 11:38:09,969:INFO:          deepchecks: Not installed
2024-01-18 11:38:09,969:INFO:             xgboost: 2.0.3
2024-01-18 11:38:09,970:INFO:            catboost: 1.2.2
2024-01-18 11:38:09,970:INFO:              kmodes: Not installed
2024-01-18 11:38:09,970:INFO:             mlxtend: Not installed
2024-01-18 11:38:09,970:INFO:       statsforecast: Not installed
2024-01-18 11:38:09,970:INFO:        tune_sklearn: Not installed
2024-01-18 11:38:09,970:INFO:                 ray: Not installed
2024-01-18 11:38:09,970:INFO:            hyperopt: Not installed
2024-01-18 11:38:09,970:INFO:              optuna: 3.5.0
2024-01-18 11:38:09,970:INFO:               skopt: Not installed
2024-01-18 11:38:09,970:INFO:              mlflow: Not installed
2024-01-18 11:38:09,970:INFO:              gradio: Not installed
2024-01-18 11:38:09,970:INFO:             fastapi: Not installed
2024-01-18 11:38:09,970:INFO:             uvicorn: Not installed
2024-01-18 11:38:09,970:INFO:              m2cgen: Not installed
2024-01-18 11:38:09,970:INFO:           evidently: Not installed
2024-01-18 11:38:09,970:INFO:               fugue: Not installed
2024-01-18 11:38:09,970:INFO:           streamlit: Not installed
2024-01-18 11:38:09,970:INFO:             prophet: Not installed
2024-01-18 11:38:09,970:INFO:None
2024-01-18 11:38:09,970:INFO:Set up data.
2024-01-18 11:39:34,070:INFO:PyCaret ClassificationExperiment
2024-01-18 11:39:34,070:INFO:Logging name: clf-default-name
2024-01-18 11:39:34,070:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:39:34,070:INFO:version 3.2.0
2024-01-18 11:39:34,070:INFO:Initializing setup()
2024-01-18 11:39:34,070:INFO:self.USI: 718e
2024-01-18 11:39:34,070:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:39:34,070:INFO:Checking environment
2024-01-18 11:39:34,070:INFO:python_version: 3.11.5
2024-01-18 11:39:34,070:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:39:34,070:INFO:machine: AMD64
2024-01-18 11:39:34,070:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:39:34,070:INFO:Memory: svmem(total=8361132032, available=1600651264, percent=80.9, used=6760480768, free=1600651264)
2024-01-18 11:39:34,070:INFO:Physical Core: 2
2024-01-18 11:39:34,070:INFO:Logical Core: 4
2024-01-18 11:39:34,070:INFO:Checking libraries
2024-01-18 11:39:34,070:INFO:System:
2024-01-18 11:39:34,070:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:39:34,070:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:39:34,070:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:39:34,070:INFO:PyCaret required dependencies:
2024-01-18 11:39:34,070:INFO:                 pip: 23.2.1
2024-01-18 11:39:34,070:INFO:          setuptools: 68.0.0
2024-01-18 11:39:34,070:INFO:             pycaret: 3.2.0
2024-01-18 11:39:34,070:INFO:             IPython: 8.15.0
2024-01-18 11:39:34,070:INFO:          ipywidgets: 8.0.4
2024-01-18 11:39:34,070:INFO:                tqdm: 4.65.0
2024-01-18 11:39:34,070:INFO:               numpy: 1.24.3
2024-01-18 11:39:34,070:INFO:              pandas: 1.5.3
2024-01-18 11:39:34,070:INFO:              jinja2: 3.1.2
2024-01-18 11:39:34,070:INFO:               scipy: 1.10.1
2024-01-18 11:39:34,070:INFO:              joblib: 1.2.0
2024-01-18 11:39:34,070:INFO:             sklearn: 1.2.2
2024-01-18 11:39:34,070:INFO:                pyod: 1.1.2
2024-01-18 11:39:34,070:INFO:            imblearn: 0.10.1
2024-01-18 11:39:34,070:INFO:   category_encoders: 2.6.3
2024-01-18 11:39:34,070:INFO:            lightgbm: 4.2.0
2024-01-18 11:39:34,070:INFO:               numba: 0.57.1
2024-01-18 11:39:34,070:INFO:            requests: 2.31.0
2024-01-18 11:39:34,070:INFO:          matplotlib: 3.6.0
2024-01-18 11:39:34,070:INFO:          scikitplot: 0.3.7
2024-01-18 11:39:34,070:INFO:         yellowbrick: 1.5
2024-01-18 11:39:34,070:INFO:              plotly: 5.9.0
2024-01-18 11:39:34,070:INFO:    plotly-resampler: Not installed
2024-01-18 11:39:34,070:INFO:             kaleido: 0.2.1
2024-01-18 11:39:34,070:INFO:           schemdraw: 0.15
2024-01-18 11:39:34,070:INFO:         statsmodels: 0.14.0
2024-01-18 11:39:34,070:INFO:              sktime: 0.21.1
2024-01-18 11:39:34,070:INFO:               tbats: 1.1.3
2024-01-18 11:39:34,070:INFO:            pmdarima: 2.0.4
2024-01-18 11:39:34,070:INFO:              psutil: 5.9.0
2024-01-18 11:39:34,070:INFO:          markupsafe: 2.1.1
2024-01-18 11:39:34,070:INFO:             pickle5: Not installed
2024-01-18 11:39:34,070:INFO:         cloudpickle: 2.2.1
2024-01-18 11:39:34,070:INFO:         deprecation: 2.1.0
2024-01-18 11:39:34,070:INFO:              xxhash: 2.0.2
2024-01-18 11:39:34,070:INFO:           wurlitzer: Not installed
2024-01-18 11:39:34,070:INFO:PyCaret optional dependencies:
2024-01-18 11:39:34,070:INFO:                shap: Not installed
2024-01-18 11:39:34,070:INFO:           interpret: Not installed
2024-01-18 11:39:34,070:INFO:                umap: Not installed
2024-01-18 11:39:34,070:INFO:     ydata_profiling: Not installed
2024-01-18 11:39:34,070:INFO:  explainerdashboard: Not installed
2024-01-18 11:39:34,070:INFO:             autoviz: Not installed
2024-01-18 11:39:34,070:INFO:           fairlearn: Not installed
2024-01-18 11:39:34,070:INFO:          deepchecks: Not installed
2024-01-18 11:39:34,070:INFO:             xgboost: 2.0.3
2024-01-18 11:39:34,070:INFO:            catboost: 1.2.2
2024-01-18 11:39:34,070:INFO:              kmodes: Not installed
2024-01-18 11:39:34,070:INFO:             mlxtend: Not installed
2024-01-18 11:39:34,070:INFO:       statsforecast: Not installed
2024-01-18 11:39:34,070:INFO:        tune_sklearn: Not installed
2024-01-18 11:39:34,070:INFO:                 ray: Not installed
2024-01-18 11:39:34,070:INFO:            hyperopt: Not installed
2024-01-18 11:39:34,070:INFO:              optuna: 3.5.0
2024-01-18 11:39:34,070:INFO:               skopt: Not installed
2024-01-18 11:39:34,070:INFO:              mlflow: Not installed
2024-01-18 11:39:34,070:INFO:              gradio: Not installed
2024-01-18 11:39:34,070:INFO:             fastapi: Not installed
2024-01-18 11:39:34,070:INFO:             uvicorn: Not installed
2024-01-18 11:39:34,070:INFO:              m2cgen: Not installed
2024-01-18 11:39:34,070:INFO:           evidently: Not installed
2024-01-18 11:39:34,070:INFO:               fugue: Not installed
2024-01-18 11:39:34,070:INFO:           streamlit: Not installed
2024-01-18 11:39:34,070:INFO:             prophet: Not installed
2024-01-18 11:39:34,070:INFO:None
2024-01-18 11:39:34,070:INFO:Set up data.
2024-01-18 11:39:34,101:INFO:Set up folding strategy.
2024-01-18 11:39:34,101:INFO:Set up train/test split.
2024-01-18 11:39:34,117:INFO:Set up index.
2024-01-18 11:39:34,117:INFO:Assigning column types.
2024-01-18 11:39:52,447:INFO:PyCaret ClassificationExperiment
2024-01-18 11:39:52,447:INFO:Logging name: clf-default-name
2024-01-18 11:39:52,447:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:39:52,447:INFO:version 3.2.0
2024-01-18 11:39:52,447:INFO:Initializing setup()
2024-01-18 11:39:52,447:INFO:self.USI: d2dd
2024-01-18 11:39:52,447:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:39:52,447:INFO:Checking environment
2024-01-18 11:39:52,447:INFO:python_version: 3.11.5
2024-01-18 11:39:52,447:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:39:52,448:INFO:machine: AMD64
2024-01-18 11:39:52,448:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:39:52,448:INFO:Memory: svmem(total=8361132032, available=1780293632, percent=78.7, used=6580838400, free=1780293632)
2024-01-18 11:39:52,448:INFO:Physical Core: 2
2024-01-18 11:39:52,448:INFO:Logical Core: 4
2024-01-18 11:39:52,448:INFO:Checking libraries
2024-01-18 11:39:52,448:INFO:System:
2024-01-18 11:39:52,448:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:39:52,448:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:39:52,449:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:39:52,449:INFO:PyCaret required dependencies:
2024-01-18 11:39:52,449:INFO:                 pip: 23.2.1
2024-01-18 11:39:52,449:INFO:          setuptools: 68.0.0
2024-01-18 11:39:52,449:INFO:             pycaret: 3.2.0
2024-01-18 11:39:52,449:INFO:             IPython: 8.15.0
2024-01-18 11:39:52,449:INFO:          ipywidgets: 8.0.4
2024-01-18 11:39:52,449:INFO:                tqdm: 4.65.0
2024-01-18 11:39:52,449:INFO:               numpy: 1.24.3
2024-01-18 11:39:52,449:INFO:              pandas: 1.5.3
2024-01-18 11:39:52,449:INFO:              jinja2: 3.1.2
2024-01-18 11:39:52,449:INFO:               scipy: 1.10.1
2024-01-18 11:39:52,449:INFO:              joblib: 1.2.0
2024-01-18 11:39:52,450:INFO:             sklearn: 1.2.2
2024-01-18 11:39:52,450:INFO:                pyod: 1.1.2
2024-01-18 11:39:52,450:INFO:            imblearn: 0.10.1
2024-01-18 11:39:52,450:INFO:   category_encoders: 2.6.3
2024-01-18 11:39:52,450:INFO:            lightgbm: 4.2.0
2024-01-18 11:39:52,450:INFO:               numba: 0.57.1
2024-01-18 11:39:52,450:INFO:            requests: 2.31.0
2024-01-18 11:39:52,450:INFO:          matplotlib: 3.6.0
2024-01-18 11:39:52,450:INFO:          scikitplot: 0.3.7
2024-01-18 11:39:52,450:INFO:         yellowbrick: 1.5
2024-01-18 11:39:52,450:INFO:              plotly: 5.9.0
2024-01-18 11:39:52,450:INFO:    plotly-resampler: Not installed
2024-01-18 11:39:52,450:INFO:             kaleido: 0.2.1
2024-01-18 11:39:52,450:INFO:           schemdraw: 0.15
2024-01-18 11:39:52,450:INFO:         statsmodels: 0.14.0
2024-01-18 11:39:52,450:INFO:              sktime: 0.21.1
2024-01-18 11:39:52,450:INFO:               tbats: 1.1.3
2024-01-18 11:39:52,452:INFO:            pmdarima: 2.0.4
2024-01-18 11:39:52,452:INFO:              psutil: 5.9.0
2024-01-18 11:39:52,452:INFO:          markupsafe: 2.1.1
2024-01-18 11:39:52,452:INFO:             pickle5: Not installed
2024-01-18 11:39:52,452:INFO:         cloudpickle: 2.2.1
2024-01-18 11:39:52,452:INFO:         deprecation: 2.1.0
2024-01-18 11:39:52,452:INFO:              xxhash: 2.0.2
2024-01-18 11:39:52,452:INFO:           wurlitzer: Not installed
2024-01-18 11:39:52,452:INFO:PyCaret optional dependencies:
2024-01-18 11:39:52,452:INFO:                shap: Not installed
2024-01-18 11:39:52,452:INFO:           interpret: Not installed
2024-01-18 11:39:52,452:INFO:                umap: Not installed
2024-01-18 11:39:52,452:INFO:     ydata_profiling: Not installed
2024-01-18 11:39:52,453:INFO:  explainerdashboard: Not installed
2024-01-18 11:39:52,453:INFO:             autoviz: Not installed
2024-01-18 11:39:52,453:INFO:           fairlearn: Not installed
2024-01-18 11:39:52,453:INFO:          deepchecks: Not installed
2024-01-18 11:39:52,453:INFO:             xgboost: 2.0.3
2024-01-18 11:39:52,453:INFO:            catboost: 1.2.2
2024-01-18 11:39:52,453:INFO:              kmodes: Not installed
2024-01-18 11:39:52,453:INFO:             mlxtend: Not installed
2024-01-18 11:39:52,453:INFO:       statsforecast: Not installed
2024-01-18 11:39:52,453:INFO:        tune_sklearn: Not installed
2024-01-18 11:39:52,453:INFO:                 ray: Not installed
2024-01-18 11:39:52,453:INFO:            hyperopt: Not installed
2024-01-18 11:39:52,453:INFO:              optuna: 3.5.0
2024-01-18 11:39:52,453:INFO:               skopt: Not installed
2024-01-18 11:39:52,453:INFO:              mlflow: Not installed
2024-01-18 11:39:52,454:INFO:              gradio: Not installed
2024-01-18 11:39:52,454:INFO:             fastapi: Not installed
2024-01-18 11:39:52,454:INFO:             uvicorn: Not installed
2024-01-18 11:39:52,454:INFO:              m2cgen: Not installed
2024-01-18 11:39:52,454:INFO:           evidently: Not installed
2024-01-18 11:39:52,454:INFO:               fugue: Not installed
2024-01-18 11:39:52,454:INFO:           streamlit: Not installed
2024-01-18 11:39:52,454:INFO:             prophet: Not installed
2024-01-18 11:39:52,454:INFO:None
2024-01-18 11:39:52,455:INFO:Set up data.
2024-01-18 11:39:52,466:INFO:Set up folding strategy.
2024-01-18 11:39:52,466:INFO:Set up train/test split.
2024-01-18 11:39:52,475:INFO:Set up index.
2024-01-18 11:39:52,475:INFO:Assigning column types.
2024-01-18 11:41:51,575:INFO:PyCaret ClassificationExperiment
2024-01-18 11:41:51,575:INFO:Logging name: clf-default-name
2024-01-18 11:41:51,575:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:41:51,575:INFO:version 3.2.0
2024-01-18 11:41:51,575:INFO:Initializing setup()
2024-01-18 11:41:51,575:INFO:self.USI: 444a
2024-01-18 11:41:51,575:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:41:51,575:INFO:Checking environment
2024-01-18 11:41:51,575:INFO:python_version: 3.11.5
2024-01-18 11:41:51,575:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:41:51,575:INFO:machine: AMD64
2024-01-18 11:41:51,575:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:41:51,575:INFO:Memory: svmem(total=8361132032, available=1915867136, percent=77.1, used=6445264896, free=1915867136)
2024-01-18 11:41:51,575:INFO:Physical Core: 2
2024-01-18 11:41:51,575:INFO:Logical Core: 4
2024-01-18 11:41:51,575:INFO:Checking libraries
2024-01-18 11:41:51,575:INFO:System:
2024-01-18 11:41:51,575:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:41:51,575:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:41:51,575:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:41:51,575:INFO:PyCaret required dependencies:
2024-01-18 11:41:51,575:INFO:                 pip: 23.2.1
2024-01-18 11:41:51,575:INFO:          setuptools: 68.0.0
2024-01-18 11:41:51,575:INFO:             pycaret: 3.2.0
2024-01-18 11:41:51,575:INFO:             IPython: 8.15.0
2024-01-18 11:41:51,575:INFO:          ipywidgets: 8.0.4
2024-01-18 11:41:51,575:INFO:                tqdm: 4.65.0
2024-01-18 11:41:51,575:INFO:               numpy: 1.24.3
2024-01-18 11:41:51,575:INFO:              pandas: 1.5.3
2024-01-18 11:41:51,575:INFO:              jinja2: 3.1.2
2024-01-18 11:41:51,575:INFO:               scipy: 1.10.1
2024-01-18 11:41:51,575:INFO:              joblib: 1.2.0
2024-01-18 11:41:51,575:INFO:             sklearn: 1.2.2
2024-01-18 11:41:51,575:INFO:                pyod: 1.1.2
2024-01-18 11:41:51,575:INFO:            imblearn: 0.10.1
2024-01-18 11:41:51,575:INFO:   category_encoders: 2.6.3
2024-01-18 11:41:51,575:INFO:            lightgbm: 4.2.0
2024-01-18 11:41:51,575:INFO:               numba: 0.57.1
2024-01-18 11:41:51,575:INFO:            requests: 2.31.0
2024-01-18 11:41:51,575:INFO:          matplotlib: 3.6.0
2024-01-18 11:41:51,575:INFO:          scikitplot: 0.3.7
2024-01-18 11:41:51,575:INFO:         yellowbrick: 1.5
2024-01-18 11:41:51,575:INFO:              plotly: 5.9.0
2024-01-18 11:41:51,575:INFO:    plotly-resampler: Not installed
2024-01-18 11:41:51,575:INFO:             kaleido: 0.2.1
2024-01-18 11:41:51,575:INFO:           schemdraw: 0.15
2024-01-18 11:41:51,575:INFO:         statsmodels: 0.14.0
2024-01-18 11:41:51,575:INFO:              sktime: 0.21.1
2024-01-18 11:41:51,575:INFO:               tbats: 1.1.3
2024-01-18 11:41:51,575:INFO:            pmdarima: 2.0.4
2024-01-18 11:41:51,575:INFO:              psutil: 5.9.0
2024-01-18 11:41:51,575:INFO:          markupsafe: 2.1.1
2024-01-18 11:41:51,575:INFO:             pickle5: Not installed
2024-01-18 11:41:51,575:INFO:         cloudpickle: 2.2.1
2024-01-18 11:41:51,575:INFO:         deprecation: 2.1.0
2024-01-18 11:41:51,575:INFO:              xxhash: 2.0.2
2024-01-18 11:41:51,575:INFO:           wurlitzer: Not installed
2024-01-18 11:41:51,575:INFO:PyCaret optional dependencies:
2024-01-18 11:41:51,575:INFO:                shap: Not installed
2024-01-18 11:41:51,575:INFO:           interpret: Not installed
2024-01-18 11:41:51,590:INFO:                umap: Not installed
2024-01-18 11:41:51,590:INFO:     ydata_profiling: Not installed
2024-01-18 11:41:51,590:INFO:  explainerdashboard: Not installed
2024-01-18 11:41:51,590:INFO:             autoviz: Not installed
2024-01-18 11:41:51,590:INFO:           fairlearn: Not installed
2024-01-18 11:41:51,590:INFO:          deepchecks: Not installed
2024-01-18 11:41:51,590:INFO:             xgboost: 2.0.3
2024-01-18 11:41:51,590:INFO:            catboost: 1.2.2
2024-01-18 11:41:51,591:INFO:              kmodes: Not installed
2024-01-18 11:41:51,591:INFO:             mlxtend: Not installed
2024-01-18 11:41:51,591:INFO:       statsforecast: Not installed
2024-01-18 11:41:51,591:INFO:        tune_sklearn: Not installed
2024-01-18 11:41:51,591:INFO:                 ray: Not installed
2024-01-18 11:41:51,591:INFO:            hyperopt: Not installed
2024-01-18 11:41:51,591:INFO:              optuna: 3.5.0
2024-01-18 11:41:51,591:INFO:               skopt: Not installed
2024-01-18 11:41:51,591:INFO:              mlflow: Not installed
2024-01-18 11:41:51,591:INFO:              gradio: Not installed
2024-01-18 11:41:51,591:INFO:             fastapi: Not installed
2024-01-18 11:41:51,591:INFO:             uvicorn: Not installed
2024-01-18 11:41:51,591:INFO:              m2cgen: Not installed
2024-01-18 11:41:51,591:INFO:           evidently: Not installed
2024-01-18 11:41:51,591:INFO:               fugue: Not installed
2024-01-18 11:41:51,591:INFO:           streamlit: Not installed
2024-01-18 11:41:51,591:INFO:             prophet: Not installed
2024-01-18 11:41:51,591:INFO:None
2024-01-18 11:41:51,591:INFO:Set up data.
2024-01-18 11:41:52,452:INFO:PyCaret ClassificationExperiment
2024-01-18 11:41:52,452:INFO:Logging name: clf-default-name
2024-01-18 11:41:52,452:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:41:52,452:INFO:version 3.2.0
2024-01-18 11:41:52,452:INFO:Initializing setup()
2024-01-18 11:41:52,452:INFO:self.USI: 301c
2024-01-18 11:41:52,452:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:41:52,452:INFO:Checking environment
2024-01-18 11:41:52,452:INFO:python_version: 3.11.5
2024-01-18 11:41:52,452:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:41:52,453:INFO:machine: AMD64
2024-01-18 11:41:52,453:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:41:52,453:INFO:Memory: svmem(total=8361132032, available=1908539392, percent=77.2, used=6452592640, free=1908539392)
2024-01-18 11:41:52,453:INFO:Physical Core: 2
2024-01-18 11:41:52,453:INFO:Logical Core: 4
2024-01-18 11:41:52,453:INFO:Checking libraries
2024-01-18 11:41:52,453:INFO:System:
2024-01-18 11:41:52,453:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:41:52,453:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:41:52,453:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:41:52,453:INFO:PyCaret required dependencies:
2024-01-18 11:41:52,453:INFO:                 pip: 23.2.1
2024-01-18 11:41:52,454:INFO:          setuptools: 68.0.0
2024-01-18 11:41:52,454:INFO:             pycaret: 3.2.0
2024-01-18 11:41:52,454:INFO:             IPython: 8.15.0
2024-01-18 11:41:52,454:INFO:          ipywidgets: 8.0.4
2024-01-18 11:41:52,454:INFO:                tqdm: 4.65.0
2024-01-18 11:41:52,454:INFO:               numpy: 1.24.3
2024-01-18 11:41:52,454:INFO:              pandas: 1.5.3
2024-01-18 11:41:52,454:INFO:              jinja2: 3.1.2
2024-01-18 11:41:52,454:INFO:               scipy: 1.10.1
2024-01-18 11:41:52,454:INFO:              joblib: 1.2.0
2024-01-18 11:41:52,454:INFO:             sklearn: 1.2.2
2024-01-18 11:41:52,454:INFO:                pyod: 1.1.2
2024-01-18 11:41:52,454:INFO:            imblearn: 0.10.1
2024-01-18 11:41:52,454:INFO:   category_encoders: 2.6.3
2024-01-18 11:41:52,455:INFO:            lightgbm: 4.2.0
2024-01-18 11:41:52,455:INFO:               numba: 0.57.1
2024-01-18 11:41:52,455:INFO:            requests: 2.31.0
2024-01-18 11:41:52,455:INFO:          matplotlib: 3.6.0
2024-01-18 11:41:52,455:INFO:          scikitplot: 0.3.7
2024-01-18 11:41:52,455:INFO:         yellowbrick: 1.5
2024-01-18 11:41:52,455:INFO:              plotly: 5.9.0
2024-01-18 11:41:52,455:INFO:    plotly-resampler: Not installed
2024-01-18 11:41:52,455:INFO:             kaleido: 0.2.1
2024-01-18 11:41:52,455:INFO:           schemdraw: 0.15
2024-01-18 11:41:52,455:INFO:         statsmodels: 0.14.0
2024-01-18 11:41:52,455:INFO:              sktime: 0.21.1
2024-01-18 11:41:52,455:INFO:               tbats: 1.1.3
2024-01-18 11:41:52,455:INFO:            pmdarima: 2.0.4
2024-01-18 11:41:52,455:INFO:              psutil: 5.9.0
2024-01-18 11:41:52,455:INFO:          markupsafe: 2.1.1
2024-01-18 11:41:52,456:INFO:             pickle5: Not installed
2024-01-18 11:41:52,456:INFO:         cloudpickle: 2.2.1
2024-01-18 11:41:52,456:INFO:         deprecation: 2.1.0
2024-01-18 11:41:52,456:INFO:              xxhash: 2.0.2
2024-01-18 11:41:52,457:INFO:           wurlitzer: Not installed
2024-01-18 11:41:52,457:INFO:PyCaret optional dependencies:
2024-01-18 11:41:52,457:INFO:                shap: Not installed
2024-01-18 11:41:52,457:INFO:           interpret: Not installed
2024-01-18 11:41:52,457:INFO:                umap: Not installed
2024-01-18 11:41:52,457:INFO:     ydata_profiling: Not installed
2024-01-18 11:41:52,457:INFO:  explainerdashboard: Not installed
2024-01-18 11:41:52,457:INFO:             autoviz: Not installed
2024-01-18 11:41:52,457:INFO:           fairlearn: Not installed
2024-01-18 11:41:52,457:INFO:          deepchecks: Not installed
2024-01-18 11:41:52,457:INFO:             xgboost: 2.0.3
2024-01-18 11:41:52,457:INFO:            catboost: 1.2.2
2024-01-18 11:41:52,457:INFO:              kmodes: Not installed
2024-01-18 11:41:52,457:INFO:             mlxtend: Not installed
2024-01-18 11:41:52,458:INFO:       statsforecast: Not installed
2024-01-18 11:41:52,458:INFO:        tune_sklearn: Not installed
2024-01-18 11:41:52,458:INFO:                 ray: Not installed
2024-01-18 11:41:52,458:INFO:            hyperopt: Not installed
2024-01-18 11:41:52,458:INFO:              optuna: 3.5.0
2024-01-18 11:41:52,458:INFO:               skopt: Not installed
2024-01-18 11:41:52,458:INFO:              mlflow: Not installed
2024-01-18 11:41:52,458:INFO:              gradio: Not installed
2024-01-18 11:41:52,458:INFO:             fastapi: Not installed
2024-01-18 11:41:52,458:INFO:             uvicorn: Not installed
2024-01-18 11:41:52,458:INFO:              m2cgen: Not installed
2024-01-18 11:41:52,458:INFO:           evidently: Not installed
2024-01-18 11:41:52,458:INFO:               fugue: Not installed
2024-01-18 11:41:52,458:INFO:           streamlit: Not installed
2024-01-18 11:41:52,459:INFO:             prophet: Not installed
2024-01-18 11:41:52,459:INFO:None
2024-01-18 11:41:52,459:INFO:Set up data.
2024-01-18 11:42:57,670:INFO:PyCaret ClassificationExperiment
2024-01-18 11:42:57,670:INFO:Logging name: clf-default-name
2024-01-18 11:42:57,670:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:42:57,670:INFO:version 3.2.0
2024-01-18 11:42:57,670:INFO:Initializing setup()
2024-01-18 11:42:57,670:INFO:self.USI: d35c
2024-01-18 11:42:57,670:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:42:57,671:INFO:Checking environment
2024-01-18 11:42:57,671:INFO:python_version: 3.11.5
2024-01-18 11:42:57,671:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:42:57,671:INFO:machine: AMD64
2024-01-18 11:42:57,671:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:42:57,671:INFO:Memory: svmem(total=8361132032, available=1906614272, percent=77.2, used=6454517760, free=1906614272)
2024-01-18 11:42:57,671:INFO:Physical Core: 2
2024-01-18 11:42:57,671:INFO:Logical Core: 4
2024-01-18 11:42:57,671:INFO:Checking libraries
2024-01-18 11:42:57,671:INFO:System:
2024-01-18 11:42:57,671:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:42:57,671:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:42:57,671:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:42:57,671:INFO:PyCaret required dependencies:
2024-01-18 11:42:57,671:INFO:                 pip: 23.2.1
2024-01-18 11:42:57,671:INFO:          setuptools: 68.0.0
2024-01-18 11:42:57,672:INFO:             pycaret: 3.2.0
2024-01-18 11:42:57,672:INFO:             IPython: 8.15.0
2024-01-18 11:42:57,672:INFO:          ipywidgets: 8.0.4
2024-01-18 11:42:57,672:INFO:                tqdm: 4.65.0
2024-01-18 11:42:57,672:INFO:               numpy: 1.24.3
2024-01-18 11:42:57,672:INFO:              pandas: 1.5.3
2024-01-18 11:42:57,672:INFO:              jinja2: 3.1.2
2024-01-18 11:42:57,672:INFO:               scipy: 1.10.1
2024-01-18 11:42:57,672:INFO:              joblib: 1.2.0
2024-01-18 11:42:57,672:INFO:             sklearn: 1.2.2
2024-01-18 11:42:57,672:INFO:                pyod: 1.1.2
2024-01-18 11:42:57,672:INFO:            imblearn: 0.10.1
2024-01-18 11:42:57,672:INFO:   category_encoders: 2.6.3
2024-01-18 11:42:57,672:INFO:            lightgbm: 4.2.0
2024-01-18 11:42:57,672:INFO:               numba: 0.57.1
2024-01-18 11:42:57,672:INFO:            requests: 2.31.0
2024-01-18 11:42:57,672:INFO:          matplotlib: 3.6.0
2024-01-18 11:42:57,672:INFO:          scikitplot: 0.3.7
2024-01-18 11:42:57,672:INFO:         yellowbrick: 1.5
2024-01-18 11:42:57,672:INFO:              plotly: 5.9.0
2024-01-18 11:42:57,672:INFO:    plotly-resampler: Not installed
2024-01-18 11:42:57,672:INFO:             kaleido: 0.2.1
2024-01-18 11:42:57,672:INFO:           schemdraw: 0.15
2024-01-18 11:42:57,672:INFO:         statsmodels: 0.14.0
2024-01-18 11:42:57,672:INFO:              sktime: 0.21.1
2024-01-18 11:42:57,673:INFO:               tbats: 1.1.3
2024-01-18 11:42:57,673:INFO:            pmdarima: 2.0.4
2024-01-18 11:42:57,673:INFO:              psutil: 5.9.0
2024-01-18 11:42:57,673:INFO:          markupsafe: 2.1.1
2024-01-18 11:42:57,673:INFO:             pickle5: Not installed
2024-01-18 11:42:57,673:INFO:         cloudpickle: 2.2.1
2024-01-18 11:42:57,673:INFO:         deprecation: 2.1.0
2024-01-18 11:42:57,673:INFO:              xxhash: 2.0.2
2024-01-18 11:42:57,673:INFO:           wurlitzer: Not installed
2024-01-18 11:42:57,673:INFO:PyCaret optional dependencies:
2024-01-18 11:42:57,673:INFO:                shap: Not installed
2024-01-18 11:42:57,673:INFO:           interpret: Not installed
2024-01-18 11:42:57,673:INFO:                umap: Not installed
2024-01-18 11:42:57,673:INFO:     ydata_profiling: Not installed
2024-01-18 11:42:57,673:INFO:  explainerdashboard: Not installed
2024-01-18 11:42:57,673:INFO:             autoviz: Not installed
2024-01-18 11:42:57,673:INFO:           fairlearn: Not installed
2024-01-18 11:42:57,673:INFO:          deepchecks: Not installed
2024-01-18 11:42:57,673:INFO:             xgboost: 2.0.3
2024-01-18 11:42:57,673:INFO:            catboost: 1.2.2
2024-01-18 11:42:57,674:INFO:              kmodes: Not installed
2024-01-18 11:42:57,674:INFO:             mlxtend: Not installed
2024-01-18 11:42:57,674:INFO:       statsforecast: Not installed
2024-01-18 11:42:57,674:INFO:        tune_sklearn: Not installed
2024-01-18 11:42:57,674:INFO:                 ray: Not installed
2024-01-18 11:42:57,674:INFO:            hyperopt: Not installed
2024-01-18 11:42:57,674:INFO:              optuna: 3.5.0
2024-01-18 11:42:57,674:INFO:               skopt: Not installed
2024-01-18 11:42:57,674:INFO:              mlflow: Not installed
2024-01-18 11:42:57,674:INFO:              gradio: Not installed
2024-01-18 11:42:57,674:INFO:             fastapi: Not installed
2024-01-18 11:42:57,674:INFO:             uvicorn: Not installed
2024-01-18 11:42:57,674:INFO:              m2cgen: Not installed
2024-01-18 11:42:57,674:INFO:           evidently: Not installed
2024-01-18 11:42:57,674:INFO:               fugue: Not installed
2024-01-18 11:42:57,674:INFO:           streamlit: Not installed
2024-01-18 11:42:57,674:INFO:             prophet: Not installed
2024-01-18 11:42:57,674:INFO:None
2024-01-18 11:42:57,674:INFO:Set up data.
2024-01-18 11:42:57,682:INFO:Set up folding strategy.
2024-01-18 11:42:57,683:INFO:Set up train/test split.
2024-01-18 11:42:57,690:INFO:Set up index.
2024-01-18 11:42:57,690:INFO:Assigning column types.
2024-01-18 11:44:53,942:INFO:PyCaret ClassificationExperiment
2024-01-18 11:44:53,942:INFO:Logging name: clf-default-name
2024-01-18 11:44:53,942:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:44:53,942:INFO:version 3.2.0
2024-01-18 11:44:53,942:INFO:Initializing setup()
2024-01-18 11:44:53,942:INFO:self.USI: 7fcd
2024-01-18 11:44:53,943:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:44:53,943:INFO:Checking environment
2024-01-18 11:44:53,943:INFO:python_version: 3.11.5
2024-01-18 11:44:53,943:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:44:53,943:INFO:machine: AMD64
2024-01-18 11:44:53,943:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:44:53,943:INFO:Memory: svmem(total=8361132032, available=1808179200, percent=78.4, used=6552952832, free=1808179200)
2024-01-18 11:44:53,943:INFO:Physical Core: 2
2024-01-18 11:44:53,943:INFO:Logical Core: 4
2024-01-18 11:44:53,943:INFO:Checking libraries
2024-01-18 11:44:53,943:INFO:System:
2024-01-18 11:44:53,943:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:44:53,943:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:44:53,943:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:44:53,943:INFO:PyCaret required dependencies:
2024-01-18 11:44:53,943:INFO:                 pip: 23.2.1
2024-01-18 11:44:53,944:INFO:          setuptools: 68.0.0
2024-01-18 11:44:53,944:INFO:             pycaret: 3.2.0
2024-01-18 11:44:53,944:INFO:             IPython: 8.15.0
2024-01-18 11:44:53,944:INFO:          ipywidgets: 8.0.4
2024-01-18 11:44:53,944:INFO:                tqdm: 4.65.0
2024-01-18 11:44:53,944:INFO:               numpy: 1.24.3
2024-01-18 11:44:53,944:INFO:              pandas: 1.5.3
2024-01-18 11:44:53,944:INFO:              jinja2: 3.1.2
2024-01-18 11:44:53,944:INFO:               scipy: 1.10.1
2024-01-18 11:44:53,944:INFO:              joblib: 1.2.0
2024-01-18 11:44:53,944:INFO:             sklearn: 1.2.2
2024-01-18 11:44:53,944:INFO:                pyod: 1.1.2
2024-01-18 11:44:53,944:INFO:            imblearn: 0.10.1
2024-01-18 11:44:53,944:INFO:   category_encoders: 2.6.3
2024-01-18 11:44:53,944:INFO:            lightgbm: 4.2.0
2024-01-18 11:44:53,944:INFO:               numba: 0.57.1
2024-01-18 11:44:53,944:INFO:            requests: 2.31.0
2024-01-18 11:44:53,944:INFO:          matplotlib: 3.6.0
2024-01-18 11:44:53,944:INFO:          scikitplot: 0.3.7
2024-01-18 11:44:53,944:INFO:         yellowbrick: 1.5
2024-01-18 11:44:53,944:INFO:              plotly: 5.9.0
2024-01-18 11:44:53,945:INFO:    plotly-resampler: Not installed
2024-01-18 11:44:53,945:INFO:             kaleido: 0.2.1
2024-01-18 11:44:53,945:INFO:           schemdraw: 0.15
2024-01-18 11:44:53,945:INFO:         statsmodels: 0.14.0
2024-01-18 11:44:53,945:INFO:              sktime: 0.21.1
2024-01-18 11:44:53,945:INFO:               tbats: 1.1.3
2024-01-18 11:44:53,945:INFO:            pmdarima: 2.0.4
2024-01-18 11:44:53,945:INFO:              psutil: 5.9.0
2024-01-18 11:44:53,945:INFO:          markupsafe: 2.1.1
2024-01-18 11:44:53,945:INFO:             pickle5: Not installed
2024-01-18 11:44:53,945:INFO:         cloudpickle: 2.2.1
2024-01-18 11:44:53,945:INFO:         deprecation: 2.1.0
2024-01-18 11:44:53,945:INFO:              xxhash: 2.0.2
2024-01-18 11:44:53,945:INFO:           wurlitzer: Not installed
2024-01-18 11:44:53,945:INFO:PyCaret optional dependencies:
2024-01-18 11:44:53,945:INFO:                shap: Not installed
2024-01-18 11:44:53,945:INFO:           interpret: Not installed
2024-01-18 11:44:53,945:INFO:                umap: Not installed
2024-01-18 11:44:53,945:INFO:     ydata_profiling: Not installed
2024-01-18 11:44:53,945:INFO:  explainerdashboard: Not installed
2024-01-18 11:44:53,946:INFO:             autoviz: Not installed
2024-01-18 11:44:53,946:INFO:           fairlearn: Not installed
2024-01-18 11:44:53,946:INFO:          deepchecks: Not installed
2024-01-18 11:44:53,946:INFO:             xgboost: 2.0.3
2024-01-18 11:44:53,946:INFO:            catboost: 1.2.2
2024-01-18 11:44:53,946:INFO:              kmodes: Not installed
2024-01-18 11:44:53,946:INFO:             mlxtend: Not installed
2024-01-18 11:44:53,946:INFO:       statsforecast: Not installed
2024-01-18 11:44:53,946:INFO:        tune_sklearn: Not installed
2024-01-18 11:44:53,946:INFO:                 ray: Not installed
2024-01-18 11:44:53,946:INFO:            hyperopt: Not installed
2024-01-18 11:44:53,946:INFO:              optuna: 3.5.0
2024-01-18 11:44:53,946:INFO:               skopt: Not installed
2024-01-18 11:44:53,946:INFO:              mlflow: Not installed
2024-01-18 11:44:53,946:INFO:              gradio: Not installed
2024-01-18 11:44:53,946:INFO:             fastapi: Not installed
2024-01-18 11:44:53,946:INFO:             uvicorn: Not installed
2024-01-18 11:44:53,946:INFO:              m2cgen: Not installed
2024-01-18 11:44:53,946:INFO:           evidently: Not installed
2024-01-18 11:44:53,946:INFO:               fugue: Not installed
2024-01-18 11:44:53,946:INFO:           streamlit: Not installed
2024-01-18 11:44:53,946:INFO:             prophet: Not installed
2024-01-18 11:44:53,947:INFO:None
2024-01-18 11:44:53,947:INFO:Set up data.
2024-01-18 11:44:53,959:INFO:Set up folding strategy.
2024-01-18 11:44:53,959:INFO:Set up train/test split.
2024-01-18 11:44:53,969:INFO:Set up index.
2024-01-18 11:44:53,969:INFO:Assigning column types.
2024-01-18 11:46:33,905:INFO:PyCaret ClassificationExperiment
2024-01-18 11:46:33,905:INFO:Logging name: clf-default-name
2024-01-18 11:46:33,906:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:46:33,906:INFO:version 3.2.0
2024-01-18 11:46:33,906:INFO:Initializing setup()
2024-01-18 11:46:33,906:INFO:self.USI: 36f2
2024-01-18 11:46:33,906:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:46:33,906:INFO:Checking environment
2024-01-18 11:46:33,906:INFO:python_version: 3.11.5
2024-01-18 11:46:33,906:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:46:33,906:INFO:machine: AMD64
2024-01-18 11:46:33,906:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:46:33,906:INFO:Memory: svmem(total=8361132032, available=1865097216, percent=77.7, used=6496034816, free=1865097216)
2024-01-18 11:46:33,906:INFO:Physical Core: 2
2024-01-18 11:46:33,906:INFO:Logical Core: 4
2024-01-18 11:46:33,906:INFO:Checking libraries
2024-01-18 11:46:33,906:INFO:System:
2024-01-18 11:46:33,906:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:46:33,906:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:46:33,906:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:46:33,907:INFO:PyCaret required dependencies:
2024-01-18 11:46:33,907:INFO:                 pip: 23.2.1
2024-01-18 11:46:33,907:INFO:          setuptools: 68.0.0
2024-01-18 11:46:33,907:INFO:             pycaret: 3.2.0
2024-01-18 11:46:33,907:INFO:             IPython: 8.15.0
2024-01-18 11:46:33,907:INFO:          ipywidgets: 8.0.4
2024-01-18 11:46:33,907:INFO:                tqdm: 4.65.0
2024-01-18 11:46:33,907:INFO:               numpy: 1.24.3
2024-01-18 11:46:33,907:INFO:              pandas: 1.5.3
2024-01-18 11:46:33,907:INFO:              jinja2: 3.1.2
2024-01-18 11:46:33,907:INFO:               scipy: 1.10.1
2024-01-18 11:46:33,907:INFO:              joblib: 1.2.0
2024-01-18 11:46:33,907:INFO:             sklearn: 1.2.2
2024-01-18 11:46:33,907:INFO:                pyod: 1.1.2
2024-01-18 11:46:33,907:INFO:            imblearn: 0.10.1
2024-01-18 11:46:33,907:INFO:   category_encoders: 2.6.3
2024-01-18 11:46:33,907:INFO:            lightgbm: 4.2.0
2024-01-18 11:46:33,907:INFO:               numba: 0.57.1
2024-01-18 11:46:33,907:INFO:            requests: 2.31.0
2024-01-18 11:46:33,907:INFO:          matplotlib: 3.6.0
2024-01-18 11:46:33,907:INFO:          scikitplot: 0.3.7
2024-01-18 11:46:33,907:INFO:         yellowbrick: 1.5
2024-01-18 11:46:33,907:INFO:              plotly: 5.9.0
2024-01-18 11:46:33,907:INFO:    plotly-resampler: Not installed
2024-01-18 11:46:33,907:INFO:             kaleido: 0.2.1
2024-01-18 11:46:33,908:INFO:           schemdraw: 0.15
2024-01-18 11:46:33,908:INFO:         statsmodels: 0.14.0
2024-01-18 11:46:33,908:INFO:              sktime: 0.21.1
2024-01-18 11:46:33,908:INFO:               tbats: 1.1.3
2024-01-18 11:46:33,908:INFO:            pmdarima: 2.0.4
2024-01-18 11:46:33,908:INFO:              psutil: 5.9.0
2024-01-18 11:46:33,908:INFO:          markupsafe: 2.1.1
2024-01-18 11:46:33,908:INFO:             pickle5: Not installed
2024-01-18 11:46:33,908:INFO:         cloudpickle: 2.2.1
2024-01-18 11:46:33,908:INFO:         deprecation: 2.1.0
2024-01-18 11:46:33,908:INFO:              xxhash: 2.0.2
2024-01-18 11:46:33,908:INFO:           wurlitzer: Not installed
2024-01-18 11:46:33,908:INFO:PyCaret optional dependencies:
2024-01-18 11:46:33,908:INFO:                shap: Not installed
2024-01-18 11:46:33,908:INFO:           interpret: Not installed
2024-01-18 11:46:33,908:INFO:                umap: Not installed
2024-01-18 11:46:33,908:INFO:     ydata_profiling: Not installed
2024-01-18 11:46:33,908:INFO:  explainerdashboard: Not installed
2024-01-18 11:46:33,908:INFO:             autoviz: Not installed
2024-01-18 11:46:33,908:INFO:           fairlearn: Not installed
2024-01-18 11:46:33,908:INFO:          deepchecks: Not installed
2024-01-18 11:46:33,908:INFO:             xgboost: 2.0.3
2024-01-18 11:46:33,909:INFO:            catboost: 1.2.2
2024-01-18 11:46:33,909:INFO:              kmodes: Not installed
2024-01-18 11:46:33,909:INFO:             mlxtend: Not installed
2024-01-18 11:46:33,909:INFO:       statsforecast: Not installed
2024-01-18 11:46:33,909:INFO:        tune_sklearn: Not installed
2024-01-18 11:46:33,909:INFO:                 ray: Not installed
2024-01-18 11:46:33,909:INFO:            hyperopt: Not installed
2024-01-18 11:46:33,909:INFO:              optuna: 3.5.0
2024-01-18 11:46:33,909:INFO:               skopt: Not installed
2024-01-18 11:46:33,909:INFO:              mlflow: Not installed
2024-01-18 11:46:33,909:INFO:              gradio: Not installed
2024-01-18 11:46:33,909:INFO:             fastapi: Not installed
2024-01-18 11:46:33,910:INFO:             uvicorn: Not installed
2024-01-18 11:46:33,910:INFO:              m2cgen: Not installed
2024-01-18 11:46:33,910:INFO:           evidently: Not installed
2024-01-18 11:46:33,910:INFO:               fugue: Not installed
2024-01-18 11:46:33,910:INFO:           streamlit: Not installed
2024-01-18 11:46:33,910:INFO:             prophet: Not installed
2024-01-18 11:46:33,910:INFO:None
2024-01-18 11:46:33,910:INFO:Set up data.
2024-01-18 11:46:33,919:INFO:Set up folding strategy.
2024-01-18 11:46:33,919:INFO:Set up train/test split.
2024-01-18 11:46:33,926:INFO:Set up index.
2024-01-18 11:46:33,926:INFO:Assigning column types.
2024-01-18 11:47:08,601:INFO:PyCaret ClassificationExperiment
2024-01-18 11:47:08,601:INFO:Logging name: clf-default-name
2024-01-18 11:47:08,601:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:47:08,601:INFO:version 3.2.0
2024-01-18 11:47:08,601:INFO:Initializing setup()
2024-01-18 11:47:08,601:INFO:self.USI: 6b2d
2024-01-18 11:47:08,601:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:47:08,601:INFO:Checking environment
2024-01-18 11:47:08,601:INFO:python_version: 3.11.5
2024-01-18 11:47:08,601:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:47:08,601:INFO:machine: AMD64
2024-01-18 11:47:08,601:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:47:08,602:INFO:Memory: svmem(total=8361132032, available=1825386496, percent=78.2, used=6535745536, free=1825386496)
2024-01-18 11:47:08,602:INFO:Physical Core: 2
2024-01-18 11:47:08,602:INFO:Logical Core: 4
2024-01-18 11:47:08,602:INFO:Checking libraries
2024-01-18 11:47:08,602:INFO:System:
2024-01-18 11:47:08,602:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:47:08,602:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:47:08,602:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:47:08,602:INFO:PyCaret required dependencies:
2024-01-18 11:47:08,602:INFO:                 pip: 23.2.1
2024-01-18 11:47:08,602:INFO:          setuptools: 68.0.0
2024-01-18 11:47:08,602:INFO:             pycaret: 3.2.0
2024-01-18 11:47:08,602:INFO:             IPython: 8.15.0
2024-01-18 11:47:08,602:INFO:          ipywidgets: 8.0.4
2024-01-18 11:47:08,602:INFO:                tqdm: 4.65.0
2024-01-18 11:47:08,602:INFO:               numpy: 1.24.3
2024-01-18 11:47:08,602:INFO:              pandas: 1.5.3
2024-01-18 11:47:08,602:INFO:              jinja2: 3.1.2
2024-01-18 11:47:08,602:INFO:               scipy: 1.10.1
2024-01-18 11:47:08,603:INFO:              joblib: 1.2.0
2024-01-18 11:47:08,603:INFO:             sklearn: 1.2.2
2024-01-18 11:47:08,603:INFO:                pyod: 1.1.2
2024-01-18 11:47:08,603:INFO:            imblearn: 0.10.1
2024-01-18 11:47:08,603:INFO:   category_encoders: 2.6.3
2024-01-18 11:47:08,603:INFO:            lightgbm: 4.2.0
2024-01-18 11:47:08,603:INFO:               numba: 0.57.1
2024-01-18 11:47:08,603:INFO:            requests: 2.31.0
2024-01-18 11:47:08,603:INFO:          matplotlib: 3.6.0
2024-01-18 11:47:08,603:INFO:          scikitplot: 0.3.7
2024-01-18 11:47:08,603:INFO:         yellowbrick: 1.5
2024-01-18 11:47:08,603:INFO:              plotly: 5.9.0
2024-01-18 11:47:08,603:INFO:    plotly-resampler: Not installed
2024-01-18 11:47:08,603:INFO:             kaleido: 0.2.1
2024-01-18 11:47:08,603:INFO:           schemdraw: 0.15
2024-01-18 11:47:08,603:INFO:         statsmodels: 0.14.0
2024-01-18 11:47:08,603:INFO:              sktime: 0.21.1
2024-01-18 11:47:08,603:INFO:               tbats: 1.1.3
2024-01-18 11:47:08,603:INFO:            pmdarima: 2.0.4
2024-01-18 11:47:08,603:INFO:              psutil: 5.9.0
2024-01-18 11:47:08,603:INFO:          markupsafe: 2.1.1
2024-01-18 11:47:08,603:INFO:             pickle5: Not installed
2024-01-18 11:47:08,603:INFO:         cloudpickle: 2.2.1
2024-01-18 11:47:08,603:INFO:         deprecation: 2.1.0
2024-01-18 11:47:08,603:INFO:              xxhash: 2.0.2
2024-01-18 11:47:08,604:INFO:           wurlitzer: Not installed
2024-01-18 11:47:08,604:INFO:PyCaret optional dependencies:
2024-01-18 11:47:08,604:INFO:                shap: Not installed
2024-01-18 11:47:08,604:INFO:           interpret: Not installed
2024-01-18 11:47:08,604:INFO:                umap: Not installed
2024-01-18 11:47:08,604:INFO:     ydata_profiling: Not installed
2024-01-18 11:47:08,604:INFO:  explainerdashboard: Not installed
2024-01-18 11:47:08,604:INFO:             autoviz: Not installed
2024-01-18 11:47:08,604:INFO:           fairlearn: Not installed
2024-01-18 11:47:08,604:INFO:          deepchecks: Not installed
2024-01-18 11:47:08,604:INFO:             xgboost: 2.0.3
2024-01-18 11:47:08,604:INFO:            catboost: 1.2.2
2024-01-18 11:47:08,605:INFO:              kmodes: Not installed
2024-01-18 11:47:08,605:INFO:             mlxtend: Not installed
2024-01-18 11:47:08,605:INFO:       statsforecast: Not installed
2024-01-18 11:47:08,605:INFO:        tune_sklearn: Not installed
2024-01-18 11:47:08,605:INFO:                 ray: Not installed
2024-01-18 11:47:08,605:INFO:            hyperopt: Not installed
2024-01-18 11:47:08,605:INFO:              optuna: 3.5.0
2024-01-18 11:47:08,605:INFO:               skopt: Not installed
2024-01-18 11:47:08,605:INFO:              mlflow: Not installed
2024-01-18 11:47:08,605:INFO:              gradio: Not installed
2024-01-18 11:47:08,605:INFO:             fastapi: Not installed
2024-01-18 11:47:08,605:INFO:             uvicorn: Not installed
2024-01-18 11:47:08,605:INFO:              m2cgen: Not installed
2024-01-18 11:47:08,605:INFO:           evidently: Not installed
2024-01-18 11:47:08,605:INFO:               fugue: Not installed
2024-01-18 11:47:08,605:INFO:           streamlit: Not installed
2024-01-18 11:47:08,605:INFO:             prophet: Not installed
2024-01-18 11:47:08,605:INFO:None
2024-01-18 11:47:08,605:INFO:Set up data.
2024-01-18 11:47:08,613:INFO:Set up folding strategy.
2024-01-18 11:47:08,613:INFO:Set up train/test split.
2024-01-18 11:47:08,620:INFO:Set up index.
2024-01-18 11:47:08,620:INFO:Assigning column types.
2024-01-18 11:48:42,630:INFO:PyCaret ClassificationExperiment
2024-01-18 11:48:42,630:INFO:Logging name: clf-default-name
2024-01-18 11:48:42,630:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:48:42,630:INFO:version 3.2.0
2024-01-18 11:48:42,630:INFO:Initializing setup()
2024-01-18 11:48:42,630:INFO:self.USI: 3fb8
2024-01-18 11:48:42,630:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:48:42,630:INFO:Checking environment
2024-01-18 11:48:42,631:INFO:python_version: 3.11.5
2024-01-18 11:48:42,632:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:48:42,632:INFO:machine: AMD64
2024-01-18 11:48:42,632:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:48:42,632:INFO:Memory: svmem(total=8361132032, available=1805717504, percent=78.4, used=6555414528, free=1805717504)
2024-01-18 11:48:42,632:INFO:Physical Core: 2
2024-01-18 11:48:42,632:INFO:Logical Core: 4
2024-01-18 11:48:42,632:INFO:Checking libraries
2024-01-18 11:48:42,632:INFO:System:
2024-01-18 11:48:42,632:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:48:42,632:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:48:42,632:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:48:42,632:INFO:PyCaret required dependencies:
2024-01-18 11:48:42,632:INFO:                 pip: 23.2.1
2024-01-18 11:48:42,632:INFO:          setuptools: 68.0.0
2024-01-18 11:48:42,632:INFO:             pycaret: 3.2.0
2024-01-18 11:48:42,633:INFO:             IPython: 8.15.0
2024-01-18 11:48:42,633:INFO:          ipywidgets: 8.0.4
2024-01-18 11:48:42,633:INFO:                tqdm: 4.65.0
2024-01-18 11:48:42,633:INFO:               numpy: 1.24.3
2024-01-18 11:48:42,633:INFO:              pandas: 1.5.3
2024-01-18 11:48:42,633:INFO:              jinja2: 3.1.2
2024-01-18 11:48:42,633:INFO:               scipy: 1.10.1
2024-01-18 11:48:42,633:INFO:              joblib: 1.2.0
2024-01-18 11:48:42,633:INFO:             sklearn: 1.2.2
2024-01-18 11:48:42,633:INFO:                pyod: 1.1.2
2024-01-18 11:48:42,633:INFO:            imblearn: 0.10.1
2024-01-18 11:48:42,633:INFO:   category_encoders: 2.6.3
2024-01-18 11:48:42,633:INFO:            lightgbm: 4.2.0
2024-01-18 11:48:42,633:INFO:               numba: 0.57.1
2024-01-18 11:48:42,633:INFO:            requests: 2.31.0
2024-01-18 11:48:42,633:INFO:          matplotlib: 3.6.0
2024-01-18 11:48:42,633:INFO:          scikitplot: 0.3.7
2024-01-18 11:48:42,633:INFO:         yellowbrick: 1.5
2024-01-18 11:48:42,633:INFO:              plotly: 5.9.0
2024-01-18 11:48:42,633:INFO:    plotly-resampler: Not installed
2024-01-18 11:48:42,633:INFO:             kaleido: 0.2.1
2024-01-18 11:48:42,633:INFO:           schemdraw: 0.15
2024-01-18 11:48:42,633:INFO:         statsmodels: 0.14.0
2024-01-18 11:48:42,633:INFO:              sktime: 0.21.1
2024-01-18 11:48:42,633:INFO:               tbats: 1.1.3
2024-01-18 11:48:42,634:INFO:            pmdarima: 2.0.4
2024-01-18 11:48:42,634:INFO:              psutil: 5.9.0
2024-01-18 11:48:42,634:INFO:          markupsafe: 2.1.1
2024-01-18 11:48:42,634:INFO:             pickle5: Not installed
2024-01-18 11:48:42,634:INFO:         cloudpickle: 2.2.1
2024-01-18 11:48:42,634:INFO:         deprecation: 2.1.0
2024-01-18 11:48:42,634:INFO:              xxhash: 2.0.2
2024-01-18 11:48:42,634:INFO:           wurlitzer: Not installed
2024-01-18 11:48:42,634:INFO:PyCaret optional dependencies:
2024-01-18 11:48:42,634:INFO:                shap: Not installed
2024-01-18 11:48:42,634:INFO:           interpret: Not installed
2024-01-18 11:48:42,634:INFO:                umap: Not installed
2024-01-18 11:48:42,634:INFO:     ydata_profiling: Not installed
2024-01-18 11:48:42,634:INFO:  explainerdashboard: Not installed
2024-01-18 11:48:42,634:INFO:             autoviz: Not installed
2024-01-18 11:48:42,634:INFO:           fairlearn: Not installed
2024-01-18 11:48:42,634:INFO:          deepchecks: Not installed
2024-01-18 11:48:42,634:INFO:             xgboost: 2.0.3
2024-01-18 11:48:42,634:INFO:            catboost: 1.2.2
2024-01-18 11:48:42,634:INFO:              kmodes: Not installed
2024-01-18 11:48:42,634:INFO:             mlxtend: Not installed
2024-01-18 11:48:42,634:INFO:       statsforecast: Not installed
2024-01-18 11:48:42,634:INFO:        tune_sklearn: Not installed
2024-01-18 11:48:42,635:INFO:                 ray: Not installed
2024-01-18 11:48:42,635:INFO:            hyperopt: Not installed
2024-01-18 11:48:42,635:INFO:              optuna: 3.5.0
2024-01-18 11:48:42,635:INFO:               skopt: Not installed
2024-01-18 11:48:42,635:INFO:              mlflow: Not installed
2024-01-18 11:48:42,635:INFO:              gradio: Not installed
2024-01-18 11:48:42,635:INFO:             fastapi: Not installed
2024-01-18 11:48:42,635:INFO:             uvicorn: Not installed
2024-01-18 11:48:42,635:INFO:              m2cgen: Not installed
2024-01-18 11:48:42,635:INFO:           evidently: Not installed
2024-01-18 11:48:42,635:INFO:               fugue: Not installed
2024-01-18 11:48:42,635:INFO:           streamlit: Not installed
2024-01-18 11:48:42,635:INFO:             prophet: Not installed
2024-01-18 11:48:42,635:INFO:None
2024-01-18 11:48:42,635:INFO:Set up data.
2024-01-18 11:48:42,646:INFO:Set up folding strategy.
2024-01-18 11:48:42,648:INFO:Set up train/test split.
2024-01-18 11:48:42,661:INFO:Set up index.
2024-01-18 11:48:42,662:INFO:Assigning column types.
2024-01-18 11:48:42,672:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 11:48:42,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:48:42,729:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:48:42,744:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:42,760:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:42,812:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:48:42,813:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:48:42,847:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:42,847:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:42,847:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 11:48:42,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:48:42,942:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:42,957:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:43,004:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:48:43,051:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:43,051:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:43,051:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 11:48:43,161:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:43,177:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:43,240:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:43,256:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:44,050:INFO:Preparing preprocessing pipeline...
2024-01-18 11:48:44,050:INFO:Set up simple imputation.
2024-01-18 11:48:44,065:INFO:Set up column name cleaning.
2024-01-18 11:48:44,204:INFO:Finished creating preprocessing pipeline.
2024-01-18 11:48:44,215:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CryoSleep', 'Age', 'VIP',
                                             'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck',
                                             'HomePlanet_Earth',
                                             'HomePlanet_Europa',
                                             'HomePlanet_Mars',
                                             'Destination_55 Cancri e',
                                             'Destination_PSO J318.5-22',
                                             'Destination_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 11:48:44,215:INFO:Creating final display dataframe.
2024-01-18 11:48:44,312:INFO:Setup _display_container:                     Description             Value
0                    Session id              4420
1                        Target     Transported_y
2                   Target type            Binary
3           Original data shape        (8693, 16)
4        Transformed data shape        (8693, 16)
5   Transformed train set shape        (6085, 16)
6    Transformed test set shape        (2608, 16)
7              Numeric features                14
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3fb8
2024-01-18 11:48:44,432:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:44,432:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:44,563:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:44,563:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:44,563:INFO:setup() successfully completed in 1.94s...............
2024-01-18 11:48:58,998:INFO:PyCaret ClassificationExperiment
2024-01-18 11:48:58,998:INFO:Logging name: clf-default-name
2024-01-18 11:48:58,998:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:48:58,998:INFO:version 3.2.0
2024-01-18 11:48:58,998:INFO:Initializing setup()
2024-01-18 11:48:58,998:INFO:self.USI: 70aa
2024-01-18 11:48:58,998:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:48:58,998:INFO:Checking environment
2024-01-18 11:48:58,998:INFO:python_version: 3.11.5
2024-01-18 11:48:58,998:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:48:58,998:INFO:machine: AMD64
2024-01-18 11:48:58,998:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:48:58,998:INFO:Memory: svmem(total=8361132032, available=1835388928, percent=78.0, used=6525743104, free=1835388928)
2024-01-18 11:48:58,998:INFO:Physical Core: 2
2024-01-18 11:48:58,998:INFO:Logical Core: 4
2024-01-18 11:48:58,998:INFO:Checking libraries
2024-01-18 11:48:58,998:INFO:System:
2024-01-18 11:48:58,998:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:48:58,998:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:48:58,998:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:48:58,998:INFO:PyCaret required dependencies:
2024-01-18 11:48:58,998:INFO:                 pip: 23.2.1
2024-01-18 11:48:58,998:INFO:          setuptools: 68.0.0
2024-01-18 11:48:58,998:INFO:             pycaret: 3.2.0
2024-01-18 11:48:58,998:INFO:             IPython: 8.15.0
2024-01-18 11:48:58,998:INFO:          ipywidgets: 8.0.4
2024-01-18 11:48:58,998:INFO:                tqdm: 4.65.0
2024-01-18 11:48:58,998:INFO:               numpy: 1.24.3
2024-01-18 11:48:58,998:INFO:              pandas: 1.5.3
2024-01-18 11:48:58,998:INFO:              jinja2: 3.1.2
2024-01-18 11:48:58,998:INFO:               scipy: 1.10.1
2024-01-18 11:48:58,998:INFO:              joblib: 1.2.0
2024-01-18 11:48:58,998:INFO:             sklearn: 1.2.2
2024-01-18 11:48:58,998:INFO:                pyod: 1.1.2
2024-01-18 11:48:58,998:INFO:            imblearn: 0.10.1
2024-01-18 11:48:58,998:INFO:   category_encoders: 2.6.3
2024-01-18 11:48:58,998:INFO:            lightgbm: 4.2.0
2024-01-18 11:48:58,998:INFO:               numba: 0.57.1
2024-01-18 11:48:58,998:INFO:            requests: 2.31.0
2024-01-18 11:48:58,998:INFO:          matplotlib: 3.6.0
2024-01-18 11:48:58,998:INFO:          scikitplot: 0.3.7
2024-01-18 11:48:58,998:INFO:         yellowbrick: 1.5
2024-01-18 11:48:58,998:INFO:              plotly: 5.9.0
2024-01-18 11:48:58,998:INFO:    plotly-resampler: Not installed
2024-01-18 11:48:58,998:INFO:             kaleido: 0.2.1
2024-01-18 11:48:58,998:INFO:           schemdraw: 0.15
2024-01-18 11:48:58,998:INFO:         statsmodels: 0.14.0
2024-01-18 11:48:58,998:INFO:              sktime: 0.21.1
2024-01-18 11:48:58,998:INFO:               tbats: 1.1.3
2024-01-18 11:48:58,998:INFO:            pmdarima: 2.0.4
2024-01-18 11:48:58,998:INFO:              psutil: 5.9.0
2024-01-18 11:48:58,998:INFO:          markupsafe: 2.1.1
2024-01-18 11:48:58,998:INFO:             pickle5: Not installed
2024-01-18 11:48:58,998:INFO:         cloudpickle: 2.2.1
2024-01-18 11:48:58,998:INFO:         deprecation: 2.1.0
2024-01-18 11:48:58,998:INFO:              xxhash: 2.0.2
2024-01-18 11:48:58,998:INFO:           wurlitzer: Not installed
2024-01-18 11:48:58,998:INFO:PyCaret optional dependencies:
2024-01-18 11:48:58,998:INFO:                shap: Not installed
2024-01-18 11:48:58,998:INFO:           interpret: Not installed
2024-01-18 11:48:58,998:INFO:                umap: Not installed
2024-01-18 11:48:58,998:INFO:     ydata_profiling: Not installed
2024-01-18 11:48:58,998:INFO:  explainerdashboard: Not installed
2024-01-18 11:48:58,998:INFO:             autoviz: Not installed
2024-01-18 11:48:58,998:INFO:           fairlearn: Not installed
2024-01-18 11:48:58,998:INFO:          deepchecks: Not installed
2024-01-18 11:48:58,998:INFO:             xgboost: 2.0.3
2024-01-18 11:48:58,998:INFO:            catboost: 1.2.2
2024-01-18 11:48:58,998:INFO:              kmodes: Not installed
2024-01-18 11:48:58,998:INFO:             mlxtend: Not installed
2024-01-18 11:48:58,998:INFO:       statsforecast: Not installed
2024-01-18 11:48:58,998:INFO:        tune_sklearn: Not installed
2024-01-18 11:48:58,998:INFO:                 ray: Not installed
2024-01-18 11:48:58,998:INFO:            hyperopt: Not installed
2024-01-18 11:48:58,998:INFO:              optuna: 3.5.0
2024-01-18 11:48:58,998:INFO:               skopt: Not installed
2024-01-18 11:48:58,998:INFO:              mlflow: Not installed
2024-01-18 11:48:58,998:INFO:              gradio: Not installed
2024-01-18 11:48:58,998:INFO:             fastapi: Not installed
2024-01-18 11:48:58,998:INFO:             uvicorn: Not installed
2024-01-18 11:48:58,998:INFO:              m2cgen: Not installed
2024-01-18 11:48:58,998:INFO:           evidently: Not installed
2024-01-18 11:48:58,998:INFO:               fugue: Not installed
2024-01-18 11:48:58,998:INFO:           streamlit: Not installed
2024-01-18 11:48:58,998:INFO:             prophet: Not installed
2024-01-18 11:48:58,998:INFO:None
2024-01-18 11:48:58,998:INFO:Set up data.
2024-01-18 11:48:59,017:INFO:Set up folding strategy.
2024-01-18 11:48:59,017:INFO:Set up train/test split.
2024-01-18 11:48:59,023:INFO:Set up index.
2024-01-18 11:48:59,023:INFO:Assigning column types.
2024-01-18 11:48:59,027:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 11:48:59,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:48:59,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:48:59,146:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:59,146:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:59,192:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:48:59,192:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:48:59,208:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:59,224:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:59,224:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 11:48:59,271:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:48:59,318:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:59,318:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:59,381:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:48:59,428:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:59,428:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:59,428:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 11:48:59,506:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:59,520:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:59,647:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:59,695:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:48:59,695:INFO:Preparing preprocessing pipeline...
2024-01-18 11:48:59,695:INFO:Set up simple imputation.
2024-01-18 11:48:59,695:INFO:Set up column name cleaning.
2024-01-18 11:48:59,757:INFO:Finished creating preprocessing pipeline.
2024-01-18 11:48:59,757:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CryoSleep', 'Age', 'VIP',
                                             'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck',
                                             'HomePlanet_Earth',
                                             'HomePlanet_Europa',
                                             'HomePlanet_Mars',
                                             'Destination_55 Cancri e',
                                             'Destination_PSO J318.5-22',
                                             'Destination_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 11:48:59,757:INFO:Creating final display dataframe.
2024-01-18 11:48:59,878:INFO:Setup _display_container:                     Description             Value
0                    Session id              8045
1                        Target     Transported_y
2                   Target type            Binary
3           Original data shape        (8693, 16)
4        Transformed data shape        (8693, 16)
5   Transformed train set shape        (6085, 16)
6    Transformed test set shape        (2608, 16)
7              Numeric features                14
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              70aa
2024-01-18 11:48:59,986:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:48:59,996:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:00,145:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:49:00,145:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:00,145:INFO:setup() successfully completed in 1.64s...............
2024-01-18 11:49:00,174:INFO:PyCaret ClassificationExperiment
2024-01-18 11:49:00,174:INFO:Logging name: clf-default-name
2024-01-18 11:49:00,174:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:49:00,174:INFO:version 3.2.0
2024-01-18 11:49:00,174:INFO:Initializing setup()
2024-01-18 11:49:00,174:INFO:self.USI: d2bc
2024-01-18 11:49:00,174:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:49:00,174:INFO:Checking environment
2024-01-18 11:49:00,174:INFO:python_version: 3.11.5
2024-01-18 11:49:00,174:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:49:00,174:INFO:machine: AMD64
2024-01-18 11:49:00,174:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:49:00,174:INFO:Memory: svmem(total=8361132032, available=1810657280, percent=78.3, used=6550474752, free=1810657280)
2024-01-18 11:49:00,174:INFO:Physical Core: 2
2024-01-18 11:49:00,174:INFO:Logical Core: 4
2024-01-18 11:49:00,174:INFO:Checking libraries
2024-01-18 11:49:00,174:INFO:System:
2024-01-18 11:49:00,174:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:49:00,174:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:49:00,174:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:49:00,174:INFO:PyCaret required dependencies:
2024-01-18 11:49:00,174:INFO:                 pip: 23.2.1
2024-01-18 11:49:00,174:INFO:          setuptools: 68.0.0
2024-01-18 11:49:00,174:INFO:             pycaret: 3.2.0
2024-01-18 11:49:00,174:INFO:             IPython: 8.15.0
2024-01-18 11:49:00,174:INFO:          ipywidgets: 8.0.4
2024-01-18 11:49:00,174:INFO:                tqdm: 4.65.0
2024-01-18 11:49:00,174:INFO:               numpy: 1.24.3
2024-01-18 11:49:00,174:INFO:              pandas: 1.5.3
2024-01-18 11:49:00,174:INFO:              jinja2: 3.1.2
2024-01-18 11:49:00,174:INFO:               scipy: 1.10.1
2024-01-18 11:49:00,174:INFO:              joblib: 1.2.0
2024-01-18 11:49:00,174:INFO:             sklearn: 1.2.2
2024-01-18 11:49:00,174:INFO:                pyod: 1.1.2
2024-01-18 11:49:00,174:INFO:            imblearn: 0.10.1
2024-01-18 11:49:00,174:INFO:   category_encoders: 2.6.3
2024-01-18 11:49:00,174:INFO:            lightgbm: 4.2.0
2024-01-18 11:49:00,174:INFO:               numba: 0.57.1
2024-01-18 11:49:00,174:INFO:            requests: 2.31.0
2024-01-18 11:49:00,174:INFO:          matplotlib: 3.6.0
2024-01-18 11:49:00,174:INFO:          scikitplot: 0.3.7
2024-01-18 11:49:00,174:INFO:         yellowbrick: 1.5
2024-01-18 11:49:00,174:INFO:              plotly: 5.9.0
2024-01-18 11:49:00,174:INFO:    plotly-resampler: Not installed
2024-01-18 11:49:00,174:INFO:             kaleido: 0.2.1
2024-01-18 11:49:00,174:INFO:           schemdraw: 0.15
2024-01-18 11:49:00,174:INFO:         statsmodels: 0.14.0
2024-01-18 11:49:00,174:INFO:              sktime: 0.21.1
2024-01-18 11:49:00,174:INFO:               tbats: 1.1.3
2024-01-18 11:49:00,174:INFO:            pmdarima: 2.0.4
2024-01-18 11:49:00,174:INFO:              psutil: 5.9.0
2024-01-18 11:49:00,174:INFO:          markupsafe: 2.1.1
2024-01-18 11:49:00,174:INFO:             pickle5: Not installed
2024-01-18 11:49:00,174:INFO:         cloudpickle: 2.2.1
2024-01-18 11:49:00,174:INFO:         deprecation: 2.1.0
2024-01-18 11:49:00,174:INFO:              xxhash: 2.0.2
2024-01-18 11:49:00,174:INFO:           wurlitzer: Not installed
2024-01-18 11:49:00,174:INFO:PyCaret optional dependencies:
2024-01-18 11:49:00,174:INFO:                shap: Not installed
2024-01-18 11:49:00,174:INFO:           interpret: Not installed
2024-01-18 11:49:00,174:INFO:                umap: Not installed
2024-01-18 11:49:00,174:INFO:     ydata_profiling: Not installed
2024-01-18 11:49:00,174:INFO:  explainerdashboard: Not installed
2024-01-18 11:49:00,174:INFO:             autoviz: Not installed
2024-01-18 11:49:00,174:INFO:           fairlearn: Not installed
2024-01-18 11:49:00,174:INFO:          deepchecks: Not installed
2024-01-18 11:49:00,174:INFO:             xgboost: 2.0.3
2024-01-18 11:49:00,174:INFO:            catboost: 1.2.2
2024-01-18 11:49:00,174:INFO:              kmodes: Not installed
2024-01-18 11:49:00,174:INFO:             mlxtend: Not installed
2024-01-18 11:49:00,174:INFO:       statsforecast: Not installed
2024-01-18 11:49:00,174:INFO:        tune_sklearn: Not installed
2024-01-18 11:49:00,174:INFO:                 ray: Not installed
2024-01-18 11:49:00,174:INFO:            hyperopt: Not installed
2024-01-18 11:49:00,174:INFO:              optuna: 3.5.0
2024-01-18 11:49:00,174:INFO:               skopt: Not installed
2024-01-18 11:49:00,174:INFO:              mlflow: Not installed
2024-01-18 11:49:00,174:INFO:              gradio: Not installed
2024-01-18 11:49:00,174:INFO:             fastapi: Not installed
2024-01-18 11:49:00,174:INFO:             uvicorn: Not installed
2024-01-18 11:49:00,174:INFO:              m2cgen: Not installed
2024-01-18 11:49:00,174:INFO:           evidently: Not installed
2024-01-18 11:49:00,174:INFO:               fugue: Not installed
2024-01-18 11:49:00,174:INFO:           streamlit: Not installed
2024-01-18 11:49:00,174:INFO:             prophet: Not installed
2024-01-18 11:49:00,174:INFO:None
2024-01-18 11:49:00,174:INFO:Set up data.
2024-01-18 11:49:00,188:INFO:Set up folding strategy.
2024-01-18 11:49:00,188:INFO:Set up train/test split.
2024-01-18 11:49:00,194:INFO:Set up index.
2024-01-18 11:49:00,194:INFO:Assigning column types.
2024-01-18 11:49:00,198:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 11:49:00,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:49:00,279:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:49:00,326:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:49:00,326:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:00,412:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:49:00,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:49:00,462:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:49:00,477:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:00,478:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 11:49:00,553:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:49:00,609:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:49:00,613:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:00,662:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:49:00,693:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:49:00,693:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:00,693:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 11:49:00,787:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:49:00,787:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:00,943:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:49:00,949:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:00,949:INFO:Preparing preprocessing pipeline...
2024-01-18 11:49:00,949:INFO:Set up simple imputation.
2024-01-18 11:49:00,949:INFO:Set up column name cleaning.
2024-01-18 11:49:01,006:INFO:Finished creating preprocessing pipeline.
2024-01-18 11:49:01,017:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CryoSleep', 'Age', 'VIP',
                                             'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck',
                                             'HomePlanet_Earth',
                                             'HomePlanet_Europa',
                                             'HomePlanet_Mars',
                                             'Destination_55 Cancri e',
                                             'Destination_PSO J318.5-22',
                                             'Destination_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 11:49:01,017:INFO:Creating final display dataframe.
2024-01-18 11:49:01,143:INFO:Setup _display_container:                     Description             Value
0                    Session id              8800
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Numeric features                14
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d2bc
2024-01-18 11:49:01,304:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:49:01,304:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:01,396:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:49:01,411:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:49:01,411:INFO:setup() successfully completed in 1.25s...............
2024-01-18 11:49:01,430:INFO:Initializing compare_models()
2024-01-18 11:49:01,430:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-18 11:49:01,431:INFO:Checking exceptions
2024-01-18 11:49:01,433:INFO:Preparing display monitor
2024-01-18 11:49:01,487:INFO:Initializing Logistic Regression
2024-01-18 11:49:01,488:INFO:Total runtime is 1.6657511393229165e-05 minutes
2024-01-18 11:49:01,493:INFO:SubProcess create_model() called ==================================
2024-01-18 11:49:01,493:INFO:Initializing create_model()
2024-01-18 11:49:01,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:49:01,494:INFO:Checking exceptions
2024-01-18 11:49:01,494:INFO:Importing libraries
2024-01-18 11:49:01,494:INFO:Copying training dataset
2024-01-18 11:49:01,506:INFO:Defining folds
2024-01-18 11:49:01,506:INFO:Declaring metric variables
2024-01-18 11:49:01,513:INFO:Importing untrained model
2024-01-18 11:49:01,519:INFO:Logistic Regression Imported successfully
2024-01-18 11:49:01,530:INFO:Starting cross validation
2024-01-18 11:49:01,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:17,899:INFO:Calculating mean and std
2024-01-18 11:50:17,899:INFO:Creating metrics dataframe
2024-01-18 11:50:17,899:INFO:Uploading results into container
2024-01-18 11:50:17,899:INFO:Uploading model into container now
2024-01-18 11:50:17,899:INFO:_master_model_container: 1
2024-01-18 11:50:17,899:INFO:_display_container: 2
2024-01-18 11:50:17,899:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8800, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-18 11:50:17,899:INFO:create_model() successfully completed......................................
2024-01-18 11:50:18,221:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:18,221:INFO:Creating metrics dataframe
2024-01-18 11:50:18,230:INFO:Initializing K Neighbors Classifier
2024-01-18 11:50:18,230:INFO:Total runtime is 1.2790523529052733 minutes
2024-01-18 11:50:18,240:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:18,240:INFO:Initializing create_model()
2024-01-18 11:50:18,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:18,240:INFO:Checking exceptions
2024-01-18 11:50:18,241:INFO:Importing libraries
2024-01-18 11:50:18,241:INFO:Copying training dataset
2024-01-18 11:50:18,249:INFO:Defining folds
2024-01-18 11:50:18,249:INFO:Declaring metric variables
2024-01-18 11:50:18,255:INFO:Importing untrained model
2024-01-18 11:50:18,261:INFO:K Neighbors Classifier Imported successfully
2024-01-18 11:50:18,271:INFO:Starting cross validation
2024-01-18 11:50:18,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:19,083:INFO:Calculating mean and std
2024-01-18 11:50:19,083:INFO:Creating metrics dataframe
2024-01-18 11:50:19,092:INFO:Uploading results into container
2024-01-18 11:50:19,094:INFO:Uploading model into container now
2024-01-18 11:50:19,094:INFO:_master_model_container: 2
2024-01-18 11:50:19,095:INFO:_display_container: 2
2024-01-18 11:50:19,096:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-18 11:50:19,097:INFO:create_model() successfully completed......................................
2024-01-18 11:50:19,309:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:19,309:INFO:Creating metrics dataframe
2024-01-18 11:50:19,325:INFO:Initializing Naive Bayes
2024-01-18 11:50:19,325:INFO:Total runtime is 1.2972928484280903 minutes
2024-01-18 11:50:19,325:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:19,325:INFO:Initializing create_model()
2024-01-18 11:50:19,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:19,325:INFO:Checking exceptions
2024-01-18 11:50:19,325:INFO:Importing libraries
2024-01-18 11:50:19,325:INFO:Copying training dataset
2024-01-18 11:50:19,350:INFO:Defining folds
2024-01-18 11:50:19,350:INFO:Declaring metric variables
2024-01-18 11:50:19,357:INFO:Importing untrained model
2024-01-18 11:50:19,366:INFO:Naive Bayes Imported successfully
2024-01-18 11:50:19,380:INFO:Starting cross validation
2024-01-18 11:50:19,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:19,571:INFO:Calculating mean and std
2024-01-18 11:50:19,571:INFO:Creating metrics dataframe
2024-01-18 11:50:19,586:INFO:Uploading results into container
2024-01-18 11:50:19,586:INFO:Uploading model into container now
2024-01-18 11:50:19,589:INFO:_master_model_container: 3
2024-01-18 11:50:19,589:INFO:_display_container: 2
2024-01-18 11:50:19,589:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-18 11:50:19,589:INFO:create_model() successfully completed......................................
2024-01-18 11:50:19,840:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:19,840:INFO:Creating metrics dataframe
2024-01-18 11:50:19,840:INFO:Initializing Decision Tree Classifier
2024-01-18 11:50:19,840:INFO:Total runtime is 1.3058791716893514 minutes
2024-01-18 11:50:19,840:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:19,840:INFO:Initializing create_model()
2024-01-18 11:50:19,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:19,856:INFO:Checking exceptions
2024-01-18 11:50:19,856:INFO:Importing libraries
2024-01-18 11:50:19,856:INFO:Copying training dataset
2024-01-18 11:50:19,861:INFO:Defining folds
2024-01-18 11:50:19,861:INFO:Declaring metric variables
2024-01-18 11:50:19,866:INFO:Importing untrained model
2024-01-18 11:50:19,870:INFO:Decision Tree Classifier Imported successfully
2024-01-18 11:50:19,883:INFO:Starting cross validation
2024-01-18 11:50:19,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:20,132:INFO:Calculating mean and std
2024-01-18 11:50:20,132:INFO:Creating metrics dataframe
2024-01-18 11:50:20,137:INFO:Uploading results into container
2024-01-18 11:50:20,137:INFO:Uploading model into container now
2024-01-18 11:50:20,137:INFO:_master_model_container: 4
2024-01-18 11:50:20,137:INFO:_display_container: 2
2024-01-18 11:50:20,137:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8800, splitter='best')
2024-01-18 11:50:20,137:INFO:create_model() successfully completed......................................
2024-01-18 11:50:20,422:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:20,422:INFO:Creating metrics dataframe
2024-01-18 11:50:20,437:INFO:Initializing SVM - Linear Kernel
2024-01-18 11:50:20,437:INFO:Total runtime is 1.3158326148986816 minutes
2024-01-18 11:50:20,452:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:20,453:INFO:Initializing create_model()
2024-01-18 11:50:20,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:20,453:INFO:Checking exceptions
2024-01-18 11:50:20,453:INFO:Importing libraries
2024-01-18 11:50:20,453:INFO:Copying training dataset
2024-01-18 11:50:20,463:INFO:Defining folds
2024-01-18 11:50:20,463:INFO:Declaring metric variables
2024-01-18 11:50:20,469:INFO:Importing untrained model
2024-01-18 11:50:20,479:INFO:SVM - Linear Kernel Imported successfully
2024-01-18 11:50:20,490:INFO:Starting cross validation
2024-01-18 11:50:20,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:20,739:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:50:20,739:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:50:20,896:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:50:20,896:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:50:20,896:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:50:20,896:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:50:20,976:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:50:20,976:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 11:50:20,990:INFO:Calculating mean and std
2024-01-18 11:50:20,990:INFO:Creating metrics dataframe
2024-01-18 11:50:21,006:INFO:Uploading results into container
2024-01-18 11:50:21,006:INFO:Uploading model into container now
2024-01-18 11:50:21,006:INFO:_master_model_container: 5
2024-01-18 11:50:21,006:INFO:_display_container: 2
2024-01-18 11:50:21,006:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8800, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-18 11:50:21,006:INFO:create_model() successfully completed......................................
2024-01-18 11:50:21,273:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:21,273:INFO:Creating metrics dataframe
2024-01-18 11:50:21,288:INFO:Initializing Ridge Classifier
2024-01-18 11:50:21,289:INFO:Total runtime is 1.330032765865326 minutes
2024-01-18 11:50:21,294:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:21,295:INFO:Initializing create_model()
2024-01-18 11:50:21,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:21,296:INFO:Checking exceptions
2024-01-18 11:50:21,296:INFO:Importing libraries
2024-01-18 11:50:21,296:INFO:Copying training dataset
2024-01-18 11:50:21,306:INFO:Defining folds
2024-01-18 11:50:21,306:INFO:Declaring metric variables
2024-01-18 11:50:21,312:INFO:Importing untrained model
2024-01-18 11:50:21,318:INFO:Ridge Classifier Imported successfully
2024-01-18 11:50:21,329:INFO:Starting cross validation
2024-01-18 11:50:21,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:22,445:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,445:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,445:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,445:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,548:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,548:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,564:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,564:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,595:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,602:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 11:50:22,614:INFO:Calculating mean and std
2024-01-18 11:50:22,614:INFO:Creating metrics dataframe
2024-01-18 11:50:22,614:INFO:Uploading results into container
2024-01-18 11:50:22,614:INFO:Uploading model into container now
2024-01-18 11:50:22,614:INFO:_master_model_container: 6
2024-01-18 11:50:22,614:INFO:_display_container: 2
2024-01-18 11:50:22,614:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8800, solver='auto',
                tol=0.0001)
2024-01-18 11:50:22,621:INFO:create_model() successfully completed......................................
2024-01-18 11:50:22,827:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:23,109:INFO:Creating metrics dataframe
2024-01-18 11:50:23,153:INFO:Initializing Random Forest Classifier
2024-01-18 11:50:23,153:INFO:Total runtime is 1.3610970457394918 minutes
2024-01-18 11:50:23,162:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:23,162:INFO:Initializing create_model()
2024-01-18 11:50:23,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:23,162:INFO:Checking exceptions
2024-01-18 11:50:23,162:INFO:Importing libraries
2024-01-18 11:50:23,163:INFO:Copying training dataset
2024-01-18 11:50:23,169:INFO:Defining folds
2024-01-18 11:50:23,170:INFO:Declaring metric variables
2024-01-18 11:50:23,174:INFO:Importing untrained model
2024-01-18 11:50:23,181:INFO:Random Forest Classifier Imported successfully
2024-01-18 11:50:23,194:INFO:Starting cross validation
2024-01-18 11:50:23,195:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:26,189:INFO:Calculating mean and std
2024-01-18 11:50:26,189:INFO:Creating metrics dataframe
2024-01-18 11:50:26,204:INFO:Uploading results into container
2024-01-18 11:50:26,207:INFO:Uploading model into container now
2024-01-18 11:50:26,207:INFO:_master_model_container: 7
2024-01-18 11:50:26,207:INFO:_display_container: 2
2024-01-18 11:50:26,209:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8800, verbose=0, warm_start=False)
2024-01-18 11:50:26,209:INFO:create_model() successfully completed......................................
2024-01-18 11:50:26,457:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:26,457:INFO:Creating metrics dataframe
2024-01-18 11:50:26,472:INFO:Initializing Quadratic Discriminant Analysis
2024-01-18 11:50:26,472:INFO:Total runtime is 1.4164107759793598 minutes
2024-01-18 11:50:26,485:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:26,485:INFO:Initializing create_model()
2024-01-18 11:50:26,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:26,485:INFO:Checking exceptions
2024-01-18 11:50:26,485:INFO:Importing libraries
2024-01-18 11:50:26,485:INFO:Copying training dataset
2024-01-18 11:50:26,494:INFO:Defining folds
2024-01-18 11:50:26,494:INFO:Declaring metric variables
2024-01-18 11:50:26,501:INFO:Importing untrained model
2024-01-18 11:50:26,507:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-18 11:50:26,516:INFO:Starting cross validation
2024-01-18 11:50:26,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:27,656:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:27,656:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:27,656:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:27,656:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:27,938:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:27,938:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:27,938:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:27,986:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:27,986:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:27,986:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 11:50:28,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-18 11:50:28,285:INFO:Calculating mean and std
2024-01-18 11:50:28,285:INFO:Creating metrics dataframe
2024-01-18 11:50:28,300:INFO:Uploading results into container
2024-01-18 11:50:28,300:INFO:Uploading model into container now
2024-01-18 11:50:28,300:INFO:_master_model_container: 8
2024-01-18 11:50:28,300:INFO:_display_container: 2
2024-01-18 11:50:28,300:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-18 11:50:28,300:INFO:create_model() successfully completed......................................
2024-01-18 11:50:28,541:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:28,541:INFO:Creating metrics dataframe
2024-01-18 11:50:28,556:INFO:Initializing Ada Boost Classifier
2024-01-18 11:50:28,556:INFO:Total runtime is 1.4511546730995177 minutes
2024-01-18 11:50:28,568:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:28,568:INFO:Initializing create_model()
2024-01-18 11:50:28,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:28,568:INFO:Checking exceptions
2024-01-18 11:50:28,568:INFO:Importing libraries
2024-01-18 11:50:28,568:INFO:Copying training dataset
2024-01-18 11:50:28,575:INFO:Defining folds
2024-01-18 11:50:28,575:INFO:Declaring metric variables
2024-01-18 11:50:28,580:INFO:Importing untrained model
2024-01-18 11:50:28,584:INFO:Ada Boost Classifier Imported successfully
2024-01-18 11:50:28,597:INFO:Starting cross validation
2024-01-18 11:50:28,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:30,161:INFO:Calculating mean and std
2024-01-18 11:50:30,161:INFO:Creating metrics dataframe
2024-01-18 11:50:30,161:INFO:Uploading results into container
2024-01-18 11:50:30,161:INFO:Uploading model into container now
2024-01-18 11:50:30,161:INFO:_master_model_container: 9
2024-01-18 11:50:30,161:INFO:_display_container: 2
2024-01-18 11:50:30,161:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8800)
2024-01-18 11:50:30,161:INFO:create_model() successfully completed......................................
2024-01-18 11:50:30,392:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:30,392:INFO:Creating metrics dataframe
2024-01-18 11:50:30,423:INFO:Initializing Gradient Boosting Classifier
2024-01-18 11:50:30,423:INFO:Total runtime is 1.482262337207794 minutes
2024-01-18 11:50:30,423:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:30,423:INFO:Initializing create_model()
2024-01-18 11:50:30,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:30,423:INFO:Checking exceptions
2024-01-18 11:50:30,423:INFO:Importing libraries
2024-01-18 11:50:30,423:INFO:Copying training dataset
2024-01-18 11:50:30,447:INFO:Defining folds
2024-01-18 11:50:30,447:INFO:Declaring metric variables
2024-01-18 11:50:30,452:INFO:Importing untrained model
2024-01-18 11:50:30,456:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 11:50:30,467:INFO:Starting cross validation
2024-01-18 11:50:30,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:33,355:INFO:Calculating mean and std
2024-01-18 11:50:33,355:INFO:Creating metrics dataframe
2024-01-18 11:50:33,375:INFO:Uploading results into container
2024-01-18 11:50:33,376:INFO:Uploading model into container now
2024-01-18 11:50:33,378:INFO:_master_model_container: 10
2024-01-18 11:50:33,379:INFO:_display_container: 2
2024-01-18 11:50:33,381:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 11:50:33,381:INFO:create_model() successfully completed......................................
2024-01-18 11:50:33,592:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:33,592:INFO:Creating metrics dataframe
2024-01-18 11:50:33,624:INFO:Initializing Linear Discriminant Analysis
2024-01-18 11:50:33,624:INFO:Total runtime is 1.535622195402781 minutes
2024-01-18 11:50:33,642:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:33,642:INFO:Initializing create_model()
2024-01-18 11:50:33,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:33,642:INFO:Checking exceptions
2024-01-18 11:50:33,643:INFO:Importing libraries
2024-01-18 11:50:33,643:INFO:Copying training dataset
2024-01-18 11:50:33,650:INFO:Defining folds
2024-01-18 11:50:33,650:INFO:Declaring metric variables
2024-01-18 11:50:33,654:INFO:Importing untrained model
2024-01-18 11:50:33,660:INFO:Linear Discriminant Analysis Imported successfully
2024-01-18 11:50:33,672:INFO:Starting cross validation
2024-01-18 11:50:33,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:34,656:INFO:Calculating mean and std
2024-01-18 11:50:34,656:INFO:Creating metrics dataframe
2024-01-18 11:50:34,656:INFO:Uploading results into container
2024-01-18 11:50:34,656:INFO:Uploading model into container now
2024-01-18 11:50:34,656:INFO:_master_model_container: 11
2024-01-18 11:50:34,656:INFO:_display_container: 2
2024-01-18 11:50:34,656:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-18 11:50:34,669:INFO:create_model() successfully completed......................................
2024-01-18 11:50:34,875:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:34,875:INFO:Creating metrics dataframe
2024-01-18 11:50:34,892:INFO:Initializing Extra Trees Classifier
2024-01-18 11:50:34,892:INFO:Total runtime is 1.556744400660197 minutes
2024-01-18 11:50:34,898:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:34,898:INFO:Initializing create_model()
2024-01-18 11:50:34,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:34,899:INFO:Checking exceptions
2024-01-18 11:50:34,899:INFO:Importing libraries
2024-01-18 11:50:34,899:INFO:Copying training dataset
2024-01-18 11:50:34,908:INFO:Defining folds
2024-01-18 11:50:34,908:INFO:Declaring metric variables
2024-01-18 11:50:34,913:INFO:Importing untrained model
2024-01-18 11:50:34,923:INFO:Extra Trees Classifier Imported successfully
2024-01-18 11:50:34,932:INFO:Starting cross validation
2024-01-18 11:50:34,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:38,933:INFO:Calculating mean and std
2024-01-18 11:50:38,937:INFO:Creating metrics dataframe
2024-01-18 11:50:38,942:INFO:Uploading results into container
2024-01-18 11:50:38,942:INFO:Uploading model into container now
2024-01-18 11:50:38,942:INFO:_master_model_container: 12
2024-01-18 11:50:38,942:INFO:_display_container: 2
2024-01-18 11:50:38,942:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8800, verbose=0, warm_start=False)
2024-01-18 11:50:38,942:INFO:create_model() successfully completed......................................
2024-01-18 11:50:39,184:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:39,184:INFO:Creating metrics dataframe
2024-01-18 11:50:39,218:INFO:Initializing Extreme Gradient Boosting
2024-01-18 11:50:39,218:INFO:Total runtime is 1.6288518190383912 minutes
2024-01-18 11:50:39,224:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:39,224:INFO:Initializing create_model()
2024-01-18 11:50:39,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:39,224:INFO:Checking exceptions
2024-01-18 11:50:39,225:INFO:Importing libraries
2024-01-18 11:50:39,225:INFO:Copying training dataset
2024-01-18 11:50:39,241:INFO:Defining folds
2024-01-18 11:50:39,242:INFO:Declaring metric variables
2024-01-18 11:50:39,247:INFO:Importing untrained model
2024-01-18 11:50:39,256:INFO:Extreme Gradient Boosting Imported successfully
2024-01-18 11:50:39,261:INFO:Starting cross validation
2024-01-18 11:50:39,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:43,489:INFO:Calculating mean and std
2024-01-18 11:50:43,489:INFO:Creating metrics dataframe
2024-01-18 11:50:43,506:INFO:Uploading results into container
2024-01-18 11:50:43,507:INFO:Uploading model into container now
2024-01-18 11:50:43,508:INFO:_master_model_container: 13
2024-01-18 11:50:43,508:INFO:_display_container: 2
2024-01-18 11:50:43,510:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-18 11:50:43,510:INFO:create_model() successfully completed......................................
2024-01-18 11:50:43,756:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:43,772:INFO:Creating metrics dataframe
2024-01-18 11:50:43,787:INFO:Initializing Light Gradient Boosting Machine
2024-01-18 11:50:43,787:INFO:Total runtime is 1.705001739660899 minutes
2024-01-18 11:50:43,787:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:43,802:INFO:Initializing create_model()
2024-01-18 11:50:43,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:43,802:INFO:Checking exceptions
2024-01-18 11:50:43,802:INFO:Importing libraries
2024-01-18 11:50:43,802:INFO:Copying training dataset
2024-01-18 11:50:43,808:INFO:Defining folds
2024-01-18 11:50:43,808:INFO:Declaring metric variables
2024-01-18 11:50:43,813:INFO:Importing untrained model
2024-01-18 11:50:43,822:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 11:50:43,832:INFO:Starting cross validation
2024-01-18 11:50:43,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:50:45,748:INFO:Calculating mean and std
2024-01-18 11:50:45,748:INFO:Creating metrics dataframe
2024-01-18 11:50:45,759:INFO:Uploading results into container
2024-01-18 11:50:45,760:INFO:Uploading model into container now
2024-01-18 11:50:45,762:INFO:_master_model_container: 14
2024-01-18 11:50:45,762:INFO:_display_container: 2
2024-01-18 11:50:45,762:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8800, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 11:50:45,762:INFO:create_model() successfully completed......................................
2024-01-18 11:50:45,974:INFO:SubProcess create_model() end ==================================
2024-01-18 11:50:45,974:INFO:Creating metrics dataframe
2024-01-18 11:50:45,990:INFO:Initializing CatBoost Classifier
2024-01-18 11:50:45,990:INFO:Total runtime is 1.7417092442512514 minutes
2024-01-18 11:50:46,011:INFO:SubProcess create_model() called ==================================
2024-01-18 11:50:46,011:INFO:Initializing create_model()
2024-01-18 11:50:46,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:50:46,012:INFO:Checking exceptions
2024-01-18 11:50:46,012:INFO:Importing libraries
2024-01-18 11:50:46,012:INFO:Copying training dataset
2024-01-18 11:50:46,020:INFO:Defining folds
2024-01-18 11:50:46,020:INFO:Declaring metric variables
2024-01-18 11:50:46,025:INFO:Importing untrained model
2024-01-18 11:50:46,032:INFO:CatBoost Classifier Imported successfully
2024-01-18 11:50:46,049:INFO:Starting cross validation
2024-01-18 11:50:46,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

ls = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,381:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,393:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,393:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,396:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,396:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,396:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,396:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,396:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:17,396:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Go2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,242:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,269:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,300:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,300:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,300:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,300:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,300:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:33,300:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,528:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,529:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,529:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,529:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,529:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,531:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,560:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,560:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,560:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,560:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,560:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,560:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 11:51:40,560:INFO:Calculating mean and std
2024-01-18 11:51:40,560:INFO:Creating metrics dataframe
2024-01-18 11:51:40,577:INFO:Uploading results into container
2024-01-18 11:51:40,577:INFO:Uploading model into container now
2024-01-18 11:51:40,577:INFO:_master_model_container: 15
2024-01-18 11:51:40,577:INFO:_display_container: 2
2024-01-18 11:51:40,577:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7488DBC90>
2024-01-18 11:51:40,577:INFO:create_model() successfully completed......................................
2024-01-18 11:51:40,837:INFO:SubProcess create_model() end ==================================
2024-01-18 11:51:40,837:INFO:Creating metrics dataframe
2024-01-18 11:51:40,869:INFO:Initializing Dummy Classifier
2024-01-18 11:51:40,869:INFO:Total runtime is 2.656356990337372 minutes
2024-01-18 11:51:40,884:INFO:SubProcess create_model() called ==================================
2024-01-18 11:51:40,884:INFO:Initializing create_model()
2024-01-18 11:51:40,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C74CB34A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:51:40,884:INFO:Checking exceptions
2024-01-18 11:51:40,884:INFO:Importing libraries
2024-01-18 11:51:40,884:INFO:Copying training dataset
2024-01-18 11:51:40,892:INFO:Defining folds
2024-01-18 11:51:40,892:INFO:Declaring metric variables
2024-01-18 11:51:40,898:INFO:Importing untrained model
2024-01-18 11:51:40,904:INFO:Dummy Classifier Imported successfully
2024-01-18 11:51:40,914:INFO:Starting cross validation
2024-01-18 11:51:40,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 11:51:41,081:INFO:Calculating mean and std
2024-01-18 11:51:41,082:INFO:Creating metrics dataframe
2024-01-18 11:51:41,087:INFO:Uploading results into container
2024-01-18 11:51:41,087:INFO:Uploading model into container now
2024-01-18 11:51:41,088:INFO:_master_model_container: 16
2024-01-18 11:51:41,088:INFO:_display_container: 2
2024-01-18 11:51:41,088:INFO:DummyClassifier(constant=None, random_state=8800, strategy='prior')
2024-01-18 11:51:41,088:INFO:create_model() successfully completed......................................
2024-01-18 11:51:41,320:INFO:SubProcess create_model() end ==================================
2024-01-18 11:51:41,320:INFO:Creating metrics dataframe
2024-01-18 11:51:41,365:INFO:Initializing create_model()
2024-01-18 11:51:41,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:51:41,366:INFO:Checking exceptions
2024-01-18 11:51:41,369:INFO:Importing libraries
2024-01-18 11:51:41,369:INFO:Copying training dataset
2024-01-18 11:51:41,375:INFO:Defining folds
2024-01-18 11:51:41,375:INFO:Declaring metric variables
2024-01-18 11:51:41,376:INFO:Importing untrained model
2024-01-18 11:51:41,376:INFO:Declaring custom model
2024-01-18 11:51:41,376:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 11:51:41,378:INFO:Cross validation set to False
2024-01-18 11:51:41,378:INFO:Fitting Model
2024-01-18 11:51:42,403:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 11:51:42,403:INFO:create_model() successfully completed......................................
2024-01-18 11:51:42,699:INFO:_master_model_container: 16
2024-01-18 11:51:42,699:INFO:_display_container: 2
2024-01-18 11:51:42,702:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 11:51:42,702:INFO:compare_models() successfully completed......................................
2024-01-18 11:51:43,054:INFO:Initializing finalize_model()
2024-01-18 11:51:43,054:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-18 11:51:43,054:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 11:51:43,054:INFO:Initializing create_model()
2024-01-18 11:51:43,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 11:51:43,054:INFO:Checking exceptions
2024-01-18 11:51:43,054:INFO:Importing libraries
2024-01-18 11:51:43,070:INFO:Copying training dataset
2024-01-18 11:51:43,070:INFO:Defining folds
2024-01-18 11:51:43,070:INFO:Declaring metric variables
2024-01-18 11:51:43,070:INFO:Importing untrained model
2024-01-18 11:51:43,070:INFO:Declaring custom model
2024-01-18 11:51:43,070:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 11:51:43,070:INFO:Cross validation set to False
2024-01-18 11:51:43,070:INFO:Fitting Model
2024-01-18 11:51:44,397:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CryoSleep', 'Age', 'VIP',
                                             'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck',
                                             'HomePlanet_Earth',
                                             'HomePlanet_Europa',
                                             'HomePlanet_Mars',
                                             'Destination_55 Cancri e',
                                             'Destination_PSO J318.5-22',
                                             'Destination_TRAPPIST-1e'],
                                    transformer=SimpleImputer(ad...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8800, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-01-18 11:51:44,397:INFO:create_model() successfully completed......................................
2024-01-18 11:51:44,642:INFO:_master_model_container: 16
2024-01-18 11:51:44,642:INFO:_display_container: 2
2024-01-18 11:51:44,658:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CryoSleep', 'Age', 'VIP',
                                             'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck',
                                             'HomePlanet_Earth',
                                             'HomePlanet_Europa',
                                             'HomePlanet_Mars',
                                             'Destination_55 Cancri e',
                                             'Destination_PSO J318.5-22',
                                             'Destination_TRAPPIST-1e'],
                                    transformer=SimpleImputer(ad...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8800, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-01-18 11:51:44,658:INFO:finalize_model() successfully completed......................................
2024-01-18 11:51:44,956:INFO:Initializing evaluate_model()
2024-01-18 11:51:47,677:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-18 11:51:47,706:INFO:Initializing plot_model()
2024-01-18 11:51:47,706:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 11:51:47,706:INFO:Checking exceptions
2024-01-18 11:51:47,711:INFO:Preloading libraries
2024-01-18 11:51:47,713:INFO:Copying training dataset
2024-01-18 11:51:47,713:INFO:Plot type: pipeline
2024-01-18 11:51:47,947:INFO:Visual Rendered Successfully
2024-01-18 11:51:48,194:INFO:plot_model() successfully completed......................................
2024-01-18 11:51:48,213:INFO:Initializing predict_model()
2024-01-18 11:51:48,213:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C740C754E0>)
2024-01-18 11:51:48,213:INFO:Checking exceptions
2024-01-18 11:51:48,213:INFO:Preloading libraries
2024-01-18 11:51:48,601:INFO:Initializing predict_model()
2024-01-18 11:51:48,601:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C740848790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8800, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C740C77420>)
2024-01-18 11:51:48,601:INFO:Checking exceptions
2024-01-18 11:51:48,601:INFO:Preloading libraries
2024-01-18 11:51:48,605:INFO:Set up data.
2024-01-18 11:51:48,614:INFO:Set up index.
2024-01-18 11:55:01,511:INFO:PyCaret ClassificationExperiment
2024-01-18 11:55:01,511:INFO:Logging name: clf-default-name
2024-01-18 11:55:01,511:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:55:01,511:INFO:version 3.2.0
2024-01-18 11:55:01,511:INFO:Initializing setup()
2024-01-18 11:55:01,511:INFO:self.USI: 9e66
2024-01-18 11:55:01,511:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:55:01,511:INFO:Checking environment
2024-01-18 11:55:01,512:INFO:python_version: 3.11.5
2024-01-18 11:55:01,512:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:55:01,512:INFO:machine: AMD64
2024-01-18 11:55:01,512:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:55:01,512:INFO:Memory: svmem(total=8361132032, available=1331150848, percent=84.1, used=7029981184, free=1331150848)
2024-01-18 11:55:01,512:INFO:Physical Core: 2
2024-01-18 11:55:01,512:INFO:Logical Core: 4
2024-01-18 11:55:01,512:INFO:Checking libraries
2024-01-18 11:55:01,512:INFO:System:
2024-01-18 11:55:01,512:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:55:01,513:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:55:01,513:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:55:01,513:INFO:PyCaret required dependencies:
2024-01-18 11:55:01,513:INFO:                 pip: 23.2.1
2024-01-18 11:55:01,513:INFO:          setuptools: 68.0.0
2024-01-18 11:55:01,513:INFO:             pycaret: 3.2.0
2024-01-18 11:55:01,513:INFO:             IPython: 8.15.0
2024-01-18 11:55:01,513:INFO:          ipywidgets: 8.0.4
2024-01-18 11:55:01,513:INFO:                tqdm: 4.65.0
2024-01-18 11:55:01,513:INFO:               numpy: 1.24.3
2024-01-18 11:55:01,513:INFO:              pandas: 1.5.3
2024-01-18 11:55:01,513:INFO:              jinja2: 3.1.2
2024-01-18 11:55:01,514:INFO:               scipy: 1.10.1
2024-01-18 11:55:01,514:INFO:              joblib: 1.2.0
2024-01-18 11:55:01,514:INFO:             sklearn: 1.2.2
2024-01-18 11:55:01,514:INFO:                pyod: 1.1.2
2024-01-18 11:55:01,514:INFO:            imblearn: 0.10.1
2024-01-18 11:55:01,514:INFO:   category_encoders: 2.6.3
2024-01-18 11:55:01,514:INFO:            lightgbm: 4.2.0
2024-01-18 11:55:01,514:INFO:               numba: 0.57.1
2024-01-18 11:55:01,514:INFO:            requests: 2.31.0
2024-01-18 11:55:01,514:INFO:          matplotlib: 3.6.0
2024-01-18 11:55:01,514:INFO:          scikitplot: 0.3.7
2024-01-18 11:55:01,514:INFO:         yellowbrick: 1.5
2024-01-18 11:55:01,514:INFO:              plotly: 5.9.0
2024-01-18 11:55:01,514:INFO:    plotly-resampler: Not installed
2024-01-18 11:55:01,515:INFO:             kaleido: 0.2.1
2024-01-18 11:55:01,515:INFO:           schemdraw: 0.15
2024-01-18 11:55:01,515:INFO:         statsmodels: 0.14.0
2024-01-18 11:55:01,515:INFO:              sktime: 0.21.1
2024-01-18 11:55:01,515:INFO:               tbats: 1.1.3
2024-01-18 11:55:01,515:INFO:            pmdarima: 2.0.4
2024-01-18 11:55:01,515:INFO:              psutil: 5.9.0
2024-01-18 11:55:01,515:INFO:          markupsafe: 2.1.1
2024-01-18 11:55:01,515:INFO:             pickle5: Not installed
2024-01-18 11:55:01,515:INFO:         cloudpickle: 2.2.1
2024-01-18 11:55:01,515:INFO:         deprecation: 2.1.0
2024-01-18 11:55:01,515:INFO:              xxhash: 2.0.2
2024-01-18 11:55:01,515:INFO:           wurlitzer: Not installed
2024-01-18 11:55:01,516:INFO:PyCaret optional dependencies:
2024-01-18 11:55:01,517:INFO:                shap: Not installed
2024-01-18 11:55:01,517:INFO:           interpret: Not installed
2024-01-18 11:55:01,517:INFO:                umap: Not installed
2024-01-18 11:55:01,517:INFO:     ydata_profiling: Not installed
2024-01-18 11:55:01,517:INFO:  explainerdashboard: Not installed
2024-01-18 11:55:01,517:INFO:             autoviz: Not installed
2024-01-18 11:55:01,517:INFO:           fairlearn: Not installed
2024-01-18 11:55:01,517:INFO:          deepchecks: Not installed
2024-01-18 11:55:01,517:INFO:             xgboost: 2.0.3
2024-01-18 11:55:01,517:INFO:            catboost: 1.2.2
2024-01-18 11:55:01,517:INFO:              kmodes: Not installed
2024-01-18 11:55:01,517:INFO:             mlxtend: Not installed
2024-01-18 11:55:01,517:INFO:       statsforecast: Not installed
2024-01-18 11:55:01,517:INFO:        tune_sklearn: Not installed
2024-01-18 11:55:01,517:INFO:                 ray: Not installed
2024-01-18 11:55:01,517:INFO:            hyperopt: Not installed
2024-01-18 11:55:01,518:INFO:              optuna: 3.5.0
2024-01-18 11:55:01,518:INFO:               skopt: Not installed
2024-01-18 11:55:01,518:INFO:              mlflow: Not installed
2024-01-18 11:55:01,518:INFO:              gradio: Not installed
2024-01-18 11:55:01,518:INFO:             fastapi: Not installed
2024-01-18 11:55:01,518:INFO:             uvicorn: Not installed
2024-01-18 11:55:01,518:INFO:              m2cgen: Not installed
2024-01-18 11:55:01,518:INFO:           evidently: Not installed
2024-01-18 11:55:01,518:INFO:               fugue: Not installed
2024-01-18 11:55:01,518:INFO:           streamlit: Not installed
2024-01-18 11:55:01,518:INFO:             prophet: Not installed
2024-01-18 11:55:01,518:INFO:None
2024-01-18 11:55:01,518:INFO:Set up data.
2024-01-18 11:55:01,530:INFO:Set up folding strategy.
2024-01-18 11:55:01,531:INFO:Set up train/test split.
2024-01-18 11:55:01,542:INFO:Set up index.
2024-01-18 11:55:01,542:INFO:Assigning column types.
2024-01-18 11:55:01,548:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 11:55:01,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:55:01,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:55:01,723:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:55:01,723:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:55:01,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 11:55:01,823:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:55:01,871:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:55:01,871:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:55:01,871:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 11:55:01,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:55:01,992:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:55:01,994:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:55:02,068:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 11:55:02,100:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:55:02,100:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:55:02,100:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 11:55:02,226:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:55:02,226:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:55:02,335:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:55:02,342:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:55:02,342:INFO:Preparing preprocessing pipeline...
2024-01-18 11:55:02,342:INFO:Set up simple imputation.
2024-01-18 11:55:02,342:INFO:Set up column name cleaning.
2024-01-18 11:55:02,398:INFO:Finished creating preprocessing pipeline.
2024-01-18 11:55:02,408:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CryoSleep', 'Age', 'VIP',
                                             'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck',
                                             'HomePlanet_Earth',
                                             'HomePlanet_Europa',
                                             'HomePlanet_Mars',
                                             'Destination_55 Cancri e',
                                             'Destination_PSO J318.5-22',
                                             'Destination_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 11:55:02,408:INFO:Creating final display dataframe.
2024-01-18 11:55:02,606:INFO:Setup _display_container:                     Description             Value
0                    Session id              3158
1                        Target     Transported_y
2                   Target type            Binary
3           Original data shape        (8693, 16)
4        Transformed data shape        (8693, 16)
5   Transformed train set shape        (6085, 16)
6    Transformed test set shape        (2608, 16)
7              Numeric features                14
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9e66
2024-01-18 11:55:02,755:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:55:02,760:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:55:02,883:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 11:55:02,883:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 11:55:02,883:INFO:setup() successfully completed in 1.38s...............
2024-01-18 11:55:02,883:INFO:PyCaret ClassificationExperiment
2024-01-18 11:55:02,883:INFO:Logging name: clf-default-name
2024-01-18 11:55:02,883:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:55:02,883:INFO:version 3.2.0
2024-01-18 11:55:02,898:INFO:Initializing setup()
2024-01-18 11:55:02,898:INFO:self.USI: c1f2
2024-01-18 11:55:02,898:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:55:02,898:INFO:Checking environment
2024-01-18 11:55:02,898:INFO:python_version: 3.11.5
2024-01-18 11:55:02,898:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:55:02,898:INFO:machine: AMD64
2024-01-18 11:55:02,898:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:55:02,898:INFO:Memory: svmem(total=8361132032, available=1266974720, percent=84.8, used=7094157312, free=1266974720)
2024-01-18 11:55:02,898:INFO:Physical Core: 2
2024-01-18 11:55:02,898:INFO:Logical Core: 4
2024-01-18 11:55:02,898:INFO:Checking libraries
2024-01-18 11:55:02,898:INFO:System:
2024-01-18 11:55:02,898:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:55:02,898:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:55:02,898:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:55:02,898:INFO:PyCaret required dependencies:
2024-01-18 11:55:02,898:INFO:                 pip: 23.2.1
2024-01-18 11:55:02,898:INFO:          setuptools: 68.0.0
2024-01-18 11:55:02,898:INFO:             pycaret: 3.2.0
2024-01-18 11:55:02,898:INFO:             IPython: 8.15.0
2024-01-18 11:55:02,898:INFO:          ipywidgets: 8.0.4
2024-01-18 11:55:02,898:INFO:                tqdm: 4.65.0
2024-01-18 11:55:02,898:INFO:               numpy: 1.24.3
2024-01-18 11:55:02,898:INFO:              pandas: 1.5.3
2024-01-18 11:55:02,898:INFO:              jinja2: 3.1.2
2024-01-18 11:55:02,898:INFO:               scipy: 1.10.1
2024-01-18 11:55:02,898:INFO:              joblib: 1.2.0
2024-01-18 11:55:02,898:INFO:             sklearn: 1.2.2
2024-01-18 11:55:02,898:INFO:                pyod: 1.1.2
2024-01-18 11:55:02,898:INFO:            imblearn: 0.10.1
2024-01-18 11:55:02,898:INFO:   category_encoders: 2.6.3
2024-01-18 11:55:02,898:INFO:            lightgbm: 4.2.0
2024-01-18 11:55:02,898:INFO:               numba: 0.57.1
2024-01-18 11:55:02,898:INFO:            requests: 2.31.0
2024-01-18 11:55:02,898:INFO:          matplotlib: 3.6.0
2024-01-18 11:55:02,898:INFO:          scikitplot: 0.3.7
2024-01-18 11:55:02,898:INFO:         yellowbrick: 1.5
2024-01-18 11:55:02,898:INFO:              plotly: 5.9.0
2024-01-18 11:55:02,898:INFO:    plotly-resampler: Not installed
2024-01-18 11:55:02,898:INFO:             kaleido: 0.2.1
2024-01-18 11:55:02,898:INFO:           schemdraw: 0.15
2024-01-18 11:55:02,898:INFO:         statsmodels: 0.14.0
2024-01-18 11:55:02,898:INFO:              sktime: 0.21.1
2024-01-18 11:55:02,898:INFO:               tbats: 1.1.3
2024-01-18 11:55:02,898:INFO:            pmdarima: 2.0.4
2024-01-18 11:55:02,898:INFO:              psutil: 5.9.0
2024-01-18 11:55:02,898:INFO:          markupsafe: 2.1.1
2024-01-18 11:55:02,898:INFO:             pickle5: Not installed
2024-01-18 11:55:02,898:INFO:         cloudpickle: 2.2.1
2024-01-18 11:55:02,898:INFO:         deprecation: 2.1.0
2024-01-18 11:55:02,898:INFO:              xxhash: 2.0.2
2024-01-18 11:55:02,898:INFO:           wurlitzer: Not installed
2024-01-18 11:55:02,898:INFO:PyCaret optional dependencies:
2024-01-18 11:55:02,898:INFO:                shap: Not installed
2024-01-18 11:55:02,898:INFO:           interpret: Not installed
2024-01-18 11:55:02,898:INFO:                umap: Not installed
2024-01-18 11:55:02,898:INFO:     ydata_profiling: Not installed
2024-01-18 11:55:02,898:INFO:  explainerdashboard: Not installed
2024-01-18 11:55:02,898:INFO:             autoviz: Not installed
2024-01-18 11:55:02,898:INFO:           fairlearn: Not installed
2024-01-18 11:55:02,898:INFO:          deepchecks: Not installed
2024-01-18 11:55:02,898:INFO:             xgboost: 2.0.3
2024-01-18 11:55:02,898:INFO:            catboost: 1.2.2
2024-01-18 11:55:02,898:INFO:              kmodes: Not installed
2024-01-18 11:55:02,898:INFO:             mlxtend: Not installed
2024-01-18 11:55:02,898:INFO:       statsforecast: Not installed
2024-01-18 11:55:02,898:INFO:        tune_sklearn: Not installed
2024-01-18 11:55:02,898:INFO:                 ray: Not installed
2024-01-18 11:55:02,898:INFO:            hyperopt: Not installed
2024-01-18 11:55:02,898:INFO:              optuna: 3.5.0
2024-01-18 11:55:02,898:INFO:               skopt: Not installed
2024-01-18 11:55:02,898:INFO:              mlflow: Not installed
2024-01-18 11:55:02,898:INFO:              gradio: Not installed
2024-01-18 11:55:02,898:INFO:             fastapi: Not installed
2024-01-18 11:55:02,898:INFO:             uvicorn: Not installed
2024-01-18 11:55:02,898:INFO:              m2cgen: Not installed
2024-01-18 11:55:02,898:INFO:           evidently: Not installed
2024-01-18 11:55:02,898:INFO:               fugue: Not installed
2024-01-18 11:55:02,898:INFO:           streamlit: Not installed
2024-01-18 11:55:02,898:INFO:             prophet: Not installed
2024-01-18 11:55:02,898:INFO:None
2024-01-18 11:55:02,898:INFO:Set up data.
2024-01-18 11:55:02,915:INFO:Set up folding strategy.
2024-01-18 11:55:02,915:INFO:Set up train/test split.
2024-01-18 11:55:02,930:INFO:Set up index.
2024-01-18 11:55:02,930:INFO:Assigning column types.
2024-01-18 11:55:24,933:INFO:PyCaret ClassificationExperiment
2024-01-18 11:55:24,933:INFO:Logging name: clf-default-name
2024-01-18 11:55:24,933:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:55:24,933:INFO:version 3.2.0
2024-01-18 11:55:24,933:INFO:Initializing setup()
2024-01-18 11:55:24,933:INFO:self.USI: 51e1
2024-01-18 11:55:24,933:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:55:24,933:INFO:Checking environment
2024-01-18 11:55:24,933:INFO:python_version: 3.11.5
2024-01-18 11:55:24,934:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:55:24,934:INFO:machine: AMD64
2024-01-18 11:55:24,934:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:55:24,934:INFO:Memory: svmem(total=8361132032, available=1325297664, percent=84.1, used=7035834368, free=1325297664)
2024-01-18 11:55:24,934:INFO:Physical Core: 2
2024-01-18 11:55:24,934:INFO:Logical Core: 4
2024-01-18 11:55:24,934:INFO:Checking libraries
2024-01-18 11:55:24,934:INFO:System:
2024-01-18 11:55:24,934:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:55:24,934:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:55:24,934:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:55:24,934:INFO:PyCaret required dependencies:
2024-01-18 11:55:24,935:INFO:                 pip: 23.2.1
2024-01-18 11:55:24,935:INFO:          setuptools: 68.0.0
2024-01-18 11:55:24,935:INFO:             pycaret: 3.2.0
2024-01-18 11:55:24,935:INFO:             IPython: 8.15.0
2024-01-18 11:55:24,935:INFO:          ipywidgets: 8.0.4
2024-01-18 11:55:24,935:INFO:                tqdm: 4.65.0
2024-01-18 11:55:24,935:INFO:               numpy: 1.24.3
2024-01-18 11:55:24,935:INFO:              pandas: 1.5.3
2024-01-18 11:55:24,935:INFO:              jinja2: 3.1.2
2024-01-18 11:55:24,935:INFO:               scipy: 1.10.1
2024-01-18 11:55:24,935:INFO:              joblib: 1.2.0
2024-01-18 11:55:24,935:INFO:             sklearn: 1.2.2
2024-01-18 11:55:24,936:INFO:                pyod: 1.1.2
2024-01-18 11:55:24,936:INFO:            imblearn: 0.10.1
2024-01-18 11:55:24,936:INFO:   category_encoders: 2.6.3
2024-01-18 11:55:24,936:INFO:            lightgbm: 4.2.0
2024-01-18 11:55:24,936:INFO:               numba: 0.57.1
2024-01-18 11:55:24,936:INFO:            requests: 2.31.0
2024-01-18 11:55:24,936:INFO:          matplotlib: 3.6.0
2024-01-18 11:55:24,936:INFO:          scikitplot: 0.3.7
2024-01-18 11:55:24,936:INFO:         yellowbrick: 1.5
2024-01-18 11:55:24,936:INFO:              plotly: 5.9.0
2024-01-18 11:55:24,936:INFO:    plotly-resampler: Not installed
2024-01-18 11:55:24,936:INFO:             kaleido: 0.2.1
2024-01-18 11:55:24,936:INFO:           schemdraw: 0.15
2024-01-18 11:55:24,938:INFO:         statsmodels: 0.14.0
2024-01-18 11:55:24,938:INFO:              sktime: 0.21.1
2024-01-18 11:55:24,938:INFO:               tbats: 1.1.3
2024-01-18 11:55:24,938:INFO:            pmdarima: 2.0.4
2024-01-18 11:55:24,938:INFO:              psutil: 5.9.0
2024-01-18 11:55:24,938:INFO:          markupsafe: 2.1.1
2024-01-18 11:55:24,938:INFO:             pickle5: Not installed
2024-01-18 11:55:24,938:INFO:         cloudpickle: 2.2.1
2024-01-18 11:55:24,938:INFO:         deprecation: 2.1.0
2024-01-18 11:55:24,938:INFO:              xxhash: 2.0.2
2024-01-18 11:55:24,938:INFO:           wurlitzer: Not installed
2024-01-18 11:55:24,938:INFO:PyCaret optional dependencies:
2024-01-18 11:55:24,938:INFO:                shap: Not installed
2024-01-18 11:55:24,938:INFO:           interpret: Not installed
2024-01-18 11:55:24,939:INFO:                umap: Not installed
2024-01-18 11:55:24,939:INFO:     ydata_profiling: Not installed
2024-01-18 11:55:24,939:INFO:  explainerdashboard: Not installed
2024-01-18 11:55:24,939:INFO:             autoviz: Not installed
2024-01-18 11:55:24,939:INFO:           fairlearn: Not installed
2024-01-18 11:55:24,939:INFO:          deepchecks: Not installed
2024-01-18 11:55:24,939:INFO:             xgboost: 2.0.3
2024-01-18 11:55:24,939:INFO:            catboost: 1.2.2
2024-01-18 11:55:24,939:INFO:              kmodes: Not installed
2024-01-18 11:55:24,939:INFO:             mlxtend: Not installed
2024-01-18 11:55:24,939:INFO:       statsforecast: Not installed
2024-01-18 11:55:24,939:INFO:        tune_sklearn: Not installed
2024-01-18 11:55:24,939:INFO:                 ray: Not installed
2024-01-18 11:55:24,939:INFO:            hyperopt: Not installed
2024-01-18 11:55:24,939:INFO:              optuna: 3.5.0
2024-01-18 11:55:24,939:INFO:               skopt: Not installed
2024-01-18 11:55:24,940:INFO:              mlflow: Not installed
2024-01-18 11:55:24,940:INFO:              gradio: Not installed
2024-01-18 11:55:24,940:INFO:             fastapi: Not installed
2024-01-18 11:55:24,940:INFO:             uvicorn: Not installed
2024-01-18 11:55:24,940:INFO:              m2cgen: Not installed
2024-01-18 11:55:24,940:INFO:           evidently: Not installed
2024-01-18 11:55:24,940:INFO:               fugue: Not installed
2024-01-18 11:55:24,940:INFO:           streamlit: Not installed
2024-01-18 11:55:24,940:INFO:             prophet: Not installed
2024-01-18 11:55:24,940:INFO:None
2024-01-18 11:55:24,940:INFO:Set up data.
2024-01-18 11:55:24,951:INFO:Set up folding strategy.
2024-01-18 11:55:24,951:INFO:Set up train/test split.
2024-01-18 11:55:24,958:INFO:Set up index.
2024-01-18 11:55:24,958:INFO:Assigning column types.
2024-01-18 11:56:48,506:INFO:PyCaret ClassificationExperiment
2024-01-18 11:56:48,506:INFO:Logging name: clf-default-name
2024-01-18 11:56:48,506:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:56:48,506:INFO:version 3.2.0
2024-01-18 11:56:48,506:INFO:Initializing setup()
2024-01-18 11:56:48,506:INFO:self.USI: 7e65
2024-01-18 11:56:48,506:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:56:48,506:INFO:Checking environment
2024-01-18 11:56:48,506:INFO:python_version: 3.11.5
2024-01-18 11:56:48,507:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:56:48,507:INFO:machine: AMD64
2024-01-18 11:56:48,507:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:56:48,507:INFO:Memory: svmem(total=8361132032, available=2075471872, percent=75.2, used=6285660160, free=2075471872)
2024-01-18 11:56:48,507:INFO:Physical Core: 2
2024-01-18 11:56:48,507:INFO:Logical Core: 4
2024-01-18 11:56:48,507:INFO:Checking libraries
2024-01-18 11:56:48,507:INFO:System:
2024-01-18 11:56:48,507:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:56:48,507:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:56:48,507:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:56:48,507:INFO:PyCaret required dependencies:
2024-01-18 11:56:48,507:INFO:                 pip: 23.2.1
2024-01-18 11:56:48,507:INFO:          setuptools: 68.0.0
2024-01-18 11:56:48,507:INFO:             pycaret: 3.2.0
2024-01-18 11:56:48,507:INFO:             IPython: 8.15.0
2024-01-18 11:56:48,507:INFO:          ipywidgets: 8.0.4
2024-01-18 11:56:48,507:INFO:                tqdm: 4.65.0
2024-01-18 11:56:48,507:INFO:               numpy: 1.24.3
2024-01-18 11:56:48,507:INFO:              pandas: 1.5.3
2024-01-18 11:56:48,508:INFO:              jinja2: 3.1.2
2024-01-18 11:56:48,508:INFO:               scipy: 1.10.1
2024-01-18 11:56:48,508:INFO:              joblib: 1.2.0
2024-01-18 11:56:48,508:INFO:             sklearn: 1.2.2
2024-01-18 11:56:48,508:INFO:                pyod: 1.1.2
2024-01-18 11:56:48,508:INFO:            imblearn: 0.10.1
2024-01-18 11:56:48,508:INFO:   category_encoders: 2.6.3
2024-01-18 11:56:48,508:INFO:            lightgbm: 4.2.0
2024-01-18 11:56:48,508:INFO:               numba: 0.57.1
2024-01-18 11:56:48,508:INFO:            requests: 2.31.0
2024-01-18 11:56:48,508:INFO:          matplotlib: 3.6.0
2024-01-18 11:56:48,508:INFO:          scikitplot: 0.3.7
2024-01-18 11:56:48,508:INFO:         yellowbrick: 1.5
2024-01-18 11:56:48,508:INFO:              plotly: 5.9.0
2024-01-18 11:56:48,508:INFO:    plotly-resampler: Not installed
2024-01-18 11:56:48,508:INFO:             kaleido: 0.2.1
2024-01-18 11:56:48,508:INFO:           schemdraw: 0.15
2024-01-18 11:56:48,508:INFO:         statsmodels: 0.14.0
2024-01-18 11:56:48,508:INFO:              sktime: 0.21.1
2024-01-18 11:56:48,508:INFO:               tbats: 1.1.3
2024-01-18 11:56:48,508:INFO:            pmdarima: 2.0.4
2024-01-18 11:56:48,508:INFO:              psutil: 5.9.0
2024-01-18 11:56:48,508:INFO:          markupsafe: 2.1.1
2024-01-18 11:56:48,508:INFO:             pickle5: Not installed
2024-01-18 11:56:48,508:INFO:         cloudpickle: 2.2.1
2024-01-18 11:56:48,510:INFO:         deprecation: 2.1.0
2024-01-18 11:56:48,510:INFO:              xxhash: 2.0.2
2024-01-18 11:56:48,510:INFO:           wurlitzer: Not installed
2024-01-18 11:56:48,510:INFO:PyCaret optional dependencies:
2024-01-18 11:56:48,510:INFO:                shap: Not installed
2024-01-18 11:56:48,510:INFO:           interpret: Not installed
2024-01-18 11:56:48,510:INFO:                umap: Not installed
2024-01-18 11:56:48,510:INFO:     ydata_profiling: Not installed
2024-01-18 11:56:48,510:INFO:  explainerdashboard: Not installed
2024-01-18 11:56:48,510:INFO:             autoviz: Not installed
2024-01-18 11:56:48,510:INFO:           fairlearn: Not installed
2024-01-18 11:56:48,510:INFO:          deepchecks: Not installed
2024-01-18 11:56:48,510:INFO:             xgboost: 2.0.3
2024-01-18 11:56:48,510:INFO:            catboost: 1.2.2
2024-01-18 11:56:48,511:INFO:              kmodes: Not installed
2024-01-18 11:56:48,511:INFO:             mlxtend: Not installed
2024-01-18 11:56:48,511:INFO:       statsforecast: Not installed
2024-01-18 11:56:48,511:INFO:        tune_sklearn: Not installed
2024-01-18 11:56:48,511:INFO:                 ray: Not installed
2024-01-18 11:56:48,511:INFO:            hyperopt: Not installed
2024-01-18 11:56:48,511:INFO:              optuna: 3.5.0
2024-01-18 11:56:48,511:INFO:               skopt: Not installed
2024-01-18 11:56:48,511:INFO:              mlflow: Not installed
2024-01-18 11:56:48,511:INFO:              gradio: Not installed
2024-01-18 11:56:48,511:INFO:             fastapi: Not installed
2024-01-18 11:56:48,511:INFO:             uvicorn: Not installed
2024-01-18 11:56:48,511:INFO:              m2cgen: Not installed
2024-01-18 11:56:48,511:INFO:           evidently: Not installed
2024-01-18 11:56:48,511:INFO:               fugue: Not installed
2024-01-18 11:56:48,511:INFO:           streamlit: Not installed
2024-01-18 11:56:48,512:INFO:             prophet: Not installed
2024-01-18 11:56:48,512:INFO:None
2024-01-18 11:56:48,512:INFO:Set up data.
2024-01-18 11:56:48,522:INFO:Set up folding strategy.
2024-01-18 11:56:48,522:INFO:Set up train/test split.
2024-01-18 11:56:48,539:INFO:Set up index.
2024-01-18 11:56:48,539:INFO:Assigning column types.
2024-01-18 11:57:28,657:INFO:PyCaret ClassificationExperiment
2024-01-18 11:57:28,657:INFO:Logging name: clf-default-name
2024-01-18 11:57:28,657:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:57:28,657:INFO:version 3.2.0
2024-01-18 11:57:28,657:INFO:Initializing setup()
2024-01-18 11:57:28,657:INFO:self.USI: 798e
2024-01-18 11:57:28,657:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:57:28,657:INFO:Checking environment
2024-01-18 11:57:28,657:INFO:python_version: 3.11.5
2024-01-18 11:57:28,657:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:57:28,657:INFO:machine: AMD64
2024-01-18 11:57:28,657:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:57:28,658:INFO:Memory: svmem(total=8361132032, available=2085957632, percent=75.1, used=6275174400, free=2085957632)
2024-01-18 11:57:28,658:INFO:Physical Core: 2
2024-01-18 11:57:28,658:INFO:Logical Core: 4
2024-01-18 11:57:28,658:INFO:Checking libraries
2024-01-18 11:57:28,658:INFO:System:
2024-01-18 11:57:28,658:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:57:28,658:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:57:28,658:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:57:28,658:INFO:PyCaret required dependencies:
2024-01-18 11:57:28,658:INFO:                 pip: 23.2.1
2024-01-18 11:57:28,658:INFO:          setuptools: 68.0.0
2024-01-18 11:57:28,658:INFO:             pycaret: 3.2.0
2024-01-18 11:57:28,658:INFO:             IPython: 8.15.0
2024-01-18 11:57:28,658:INFO:          ipywidgets: 8.0.4
2024-01-18 11:57:28,659:INFO:                tqdm: 4.65.0
2024-01-18 11:57:28,659:INFO:               numpy: 1.24.3
2024-01-18 11:57:28,659:INFO:              pandas: 1.5.3
2024-01-18 11:57:28,659:INFO:              jinja2: 3.1.2
2024-01-18 11:57:28,659:INFO:               scipy: 1.10.1
2024-01-18 11:57:28,659:INFO:              joblib: 1.2.0
2024-01-18 11:57:28,659:INFO:             sklearn: 1.2.2
2024-01-18 11:57:28,659:INFO:                pyod: 1.1.2
2024-01-18 11:57:28,659:INFO:            imblearn: 0.10.1
2024-01-18 11:57:28,659:INFO:   category_encoders: 2.6.3
2024-01-18 11:57:28,659:INFO:            lightgbm: 4.2.0
2024-01-18 11:57:28,659:INFO:               numba: 0.57.1
2024-01-18 11:57:28,659:INFO:            requests: 2.31.0
2024-01-18 11:57:28,659:INFO:          matplotlib: 3.6.0
2024-01-18 11:57:28,659:INFO:          scikitplot: 0.3.7
2024-01-18 11:57:28,659:INFO:         yellowbrick: 1.5
2024-01-18 11:57:28,660:INFO:              plotly: 5.9.0
2024-01-18 11:57:28,660:INFO:    plotly-resampler: Not installed
2024-01-18 11:57:28,660:INFO:             kaleido: 0.2.1
2024-01-18 11:57:28,660:INFO:           schemdraw: 0.15
2024-01-18 11:57:28,660:INFO:         statsmodels: 0.14.0
2024-01-18 11:57:28,660:INFO:              sktime: 0.21.1
2024-01-18 11:57:28,660:INFO:               tbats: 1.1.3
2024-01-18 11:57:28,660:INFO:            pmdarima: 2.0.4
2024-01-18 11:57:28,660:INFO:              psutil: 5.9.0
2024-01-18 11:57:28,660:INFO:          markupsafe: 2.1.1
2024-01-18 11:57:28,660:INFO:             pickle5: Not installed
2024-01-18 11:57:28,660:INFO:         cloudpickle: 2.2.1
2024-01-18 11:57:28,660:INFO:         deprecation: 2.1.0
2024-01-18 11:57:28,660:INFO:              xxhash: 2.0.2
2024-01-18 11:57:28,660:INFO:           wurlitzer: Not installed
2024-01-18 11:57:28,661:INFO:PyCaret optional dependencies:
2024-01-18 11:57:28,661:INFO:                shap: Not installed
2024-01-18 11:57:28,661:INFO:           interpret: Not installed
2024-01-18 11:57:28,661:INFO:                umap: Not installed
2024-01-18 11:57:28,661:INFO:     ydata_profiling: Not installed
2024-01-18 11:57:28,661:INFO:  explainerdashboard: Not installed
2024-01-18 11:57:28,661:INFO:             autoviz: Not installed
2024-01-18 11:57:28,661:INFO:           fairlearn: Not installed
2024-01-18 11:57:28,661:INFO:          deepchecks: Not installed
2024-01-18 11:57:28,661:INFO:             xgboost: 2.0.3
2024-01-18 11:57:28,661:INFO:            catboost: 1.2.2
2024-01-18 11:57:28,661:INFO:              kmodes: Not installed
2024-01-18 11:57:28,661:INFO:             mlxtend: Not installed
2024-01-18 11:57:28,661:INFO:       statsforecast: Not installed
2024-01-18 11:57:28,661:INFO:        tune_sklearn: Not installed
2024-01-18 11:57:28,661:INFO:                 ray: Not installed
2024-01-18 11:57:28,661:INFO:            hyperopt: Not installed
2024-01-18 11:57:28,661:INFO:              optuna: 3.5.0
2024-01-18 11:57:28,661:INFO:               skopt: Not installed
2024-01-18 11:57:28,661:INFO:              mlflow: Not installed
2024-01-18 11:57:28,661:INFO:              gradio: Not installed
2024-01-18 11:57:28,661:INFO:             fastapi: Not installed
2024-01-18 11:57:28,661:INFO:             uvicorn: Not installed
2024-01-18 11:57:28,661:INFO:              m2cgen: Not installed
2024-01-18 11:57:28,661:INFO:           evidently: Not installed
2024-01-18 11:57:28,662:INFO:               fugue: Not installed
2024-01-18 11:57:28,662:INFO:           streamlit: Not installed
2024-01-18 11:57:28,662:INFO:             prophet: Not installed
2024-01-18 11:57:28,662:INFO:None
2024-01-18 11:57:28,662:INFO:Set up data.
2024-01-18 11:57:28,669:INFO:Set up folding strategy.
2024-01-18 11:57:28,670:INFO:Set up train/test split.
2024-01-18 11:57:28,686:INFO:Set up index.
2024-01-18 11:57:28,687:INFO:Assigning column types.
2024-01-18 11:59:16,083:INFO:PyCaret ClassificationExperiment
2024-01-18 11:59:16,083:INFO:Logging name: clf-default-name
2024-01-18 11:59:16,083:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 11:59:16,083:INFO:version 3.2.0
2024-01-18 11:59:16,083:INFO:Initializing setup()
2024-01-18 11:59:16,083:INFO:self.USI: 11d8
2024-01-18 11:59:16,083:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 11:59:16,083:INFO:Checking environment
2024-01-18 11:59:16,083:INFO:python_version: 3.11.5
2024-01-18 11:59:16,083:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 11:59:16,084:INFO:machine: AMD64
2024-01-18 11:59:16,084:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 11:59:16,084:INFO:Memory: svmem(total=8361132032, available=2107805696, percent=74.8, used=6253326336, free=2107805696)
2024-01-18 11:59:16,084:INFO:Physical Core: 2
2024-01-18 11:59:16,084:INFO:Logical Core: 4
2024-01-18 11:59:16,084:INFO:Checking libraries
2024-01-18 11:59:16,084:INFO:System:
2024-01-18 11:59:16,084:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 11:59:16,084:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 11:59:16,084:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 11:59:16,084:INFO:PyCaret required dependencies:
2024-01-18 11:59:16,084:INFO:                 pip: 23.2.1
2024-01-18 11:59:16,084:INFO:          setuptools: 68.0.0
2024-01-18 11:59:16,084:INFO:             pycaret: 3.2.0
2024-01-18 11:59:16,084:INFO:             IPython: 8.15.0
2024-01-18 11:59:16,084:INFO:          ipywidgets: 8.0.4
2024-01-18 11:59:16,084:INFO:                tqdm: 4.65.0
2024-01-18 11:59:16,084:INFO:               numpy: 1.24.3
2024-01-18 11:59:16,084:INFO:              pandas: 1.5.3
2024-01-18 11:59:16,085:INFO:              jinja2: 3.1.2
2024-01-18 11:59:16,085:INFO:               scipy: 1.10.1
2024-01-18 11:59:16,085:INFO:              joblib: 1.2.0
2024-01-18 11:59:16,085:INFO:             sklearn: 1.2.2
2024-01-18 11:59:16,085:INFO:                pyod: 1.1.2
2024-01-18 11:59:16,085:INFO:            imblearn: 0.10.1
2024-01-18 11:59:16,085:INFO:   category_encoders: 2.6.3
2024-01-18 11:59:16,085:INFO:            lightgbm: 4.2.0
2024-01-18 11:59:16,085:INFO:               numba: 0.57.1
2024-01-18 11:59:16,085:INFO:            requests: 2.31.0
2024-01-18 11:59:16,085:INFO:          matplotlib: 3.6.0
2024-01-18 11:59:16,086:INFO:          scikitplot: 0.3.7
2024-01-18 11:59:16,086:INFO:         yellowbrick: 1.5
2024-01-18 11:59:16,086:INFO:              plotly: 5.9.0
2024-01-18 11:59:16,086:INFO:    plotly-resampler: Not installed
2024-01-18 11:59:16,086:INFO:             kaleido: 0.2.1
2024-01-18 11:59:16,086:INFO:           schemdraw: 0.15
2024-01-18 11:59:16,086:INFO:         statsmodels: 0.14.0
2024-01-18 11:59:16,086:INFO:              sktime: 0.21.1
2024-01-18 11:59:16,086:INFO:               tbats: 1.1.3
2024-01-18 11:59:16,086:INFO:            pmdarima: 2.0.4
2024-01-18 11:59:16,086:INFO:              psutil: 5.9.0
2024-01-18 11:59:16,086:INFO:          markupsafe: 2.1.1
2024-01-18 11:59:16,086:INFO:             pickle5: Not installed
2024-01-18 11:59:16,086:INFO:         cloudpickle: 2.2.1
2024-01-18 11:59:16,086:INFO:         deprecation: 2.1.0
2024-01-18 11:59:16,086:INFO:              xxhash: 2.0.2
2024-01-18 11:59:16,086:INFO:           wurlitzer: Not installed
2024-01-18 11:59:16,086:INFO:PyCaret optional dependencies:
2024-01-18 11:59:16,086:INFO:                shap: Not installed
2024-01-18 11:59:16,086:INFO:           interpret: Not installed
2024-01-18 11:59:16,086:INFO:                umap: Not installed
2024-01-18 11:59:16,087:INFO:     ydata_profiling: Not installed
2024-01-18 11:59:16,087:INFO:  explainerdashboard: Not installed
2024-01-18 11:59:16,087:INFO:             autoviz: Not installed
2024-01-18 11:59:16,087:INFO:           fairlearn: Not installed
2024-01-18 11:59:16,087:INFO:          deepchecks: Not installed
2024-01-18 11:59:16,087:INFO:             xgboost: 2.0.3
2024-01-18 11:59:16,087:INFO:            catboost: 1.2.2
2024-01-18 11:59:16,087:INFO:              kmodes: Not installed
2024-01-18 11:59:16,087:INFO:             mlxtend: Not installed
2024-01-18 11:59:16,087:INFO:       statsforecast: Not installed
2024-01-18 11:59:16,087:INFO:        tune_sklearn: Not installed
2024-01-18 11:59:16,087:INFO:                 ray: Not installed
2024-01-18 11:59:16,087:INFO:            hyperopt: Not installed
2024-01-18 11:59:16,087:INFO:              optuna: 3.5.0
2024-01-18 11:59:16,087:INFO:               skopt: Not installed
2024-01-18 11:59:16,087:INFO:              mlflow: Not installed
2024-01-18 11:59:16,087:INFO:              gradio: Not installed
2024-01-18 11:59:16,087:INFO:             fastapi: Not installed
2024-01-18 11:59:16,087:INFO:             uvicorn: Not installed
2024-01-18 11:59:16,087:INFO:              m2cgen: Not installed
2024-01-18 11:59:16,088:INFO:           evidently: Not installed
2024-01-18 11:59:16,088:INFO:               fugue: Not installed
2024-01-18 11:59:16,088:INFO:           streamlit: Not installed
2024-01-18 11:59:16,088:INFO:             prophet: Not installed
2024-01-18 11:59:16,088:INFO:None
2024-01-18 11:59:16,088:INFO:Set up data.
2024-01-18 11:59:16,096:INFO:Set up folding strategy.
2024-01-18 11:59:16,097:INFO:Set up train/test split.
2024-01-18 11:59:16,107:INFO:Set up index.
2024-01-18 11:59:16,107:INFO:Assigning column types.
2024-01-18 12:01:22,801:INFO:PyCaret ClassificationExperiment
2024-01-18 12:01:22,801:INFO:Logging name: clf-default-name
2024-01-18 12:01:22,801:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 12:01:22,803:INFO:version 3.2.0
2024-01-18 12:01:22,803:INFO:Initializing setup()
2024-01-18 12:01:22,803:INFO:self.USI: 5749
2024-01-18 12:01:22,803:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 12:01:22,803:INFO:Checking environment
2024-01-18 12:01:22,803:INFO:python_version: 3.11.5
2024-01-18 12:01:22,803:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 12:01:22,803:INFO:machine: AMD64
2024-01-18 12:01:22,803:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 12:01:22,804:INFO:Memory: svmem(total=8361132032, available=2129625088, percent=74.5, used=6231506944, free=2129625088)
2024-01-18 12:01:22,804:INFO:Physical Core: 2
2024-01-18 12:01:22,804:INFO:Logical Core: 4
2024-01-18 12:01:22,804:INFO:Checking libraries
2024-01-18 12:01:22,804:INFO:System:
2024-01-18 12:01:22,804:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 12:01:22,804:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 12:01:22,805:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 12:01:22,805:INFO:PyCaret required dependencies:
2024-01-18 12:01:22,805:INFO:                 pip: 23.2.1
2024-01-18 12:01:22,805:INFO:          setuptools: 68.0.0
2024-01-18 12:01:22,805:INFO:             pycaret: 3.2.0
2024-01-18 12:01:22,805:INFO:             IPython: 8.15.0
2024-01-18 12:01:22,805:INFO:          ipywidgets: 8.0.4
2024-01-18 12:01:22,805:INFO:                tqdm: 4.65.0
2024-01-18 12:01:22,806:INFO:               numpy: 1.24.3
2024-01-18 12:01:22,806:INFO:              pandas: 1.5.3
2024-01-18 12:01:22,806:INFO:              jinja2: 3.1.2
2024-01-18 12:01:22,806:INFO:               scipy: 1.10.1
2024-01-18 12:01:22,806:INFO:              joblib: 1.2.0
2024-01-18 12:01:22,806:INFO:             sklearn: 1.2.2
2024-01-18 12:01:22,806:INFO:                pyod: 1.1.2
2024-01-18 12:01:22,806:INFO:            imblearn: 0.10.1
2024-01-18 12:01:22,806:INFO:   category_encoders: 2.6.3
2024-01-18 12:01:22,806:INFO:            lightgbm: 4.2.0
2024-01-18 12:01:22,807:INFO:               numba: 0.57.1
2024-01-18 12:01:22,807:INFO:            requests: 2.31.0
2024-01-18 12:01:22,807:INFO:          matplotlib: 3.6.0
2024-01-18 12:01:22,807:INFO:          scikitplot: 0.3.7
2024-01-18 12:01:22,807:INFO:         yellowbrick: 1.5
2024-01-18 12:01:22,807:INFO:              plotly: 5.9.0
2024-01-18 12:01:22,807:INFO:    plotly-resampler: Not installed
2024-01-18 12:01:22,807:INFO:             kaleido: 0.2.1
2024-01-18 12:01:22,807:INFO:           schemdraw: 0.15
2024-01-18 12:01:22,808:INFO:         statsmodels: 0.14.0
2024-01-18 12:01:22,808:INFO:              sktime: 0.21.1
2024-01-18 12:01:22,808:INFO:               tbats: 1.1.3
2024-01-18 12:01:22,808:INFO:            pmdarima: 2.0.4
2024-01-18 12:01:22,808:INFO:              psutil: 5.9.0
2024-01-18 12:01:22,808:INFO:          markupsafe: 2.1.1
2024-01-18 12:01:22,808:INFO:             pickle5: Not installed
2024-01-18 12:01:22,808:INFO:         cloudpickle: 2.2.1
2024-01-18 12:01:22,808:INFO:         deprecation: 2.1.0
2024-01-18 12:01:22,808:INFO:              xxhash: 2.0.2
2024-01-18 12:01:22,809:INFO:           wurlitzer: Not installed
2024-01-18 12:01:22,809:INFO:PyCaret optional dependencies:
2024-01-18 12:01:22,809:INFO:                shap: Not installed
2024-01-18 12:01:22,809:INFO:           interpret: Not installed
2024-01-18 12:01:22,809:INFO:                umap: Not installed
2024-01-18 12:01:22,809:INFO:     ydata_profiling: Not installed
2024-01-18 12:01:22,809:INFO:  explainerdashboard: Not installed
2024-01-18 12:01:22,809:INFO:             autoviz: Not installed
2024-01-18 12:01:22,809:INFO:           fairlearn: Not installed
2024-01-18 12:01:22,810:INFO:          deepchecks: Not installed
2024-01-18 12:01:22,810:INFO:             xgboost: 2.0.3
2024-01-18 12:01:22,810:INFO:            catboost: 1.2.2
2024-01-18 12:01:22,810:INFO:              kmodes: Not installed
2024-01-18 12:01:22,810:INFO:             mlxtend: Not installed
2024-01-18 12:01:22,810:INFO:       statsforecast: Not installed
2024-01-18 12:01:22,810:INFO:        tune_sklearn: Not installed
2024-01-18 12:01:22,810:INFO:                 ray: Not installed
2024-01-18 12:01:22,810:INFO:            hyperopt: Not installed
2024-01-18 12:01:22,810:INFO:              optuna: 3.5.0
2024-01-18 12:01:22,811:INFO:               skopt: Not installed
2024-01-18 12:01:22,811:INFO:              mlflow: Not installed
2024-01-18 12:01:22,811:INFO:              gradio: Not installed
2024-01-18 12:01:22,811:INFO:             fastapi: Not installed
2024-01-18 12:01:22,811:INFO:             uvicorn: Not installed
2024-01-18 12:01:22,811:INFO:              m2cgen: Not installed
2024-01-18 12:01:22,811:INFO:           evidently: Not installed
2024-01-18 12:01:22,811:INFO:               fugue: Not installed
2024-01-18 12:01:22,811:INFO:           streamlit: Not installed
2024-01-18 12:01:22,811:INFO:             prophet: Not installed
2024-01-18 12:01:22,811:INFO:None
2024-01-18 12:01:22,812:INFO:Set up data.
2024-01-18 12:01:22,818:INFO:Set up folding strategy.
2024-01-18 12:01:22,818:INFO:Set up train/test split.
2024-01-18 12:01:22,834:INFO:Set up index.
2024-01-18 12:01:22,834:INFO:Assigning column types.
2024-01-18 12:02:50,702:INFO:PyCaret ClassificationExperiment
2024-01-18 12:02:50,703:INFO:Logging name: clf-default-name
2024-01-18 12:02:50,703:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 12:02:50,703:INFO:version 3.2.0
2024-01-18 12:02:50,703:INFO:Initializing setup()
2024-01-18 12:02:50,703:INFO:self.USI: a599
2024-01-18 12:02:50,703:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 12:02:50,703:INFO:Checking environment
2024-01-18 12:02:50,703:INFO:python_version: 3.11.5
2024-01-18 12:02:50,703:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 12:02:50,703:INFO:machine: AMD64
2024-01-18 12:02:50,703:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 12:02:50,703:INFO:Memory: svmem(total=8361132032, available=1975914496, percent=76.4, used=6385217536, free=1975914496)
2024-01-18 12:02:50,703:INFO:Physical Core: 2
2024-01-18 12:02:50,703:INFO:Logical Core: 4
2024-01-18 12:02:50,703:INFO:Checking libraries
2024-01-18 12:02:50,703:INFO:System:
2024-01-18 12:02:50,704:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 12:02:50,704:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 12:02:50,704:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 12:02:50,704:INFO:PyCaret required dependencies:
2024-01-18 12:02:50,704:INFO:                 pip: 23.2.1
2024-01-18 12:02:50,704:INFO:          setuptools: 68.0.0
2024-01-18 12:02:50,704:INFO:             pycaret: 3.2.0
2024-01-18 12:02:50,704:INFO:             IPython: 8.15.0
2024-01-18 12:02:50,704:INFO:          ipywidgets: 8.0.4
2024-01-18 12:02:50,704:INFO:                tqdm: 4.65.0
2024-01-18 12:02:50,704:INFO:               numpy: 1.24.3
2024-01-18 12:02:50,704:INFO:              pandas: 1.5.3
2024-01-18 12:02:50,704:INFO:              jinja2: 3.1.2
2024-01-18 12:02:50,704:INFO:               scipy: 1.10.1
2024-01-18 12:02:50,704:INFO:              joblib: 1.2.0
2024-01-18 12:02:50,704:INFO:             sklearn: 1.2.2
2024-01-18 12:02:50,704:INFO:                pyod: 1.1.2
2024-01-18 12:02:50,705:INFO:            imblearn: 0.10.1
2024-01-18 12:02:50,705:INFO:   category_encoders: 2.6.3
2024-01-18 12:02:50,705:INFO:            lightgbm: 4.2.0
2024-01-18 12:02:50,705:INFO:               numba: 0.57.1
2024-01-18 12:02:50,705:INFO:            requests: 2.31.0
2024-01-18 12:02:50,705:INFO:          matplotlib: 3.6.0
2024-01-18 12:02:50,705:INFO:          scikitplot: 0.3.7
2024-01-18 12:02:50,705:INFO:         yellowbrick: 1.5
2024-01-18 12:02:50,705:INFO:              plotly: 5.9.0
2024-01-18 12:02:50,705:INFO:    plotly-resampler: Not installed
2024-01-18 12:02:50,705:INFO:             kaleido: 0.2.1
2024-01-18 12:02:50,705:INFO:           schemdraw: 0.15
2024-01-18 12:02:50,705:INFO:         statsmodels: 0.14.0
2024-01-18 12:02:50,705:INFO:              sktime: 0.21.1
2024-01-18 12:02:50,706:INFO:               tbats: 1.1.3
2024-01-18 12:02:50,706:INFO:            pmdarima: 2.0.4
2024-01-18 12:02:50,706:INFO:              psutil: 5.9.0
2024-01-18 12:02:50,706:INFO:          markupsafe: 2.1.1
2024-01-18 12:02:50,706:INFO:             pickle5: Not installed
2024-01-18 12:02:50,706:INFO:         cloudpickle: 2.2.1
2024-01-18 12:02:50,706:INFO:         deprecation: 2.1.0
2024-01-18 12:02:50,706:INFO:              xxhash: 2.0.2
2024-01-18 12:02:50,706:INFO:           wurlitzer: Not installed
2024-01-18 12:02:50,706:INFO:PyCaret optional dependencies:
2024-01-18 12:02:50,706:INFO:                shap: Not installed
2024-01-18 12:02:50,706:INFO:           interpret: Not installed
2024-01-18 12:02:50,706:INFO:                umap: Not installed
2024-01-18 12:02:50,706:INFO:     ydata_profiling: Not installed
2024-01-18 12:02:50,707:INFO:  explainerdashboard: Not installed
2024-01-18 12:02:50,707:INFO:             autoviz: Not installed
2024-01-18 12:02:50,707:INFO:           fairlearn: Not installed
2024-01-18 12:02:50,707:INFO:          deepchecks: Not installed
2024-01-18 12:02:50,707:INFO:             xgboost: 2.0.3
2024-01-18 12:02:50,707:INFO:            catboost: 1.2.2
2024-01-18 12:02:50,707:INFO:              kmodes: Not installed
2024-01-18 12:02:50,707:INFO:             mlxtend: Not installed
2024-01-18 12:02:50,707:INFO:       statsforecast: Not installed
2024-01-18 12:02:50,707:INFO:        tune_sklearn: Not installed
2024-01-18 12:02:50,707:INFO:                 ray: Not installed
2024-01-18 12:02:50,707:INFO:            hyperopt: Not installed
2024-01-18 12:02:50,707:INFO:              optuna: 3.5.0
2024-01-18 12:02:50,707:INFO:               skopt: Not installed
2024-01-18 12:02:50,707:INFO:              mlflow: Not installed
2024-01-18 12:02:50,708:INFO:              gradio: Not installed
2024-01-18 12:02:50,708:INFO:             fastapi: Not installed
2024-01-18 12:02:50,708:INFO:             uvicorn: Not installed
2024-01-18 12:02:50,708:INFO:              m2cgen: Not installed
2024-01-18 12:02:50,708:INFO:           evidently: Not installed
2024-01-18 12:02:50,708:INFO:               fugue: Not installed
2024-01-18 12:02:50,708:INFO:           streamlit: Not installed
2024-01-18 12:02:50,708:INFO:             prophet: Not installed
2024-01-18 12:02:50,708:INFO:None
2024-01-18 12:02:50,708:INFO:Set up data.
2024-01-18 12:02:50,716:INFO:Set up folding strategy.
2024-01-18 12:02:50,717:INFO:Set up train/test split.
2024-01-18 12:02:50,723:INFO:Set up index.
2024-01-18 12:02:50,723:INFO:Assigning column types.
2024-01-18 12:04:27,391:INFO:PyCaret ClassificationExperiment
2024-01-18 12:04:27,391:INFO:Logging name: clf-default-name
2024-01-18 12:04:27,391:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 12:04:27,391:INFO:version 3.2.0
2024-01-18 12:04:27,391:INFO:Initializing setup()
2024-01-18 12:04:27,392:INFO:self.USI: e4e2
2024-01-18 12:04:27,392:INFO:self._variable_keys: {'target_param', 'fix_imbalance', '_available_plots', 'X_test', 'exp_id', 'fold_groups_param', 'X', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_name_log', 'fold_shuffle_param', 'idx', 'USI', 'data', 'memory', 'pipeline', 'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'is_multiclass'}
2024-01-18 12:04:27,392:INFO:Checking environment
2024-01-18 12:04:27,392:INFO:python_version: 3.11.5
2024-01-18 12:04:27,392:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 12:04:27,392:INFO:machine: AMD64
2024-01-18 12:04:27,392:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 12:04:27,392:INFO:Memory: svmem(total=8361132032, available=2007400448, percent=76.0, used=6353731584, free=2007400448)
2024-01-18 12:04:27,392:INFO:Physical Core: 2
2024-01-18 12:04:27,393:INFO:Logical Core: 4
2024-01-18 12:04:27,393:INFO:Checking libraries
2024-01-18 12:04:27,393:INFO:System:
2024-01-18 12:04:27,393:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 12:04:27,393:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 12:04:27,393:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 12:04:27,393:INFO:PyCaret required dependencies:
2024-01-18 12:04:27,393:INFO:                 pip: 23.2.1
2024-01-18 12:04:27,393:INFO:          setuptools: 68.0.0
2024-01-18 12:04:27,393:INFO:             pycaret: 3.2.0
2024-01-18 12:04:27,393:INFO:             IPython: 8.15.0
2024-01-18 12:04:27,393:INFO:          ipywidgets: 8.0.4
2024-01-18 12:04:27,393:INFO:                tqdm: 4.65.0
2024-01-18 12:04:27,394:INFO:               numpy: 1.24.3
2024-01-18 12:04:27,394:INFO:              pandas: 1.5.3
2024-01-18 12:04:27,394:INFO:              jinja2: 3.1.2
2024-01-18 12:04:27,394:INFO:               scipy: 1.10.1
2024-01-18 12:04:27,394:INFO:              joblib: 1.2.0
2024-01-18 12:04:27,394:INFO:             sklearn: 1.2.2
2024-01-18 12:04:27,394:INFO:                pyod: 1.1.2
2024-01-18 12:04:27,394:INFO:            imblearn: 0.10.1
2024-01-18 12:04:27,394:INFO:   category_encoders: 2.6.3
2024-01-18 12:04:27,394:INFO:            lightgbm: 4.2.0
2024-01-18 12:04:27,394:INFO:               numba: 0.57.1
2024-01-18 12:04:27,394:INFO:            requests: 2.31.0
2024-01-18 12:04:27,394:INFO:          matplotlib: 3.6.0
2024-01-18 12:04:27,394:INFO:          scikitplot: 0.3.7
2024-01-18 12:04:27,394:INFO:         yellowbrick: 1.5
2024-01-18 12:04:27,394:INFO:              plotly: 5.9.0
2024-01-18 12:04:27,394:INFO:    plotly-resampler: Not installed
2024-01-18 12:04:27,394:INFO:             kaleido: 0.2.1
2024-01-18 12:04:27,394:INFO:           schemdraw: 0.15
2024-01-18 12:04:27,394:INFO:         statsmodels: 0.14.0
2024-01-18 12:04:27,394:INFO:              sktime: 0.21.1
2024-01-18 12:04:27,394:INFO:               tbats: 1.1.3
2024-01-18 12:04:27,394:INFO:            pmdarima: 2.0.4
2024-01-18 12:04:27,394:INFO:              psutil: 5.9.0
2024-01-18 12:04:27,395:INFO:          markupsafe: 2.1.1
2024-01-18 12:04:27,395:INFO:             pickle5: Not installed
2024-01-18 12:04:27,395:INFO:         cloudpickle: 2.2.1
2024-01-18 12:04:27,395:INFO:         deprecation: 2.1.0
2024-01-18 12:04:27,395:INFO:              xxhash: 2.0.2
2024-01-18 12:04:27,395:INFO:           wurlitzer: Not installed
2024-01-18 12:04:27,395:INFO:PyCaret optional dependencies:
2024-01-18 12:04:27,395:INFO:                shap: Not installed
2024-01-18 12:04:27,395:INFO:           interpret: Not installed
2024-01-18 12:04:27,395:INFO:                umap: Not installed
2024-01-18 12:04:27,395:INFO:     ydata_profiling: Not installed
2024-01-18 12:04:27,395:INFO:  explainerdashboard: Not installed
2024-01-18 12:04:27,395:INFO:             autoviz: Not installed
2024-01-18 12:04:27,395:INFO:           fairlearn: Not installed
2024-01-18 12:04:27,395:INFO:          deepchecks: Not installed
2024-01-18 12:04:27,395:INFO:             xgboost: 2.0.3
2024-01-18 12:04:27,395:INFO:            catboost: 1.2.2
2024-01-18 12:04:27,395:INFO:              kmodes: Not installed
2024-01-18 12:04:27,395:INFO:             mlxtend: Not installed
2024-01-18 12:04:27,395:INFO:       statsforecast: Not installed
2024-01-18 12:04:27,395:INFO:        tune_sklearn: Not installed
2024-01-18 12:04:27,395:INFO:                 ray: Not installed
2024-01-18 12:04:27,396:INFO:            hyperopt: Not installed
2024-01-18 12:04:27,396:INFO:              optuna: 3.5.0
2024-01-18 12:04:27,396:INFO:               skopt: Not installed
2024-01-18 12:04:27,396:INFO:              mlflow: Not installed
2024-01-18 12:04:27,396:INFO:              gradio: Not installed
2024-01-18 12:04:27,396:INFO:             fastapi: Not installed
2024-01-18 12:04:27,396:INFO:             uvicorn: Not installed
2024-01-18 12:04:27,396:INFO:              m2cgen: Not installed
2024-01-18 12:04:27,396:INFO:           evidently: Not installed
2024-01-18 12:04:27,396:INFO:               fugue: Not installed
2024-01-18 12:04:27,396:INFO:           streamlit: Not installed
2024-01-18 12:04:27,396:INFO:             prophet: Not installed
2024-01-18 12:04:27,396:INFO:None
2024-01-18 12:04:27,396:INFO:Set up data.
2024-01-18 12:04:27,418:INFO:Set up folding strategy.
2024-01-18 12:04:27,418:INFO:Set up train/test split.
2024-01-18 12:04:27,433:INFO:Set up index.
2024-01-18 12:04:27,433:INFO:Assigning column types.
2024-01-18 16:33:59,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 16:33:59,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 16:33:59,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 16:33:59,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 16:39:36,198:INFO:PyCaret ClassificationExperiment
2024-01-18 16:39:36,198:INFO:Logging name: clf-default-name
2024-01-18 16:39:36,198:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 16:39:36,198:INFO:version 3.2.0
2024-01-18 16:39:36,198:INFO:Initializing setup()
2024-01-18 16:39:36,198:INFO:self.USI: 9caa
2024-01-18 16:39:36,198:INFO:self._variable_keys: {'y', 'log_plots_param', 'fold_groups_param', 'fix_imbalance', 'USI', 'X_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'X_train', 'exp_name_log', 'idx', 'y_train', 'X', 'logging_param', 'n_jobs_param', 'pipeline', 'seed', '_available_plots', 'gpu_n_jobs_param', 'y_test', 'data', 'fold_shuffle_param', 'gpu_param', 'memory', 'fold_generator', 'target_param', 'html_param'}
2024-01-18 16:39:36,198:INFO:Checking environment
2024-01-18 16:39:36,198:INFO:python_version: 3.11.5
2024-01-18 16:39:36,198:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 16:39:36,198:INFO:machine: AMD64
2024-01-18 16:39:36,198:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 16:39:36,198:INFO:Memory: svmem(total=8361132032, available=1396310016, percent=83.3, used=6964822016, free=1396310016)
2024-01-18 16:39:36,198:INFO:Physical Core: 2
2024-01-18 16:39:36,198:INFO:Logical Core: 4
2024-01-18 16:39:36,198:INFO:Checking libraries
2024-01-18 16:39:36,198:INFO:System:
2024-01-18 16:39:36,198:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 16:39:36,198:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 16:39:36,198:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 16:39:36,198:INFO:PyCaret required dependencies:
2024-01-18 16:39:36,198:INFO:                 pip: 23.2.1
2024-01-18 16:39:36,198:INFO:          setuptools: 68.0.0
2024-01-18 16:39:36,198:INFO:             pycaret: 3.2.0
2024-01-18 16:39:36,198:INFO:             IPython: 8.15.0
2024-01-18 16:39:36,198:INFO:          ipywidgets: 8.0.4
2024-01-18 16:39:36,198:INFO:                tqdm: 4.65.0
2024-01-18 16:39:36,198:INFO:               numpy: 1.24.3
2024-01-18 16:39:36,198:INFO:              pandas: 1.5.3
2024-01-18 16:39:36,198:INFO:              jinja2: 3.1.2
2024-01-18 16:39:36,198:INFO:               scipy: 1.10.1
2024-01-18 16:39:36,198:INFO:              joblib: 1.2.0
2024-01-18 16:39:36,198:INFO:             sklearn: 1.2.2
2024-01-18 16:39:36,198:INFO:                pyod: 1.1.2
2024-01-18 16:39:36,198:INFO:            imblearn: 0.10.1
2024-01-18 16:39:36,198:INFO:   category_encoders: 2.6.3
2024-01-18 16:39:36,198:INFO:            lightgbm: 4.2.0
2024-01-18 16:39:36,198:INFO:               numba: 0.57.1
2024-01-18 16:39:36,198:INFO:            requests: 2.31.0
2024-01-18 16:39:36,198:INFO:          matplotlib: 3.6.0
2024-01-18 16:39:36,198:INFO:          scikitplot: 0.3.7
2024-01-18 16:39:36,198:INFO:         yellowbrick: 1.5
2024-01-18 16:39:36,198:INFO:              plotly: 5.9.0
2024-01-18 16:39:36,198:INFO:    plotly-resampler: Not installed
2024-01-18 16:39:36,198:INFO:             kaleido: 0.2.1
2024-01-18 16:39:36,198:INFO:           schemdraw: 0.15
2024-01-18 16:39:36,198:INFO:         statsmodels: 0.14.0
2024-01-18 16:39:36,198:INFO:              sktime: 0.21.1
2024-01-18 16:39:36,198:INFO:               tbats: 1.1.3
2024-01-18 16:39:36,198:INFO:            pmdarima: 2.0.4
2024-01-18 16:39:36,198:INFO:              psutil: 5.9.0
2024-01-18 16:39:36,198:INFO:          markupsafe: 2.1.1
2024-01-18 16:39:36,198:INFO:             pickle5: Not installed
2024-01-18 16:39:36,198:INFO:         cloudpickle: 2.2.1
2024-01-18 16:39:36,198:INFO:         deprecation: 2.1.0
2024-01-18 16:39:36,198:INFO:              xxhash: 2.0.2
2024-01-18 16:39:36,198:INFO:           wurlitzer: Not installed
2024-01-18 16:39:36,198:INFO:PyCaret optional dependencies:
2024-01-18 16:39:36,244:INFO:                shap: Not installed
2024-01-18 16:39:36,244:INFO:           interpret: Not installed
2024-01-18 16:39:36,244:INFO:                umap: Not installed
2024-01-18 16:39:36,244:INFO:     ydata_profiling: Not installed
2024-01-18 16:39:36,244:INFO:  explainerdashboard: Not installed
2024-01-18 16:39:36,244:INFO:             autoviz: Not installed
2024-01-18 16:39:36,244:INFO:           fairlearn: Not installed
2024-01-18 16:39:36,244:INFO:          deepchecks: Not installed
2024-01-18 16:39:36,244:INFO:             xgboost: 2.0.3
2024-01-18 16:39:36,244:INFO:            catboost: 1.2.2
2024-01-18 16:39:36,244:INFO:              kmodes: Not installed
2024-01-18 16:39:36,244:INFO:             mlxtend: Not installed
2024-01-18 16:39:36,244:INFO:       statsforecast: Not installed
2024-01-18 16:39:36,244:INFO:        tune_sklearn: Not installed
2024-01-18 16:39:36,244:INFO:                 ray: Not installed
2024-01-18 16:39:36,244:INFO:            hyperopt: Not installed
2024-01-18 16:39:36,244:INFO:              optuna: 3.5.0
2024-01-18 16:39:36,244:INFO:               skopt: Not installed
2024-01-18 16:39:36,244:INFO:              mlflow: Not installed
2024-01-18 16:39:36,244:INFO:              gradio: Not installed
2024-01-18 16:39:36,244:INFO:             fastapi: Not installed
2024-01-18 16:39:36,244:INFO:             uvicorn: Not installed
2024-01-18 16:39:36,244:INFO:              m2cgen: Not installed
2024-01-18 16:39:36,244:INFO:           evidently: Not installed
2024-01-18 16:39:36,244:INFO:               fugue: Not installed
2024-01-18 16:39:36,244:INFO:           streamlit: Not installed
2024-01-18 16:39:36,244:INFO:             prophet: Not installed
2024-01-18 16:39:36,244:INFO:None
2024-01-18 16:39:36,244:INFO:Set up data.
2024-01-18 16:39:36,323:INFO:Set up folding strategy.
2024-01-18 16:39:36,323:INFO:Set up train/test split.
2024-01-18 16:39:36,417:INFO:Set up index.
2024-01-18 16:39:36,464:INFO:Assigning column types.
2024-01-18 16:39:36,464:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 16:39:36,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:39:36,559:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:39:36,716:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:36,716:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:36,851:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:39:36,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:39:36,884:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:36,884:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:36,884:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 16:39:36,966:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:39:36,998:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:36,998:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:37,070:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:39:37,109:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:37,111:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:37,112:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 16:39:37,222:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:37,225:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:37,328:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:37,328:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:37,357:INFO:Preparing preprocessing pipeline...
2024-01-18 16:39:37,380:INFO:Set up simple imputation.
2024-01-18 16:39:37,396:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\preprocess\preprocessor.py:653: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.
  for name, column in X_transformed[self._fxs["Categorical"]].items():

2024-01-18 16:39:37,411:INFO:Set up encoding of ordinal features.
2024-01-18 16:39:37,427:INFO:Set up encoding of categorical features.
2024-01-18 16:39:37,442:INFO:Set up column name cleaning.
2024-01-18 16:39:37,747:INFO:Finished creating preprocessing pipeline.
2024-01-18 16:39:37,923:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -0.316951    0
 3.155058    1
 NaN        -1
dtype: int64},
                                                                        {'col': 'Destination_TRAPPIST-1e',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -1.546237    0
 0.646731    1
 NaN        -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 16:39:37,923:INFO:Creating final display dataframe.
2024-01-18 16:39:38,332:INFO:Setup _display_container:                     Description             Value
0                    Session id              6632
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Ordinal features                 8
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              9caa
2024-01-18 16:39:38,464:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:38,465:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:38,580:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:38,580:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:38,580:INFO:setup() successfully completed in 2.85s...............
2024-01-18 16:39:51,697:INFO:PyCaret ClassificationExperiment
2024-01-18 16:39:51,697:INFO:Logging name: clf-default-name
2024-01-18 16:39:51,697:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 16:39:51,697:INFO:version 3.2.0
2024-01-18 16:39:51,697:INFO:Initializing setup()
2024-01-18 16:39:51,697:INFO:self.USI: 5e5b
2024-01-18 16:39:51,697:INFO:self._variable_keys: {'y', 'log_plots_param', 'fold_groups_param', 'fix_imbalance', 'USI', 'X_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'X_train', 'exp_name_log', 'idx', 'y_train', 'X', 'logging_param', 'n_jobs_param', 'pipeline', 'seed', '_available_plots', 'gpu_n_jobs_param', 'y_test', 'data', 'fold_shuffle_param', 'gpu_param', 'memory', 'fold_generator', 'target_param', 'html_param'}
2024-01-18 16:39:51,697:INFO:Checking environment
2024-01-18 16:39:51,697:INFO:python_version: 3.11.5
2024-01-18 16:39:51,697:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 16:39:51,697:INFO:machine: AMD64
2024-01-18 16:39:51,697:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 16:39:51,698:INFO:Memory: svmem(total=8361132032, available=1678209024, percent=79.9, used=6682923008, free=1678209024)
2024-01-18 16:39:51,698:INFO:Physical Core: 2
2024-01-18 16:39:51,698:INFO:Logical Core: 4
2024-01-18 16:39:51,698:INFO:Checking libraries
2024-01-18 16:39:51,698:INFO:System:
2024-01-18 16:39:51,698:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 16:39:51,698:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 16:39:51,698:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 16:39:51,698:INFO:PyCaret required dependencies:
2024-01-18 16:39:51,698:INFO:                 pip: 23.2.1
2024-01-18 16:39:51,698:INFO:          setuptools: 68.0.0
2024-01-18 16:39:51,698:INFO:             pycaret: 3.2.0
2024-01-18 16:39:51,698:INFO:             IPython: 8.15.0
2024-01-18 16:39:51,699:INFO:          ipywidgets: 8.0.4
2024-01-18 16:39:51,699:INFO:                tqdm: 4.65.0
2024-01-18 16:39:51,699:INFO:               numpy: 1.24.3
2024-01-18 16:39:51,699:INFO:              pandas: 1.5.3
2024-01-18 16:39:51,699:INFO:              jinja2: 3.1.2
2024-01-18 16:39:51,699:INFO:               scipy: 1.10.1
2024-01-18 16:39:51,699:INFO:              joblib: 1.2.0
2024-01-18 16:39:51,699:INFO:             sklearn: 1.2.2
2024-01-18 16:39:51,699:INFO:                pyod: 1.1.2
2024-01-18 16:39:51,699:INFO:            imblearn: 0.10.1
2024-01-18 16:39:51,699:INFO:   category_encoders: 2.6.3
2024-01-18 16:39:51,699:INFO:            lightgbm: 4.2.0
2024-01-18 16:39:51,699:INFO:               numba: 0.57.1
2024-01-18 16:39:51,700:INFO:            requests: 2.31.0
2024-01-18 16:39:51,700:INFO:          matplotlib: 3.6.0
2024-01-18 16:39:51,700:INFO:          scikitplot: 0.3.7
2024-01-18 16:39:51,700:INFO:         yellowbrick: 1.5
2024-01-18 16:39:51,700:INFO:              plotly: 5.9.0
2024-01-18 16:39:51,700:INFO:    plotly-resampler: Not installed
2024-01-18 16:39:51,700:INFO:             kaleido: 0.2.1
2024-01-18 16:39:51,700:INFO:           schemdraw: 0.15
2024-01-18 16:39:51,700:INFO:         statsmodels: 0.14.0
2024-01-18 16:39:51,701:INFO:              sktime: 0.21.1
2024-01-18 16:39:51,701:INFO:               tbats: 1.1.3
2024-01-18 16:39:51,701:INFO:            pmdarima: 2.0.4
2024-01-18 16:39:51,701:INFO:              psutil: 5.9.0
2024-01-18 16:39:51,701:INFO:          markupsafe: 2.1.1
2024-01-18 16:39:51,701:INFO:             pickle5: Not installed
2024-01-18 16:39:51,701:INFO:         cloudpickle: 2.2.1
2024-01-18 16:39:51,701:INFO:         deprecation: 2.1.0
2024-01-18 16:39:51,701:INFO:              xxhash: 2.0.2
2024-01-18 16:39:51,701:INFO:           wurlitzer: Not installed
2024-01-18 16:39:51,701:INFO:PyCaret optional dependencies:
2024-01-18 16:39:51,701:INFO:                shap: Not installed
2024-01-18 16:39:51,701:INFO:           interpret: Not installed
2024-01-18 16:39:51,701:INFO:                umap: Not installed
2024-01-18 16:39:51,701:INFO:     ydata_profiling: Not installed
2024-01-18 16:39:51,702:INFO:  explainerdashboard: Not installed
2024-01-18 16:39:51,702:INFO:             autoviz: Not installed
2024-01-18 16:39:51,702:INFO:           fairlearn: Not installed
2024-01-18 16:39:51,702:INFO:          deepchecks: Not installed
2024-01-18 16:39:51,702:INFO:             xgboost: 2.0.3
2024-01-18 16:39:51,702:INFO:            catboost: 1.2.2
2024-01-18 16:39:51,702:INFO:              kmodes: Not installed
2024-01-18 16:39:51,702:INFO:             mlxtend: Not installed
2024-01-18 16:39:51,702:INFO:       statsforecast: Not installed
2024-01-18 16:39:51,702:INFO:        tune_sklearn: Not installed
2024-01-18 16:39:51,702:INFO:                 ray: Not installed
2024-01-18 16:39:51,702:INFO:            hyperopt: Not installed
2024-01-18 16:39:51,702:INFO:              optuna: 3.5.0
2024-01-18 16:39:51,702:INFO:               skopt: Not installed
2024-01-18 16:39:51,703:INFO:              mlflow: Not installed
2024-01-18 16:39:51,703:INFO:              gradio: Not installed
2024-01-18 16:39:51,703:INFO:             fastapi: Not installed
2024-01-18 16:39:51,703:INFO:             uvicorn: Not installed
2024-01-18 16:39:51,703:INFO:              m2cgen: Not installed
2024-01-18 16:39:51,703:INFO:           evidently: Not installed
2024-01-18 16:39:51,703:INFO:               fugue: Not installed
2024-01-18 16:39:51,703:INFO:           streamlit: Not installed
2024-01-18 16:39:51,703:INFO:             prophet: Not installed
2024-01-18 16:39:51,703:INFO:None
2024-01-18 16:39:51,703:INFO:Set up data.
2024-01-18 16:39:51,713:INFO:Set up folding strategy.
2024-01-18 16:39:51,713:INFO:Set up train/test split.
2024-01-18 16:39:51,721:INFO:Set up index.
2024-01-18 16:39:51,721:INFO:Assigning column types.
2024-01-18 16:39:51,731:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 16:39:51,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:39:51,796:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:39:51,828:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:51,828:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:51,927:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:39:51,927:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:39:51,959:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:51,974:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:51,974:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 16:39:52,021:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:39:52,052:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:52,052:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:52,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:39:52,132:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:52,193:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:52,193:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 16:39:52,353:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:52,371:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:52,491:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:52,491:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:52,491:INFO:Preparing preprocessing pipeline...
2024-01-18 16:39:52,491:INFO:Set up simple imputation.
2024-01-18 16:39:52,491:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\preprocess\preprocessor.py:653: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.
  for name, column in X_transformed[self._fxs["Categorical"]].items():

2024-01-18 16:39:52,491:INFO:Set up encoding of ordinal features.
2024-01-18 16:39:52,507:INFO:Set up encoding of categorical features.
2024-01-18 16:39:52,507:INFO:Set up column name cleaning.
2024-01-18 16:39:52,602:INFO:Finished creating preprocessing pipeline.
2024-01-18 16:39:52,711:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -0.316951    0
 3.155058    1
 NaN        -1
dtype: int64},
                                                                        {'col': 'Destination_TRAPPIST-1e',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -1.546237    0
 0.646731    1
 NaN        -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 16:39:52,711:INFO:Creating final display dataframe.
2024-01-18 16:39:52,953:INFO:Setup _display_container:                     Description             Value
0                    Session id              4811
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Ordinal features                 8
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              5e5b
2024-01-18 16:39:53,065:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:53,065:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:53,181:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:39:53,181:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:39:53,181:INFO:setup() successfully completed in 1.49s...............
2024-01-18 16:39:55,023:INFO:Initializing compare_models()
2024-01-18 16:39:55,023:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-18 16:39:55,024:INFO:Checking exceptions
2024-01-18 16:39:55,089:INFO:Preparing display monitor
2024-01-18 16:39:55,156:INFO:Initializing Logistic Regression
2024-01-18 16:39:55,156:INFO:Total runtime is 0.0 minutes
2024-01-18 16:39:55,162:INFO:SubProcess create_model() called ==================================
2024-01-18 16:39:55,163:INFO:Initializing create_model()
2024-01-18 16:39:55,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:39:55,163:INFO:Checking exceptions
2024-01-18 16:39:55,163:INFO:Importing libraries
2024-01-18 16:39:55,163:INFO:Copying training dataset
2024-01-18 16:39:55,173:INFO:Defining folds
2024-01-18 16:39:55,173:INFO:Declaring metric variables
2024-01-18 16:39:55,179:INFO:Importing untrained model
2024-01-18 16:39:55,183:INFO:Logistic Regression Imported successfully
2024-01-18 16:39:55,191:INFO:Starting cross validation
2024-01-18 16:39:55,193:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:09,643:INFO:Calculating mean and std
2024-01-18 16:40:09,643:INFO:Creating metrics dataframe
2024-01-18 16:40:09,674:INFO:Uploading results into container
2024-01-18 16:40:09,674:INFO:Uploading model into container now
2024-01-18 16:40:09,674:INFO:_master_model_container: 1
2024-01-18 16:40:09,674:INFO:_display_container: 2
2024-01-18 16:40:09,674:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4811, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-18 16:40:09,674:INFO:create_model() successfully completed......................................
2024-01-18 16:40:09,806:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:09,806:INFO:Creating metrics dataframe
2024-01-18 16:40:09,823:INFO:Initializing K Neighbors Classifier
2024-01-18 16:40:09,823:INFO:Total runtime is 0.2444446365038554 minutes
2024-01-18 16:40:09,823:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:09,831:INFO:Initializing create_model()
2024-01-18 16:40:09,832:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:09,832:INFO:Checking exceptions
2024-01-18 16:40:09,832:INFO:Importing libraries
2024-01-18 16:40:09,832:INFO:Copying training dataset
2024-01-18 16:40:09,841:INFO:Defining folds
2024-01-18 16:40:09,841:INFO:Declaring metric variables
2024-01-18 16:40:09,846:INFO:Importing untrained model
2024-01-18 16:40:09,850:INFO:K Neighbors Classifier Imported successfully
2024-01-18 16:40:09,858:INFO:Starting cross validation
2024-01-18 16:40:09,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:11,149:INFO:Calculating mean and std
2024-01-18 16:40:11,149:INFO:Creating metrics dataframe
2024-01-18 16:40:11,166:INFO:Uploading results into container
2024-01-18 16:40:11,166:INFO:Uploading model into container now
2024-01-18 16:40:11,166:INFO:_master_model_container: 2
2024-01-18 16:40:11,166:INFO:_display_container: 2
2024-01-18 16:40:11,166:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-18 16:40:11,166:INFO:create_model() successfully completed......................................
2024-01-18 16:40:11,295:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:11,295:INFO:Creating metrics dataframe
2024-01-18 16:40:11,314:INFO:Initializing Naive Bayes
2024-01-18 16:40:11,314:INFO:Total runtime is 0.2693026820818583 minutes
2024-01-18 16:40:11,316:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:11,316:INFO:Initializing create_model()
2024-01-18 16:40:11,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:11,316:INFO:Checking exceptions
2024-01-18 16:40:11,316:INFO:Importing libraries
2024-01-18 16:40:11,316:INFO:Copying training dataset
2024-01-18 16:40:11,330:INFO:Defining folds
2024-01-18 16:40:11,330:INFO:Declaring metric variables
2024-01-18 16:40:11,335:INFO:Importing untrained model
2024-01-18 16:40:11,341:INFO:Naive Bayes Imported successfully
2024-01-18 16:40:11,351:INFO:Starting cross validation
2024-01-18 16:40:11,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:12,200:INFO:Calculating mean and std
2024-01-18 16:40:12,206:INFO:Creating metrics dataframe
2024-01-18 16:40:12,215:INFO:Uploading results into container
2024-01-18 16:40:12,216:INFO:Uploading model into container now
2024-01-18 16:40:12,217:INFO:_master_model_container: 3
2024-01-18 16:40:12,218:INFO:_display_container: 2
2024-01-18 16:40:12,218:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-18 16:40:12,218:INFO:create_model() successfully completed......................................
2024-01-18 16:40:12,332:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:12,332:INFO:Creating metrics dataframe
2024-01-18 16:40:12,363:INFO:Initializing Decision Tree Classifier
2024-01-18 16:40:12,364:INFO:Total runtime is 0.28679596185684203 minutes
2024-01-18 16:40:12,364:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:12,364:INFO:Initializing create_model()
2024-01-18 16:40:12,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:12,370:INFO:Checking exceptions
2024-01-18 16:40:12,370:INFO:Importing libraries
2024-01-18 16:40:12,370:INFO:Copying training dataset
2024-01-18 16:40:12,370:INFO:Defining folds
2024-01-18 16:40:12,370:INFO:Declaring metric variables
2024-01-18 16:40:12,385:INFO:Importing untrained model
2024-01-18 16:40:12,393:INFO:Decision Tree Classifier Imported successfully
2024-01-18 16:40:12,402:INFO:Starting cross validation
2024-01-18 16:40:12,404:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:13,554:INFO:Calculating mean and std
2024-01-18 16:40:13,554:INFO:Creating metrics dataframe
2024-01-18 16:40:13,554:INFO:Uploading results into container
2024-01-18 16:40:13,554:INFO:Uploading model into container now
2024-01-18 16:40:13,554:INFO:_master_model_container: 4
2024-01-18 16:40:13,554:INFO:_display_container: 2
2024-01-18 16:40:13,569:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4811, splitter='best')
2024-01-18 16:40:13,569:INFO:create_model() successfully completed......................................
2024-01-18 16:40:13,659:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:13,659:INFO:Creating metrics dataframe
2024-01-18 16:40:13,675:INFO:Initializing SVM - Linear Kernel
2024-01-18 16:40:13,675:INFO:Total runtime is 0.3086418072382609 minutes
2024-01-18 16:40:13,686:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:13,686:INFO:Initializing create_model()
2024-01-18 16:40:13,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:13,686:INFO:Checking exceptions
2024-01-18 16:40:13,687:INFO:Importing libraries
2024-01-18 16:40:13,687:INFO:Copying training dataset
2024-01-18 16:40:13,696:INFO:Defining folds
2024-01-18 16:40:13,696:INFO:Declaring metric variables
2024-01-18 16:40:13,701:INFO:Importing untrained model
2024-01-18 16:40:13,705:INFO:SVM - Linear Kernel Imported successfully
2024-01-18 16:40:13,720:INFO:Starting cross validation
2024-01-18 16:40:13,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:14,846:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:40:14,847:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:40:14,847:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:40:15,208:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:40:15,225:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:40:15,228:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:40:15,229:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:40:15,472:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:40:15,972:INFO:Calculating mean and std
2024-01-18 16:40:15,972:INFO:Creating metrics dataframe
2024-01-18 16:40:15,972:INFO:Uploading results into container
2024-01-18 16:40:15,972:INFO:Uploading model into container now
2024-01-18 16:40:15,972:INFO:_master_model_container: 5
2024-01-18 16:40:15,972:INFO:_display_container: 2
2024-01-18 16:40:15,984:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4811, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-18 16:40:15,984:INFO:create_model() successfully completed......................................
2024-01-18 16:40:16,091:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:16,091:INFO:Creating metrics dataframe
2024-01-18 16:40:16,107:INFO:Initializing Ridge Classifier
2024-01-18 16:40:16,107:INFO:Total runtime is 0.34918309052785235 minutes
2024-01-18 16:40:16,117:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:16,117:INFO:Initializing create_model()
2024-01-18 16:40:16,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:16,117:INFO:Checking exceptions
2024-01-18 16:40:16,118:INFO:Importing libraries
2024-01-18 16:40:16,118:INFO:Copying training dataset
2024-01-18 16:40:16,125:INFO:Defining folds
2024-01-18 16:40:16,125:INFO:Declaring metric variables
2024-01-18 16:40:16,130:INFO:Importing untrained model
2024-01-18 16:40:16,135:INFO:Ridge Classifier Imported successfully
2024-01-18 16:40:16,147:INFO:Starting cross validation
2024-01-18 16:40:16,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:17,022:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,038:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,053:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,053:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,285:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,323:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,344:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,359:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,517:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,532:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:40:17,548:INFO:Calculating mean and std
2024-01-18 16:40:17,548:INFO:Creating metrics dataframe
2024-01-18 16:40:17,561:INFO:Uploading results into container
2024-01-18 16:40:17,562:INFO:Uploading model into container now
2024-01-18 16:40:17,562:INFO:_master_model_container: 6
2024-01-18 16:40:17,562:INFO:_display_container: 2
2024-01-18 16:40:17,563:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4811, solver='auto',
                tol=0.0001)
2024-01-18 16:40:17,563:INFO:create_model() successfully completed......................................
2024-01-18 16:40:17,676:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:17,676:INFO:Creating metrics dataframe
2024-01-18 16:40:17,676:INFO:Initializing Random Forest Classifier
2024-01-18 16:40:17,676:INFO:Total runtime is 0.3753325819969177 minutes
2024-01-18 16:40:17,676:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:17,676:INFO:Initializing create_model()
2024-01-18 16:40:17,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:17,676:INFO:Checking exceptions
2024-01-18 16:40:17,692:INFO:Importing libraries
2024-01-18 16:40:17,692:INFO:Copying training dataset
2024-01-18 16:40:17,698:INFO:Defining folds
2024-01-18 16:40:17,699:INFO:Declaring metric variables
2024-01-18 16:40:17,704:INFO:Importing untrained model
2024-01-18 16:40:17,712:INFO:Random Forest Classifier Imported successfully
2024-01-18 16:40:17,721:INFO:Starting cross validation
2024-01-18 16:40:17,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:21,470:INFO:Calculating mean and std
2024-01-18 16:40:21,470:INFO:Creating metrics dataframe
2024-01-18 16:40:21,480:INFO:Uploading results into container
2024-01-18 16:40:21,481:INFO:Uploading model into container now
2024-01-18 16:40:21,482:INFO:_master_model_container: 7
2024-01-18 16:40:21,482:INFO:_display_container: 2
2024-01-18 16:40:21,483:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4811, verbose=0, warm_start=False)
2024-01-18 16:40:21,483:INFO:create_model() successfully completed......................................
2024-01-18 16:40:21,599:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:21,599:INFO:Creating metrics dataframe
2024-01-18 16:40:21,619:INFO:Initializing Quadratic Discriminant Analysis
2024-01-18 16:40:21,620:INFO:Total runtime is 0.44106462796529133 minutes
2024-01-18 16:40:21,625:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:21,625:INFO:Initializing create_model()
2024-01-18 16:40:21,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:21,625:INFO:Checking exceptions
2024-01-18 16:40:21,626:INFO:Importing libraries
2024-01-18 16:40:21,626:INFO:Copying training dataset
2024-01-18 16:40:21,631:INFO:Defining folds
2024-01-18 16:40:21,632:INFO:Declaring metric variables
2024-01-18 16:40:21,636:INFO:Importing untrained model
2024-01-18 16:40:21,642:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-18 16:40:21,652:INFO:Starting cross validation
2024-01-18 16:40:21,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:22,371:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:40:22,371:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:40:22,687:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:40:22,705:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:40:22,705:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:40:22,718:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:40:22,873:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:40:22,907:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:40:22,967:INFO:Calculating mean and std
2024-01-18 16:40:22,967:INFO:Creating metrics dataframe
2024-01-18 16:40:22,967:INFO:Uploading results into container
2024-01-18 16:40:22,967:INFO:Uploading model into container now
2024-01-18 16:40:22,967:INFO:_master_model_container: 8
2024-01-18 16:40:22,967:INFO:_display_container: 2
2024-01-18 16:40:22,967:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-18 16:40:22,967:INFO:create_model() successfully completed......................................
2024-01-18 16:40:23,110:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:23,111:INFO:Creating metrics dataframe
2024-01-18 16:40:23,127:INFO:Initializing Ada Boost Classifier
2024-01-18 16:40:23,128:INFO:Total runtime is 0.46620012521743776 minutes
2024-01-18 16:40:23,143:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:23,147:INFO:Initializing create_model()
2024-01-18 16:40:23,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:23,148:INFO:Checking exceptions
2024-01-18 16:40:23,148:INFO:Importing libraries
2024-01-18 16:40:23,148:INFO:Copying training dataset
2024-01-18 16:40:23,164:INFO:Defining folds
2024-01-18 16:40:23,164:INFO:Declaring metric variables
2024-01-18 16:40:23,171:INFO:Importing untrained model
2024-01-18 16:40:23,179:INFO:Ada Boost Classifier Imported successfully
2024-01-18 16:40:23,196:INFO:Starting cross validation
2024-01-18 16:40:23,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:25,099:INFO:Calculating mean and std
2024-01-18 16:40:25,099:INFO:Creating metrics dataframe
2024-01-18 16:40:25,099:INFO:Uploading results into container
2024-01-18 16:40:25,112:INFO:Uploading model into container now
2024-01-18 16:40:25,112:INFO:_master_model_container: 9
2024-01-18 16:40:25,112:INFO:_display_container: 2
2024-01-18 16:40:25,113:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=4811)
2024-01-18 16:40:25,113:INFO:create_model() successfully completed......................................
2024-01-18 16:40:25,228:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:25,228:INFO:Creating metrics dataframe
2024-01-18 16:40:25,262:INFO:Initializing Gradient Boosting Classifier
2024-01-18 16:40:25,262:INFO:Total runtime is 0.5017694155375163 minutes
2024-01-18 16:40:25,266:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:25,268:INFO:Initializing create_model()
2024-01-18 16:40:25,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:25,269:INFO:Checking exceptions
2024-01-18 16:40:25,270:INFO:Importing libraries
2024-01-18 16:40:25,270:INFO:Copying training dataset
2024-01-18 16:40:25,279:INFO:Defining folds
2024-01-18 16:40:25,279:INFO:Declaring metric variables
2024-01-18 16:40:25,284:INFO:Importing untrained model
2024-01-18 16:40:25,289:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 16:40:25,296:INFO:Starting cross validation
2024-01-18 16:40:25,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:29,274:INFO:Calculating mean and std
2024-01-18 16:40:29,275:INFO:Creating metrics dataframe
2024-01-18 16:40:29,281:INFO:Uploading results into container
2024-01-18 16:40:29,285:INFO:Uploading model into container now
2024-01-18 16:40:29,285:INFO:_master_model_container: 10
2024-01-18 16:40:29,285:INFO:_display_container: 2
2024-01-18 16:40:29,285:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4811, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 16:40:29,285:INFO:create_model() successfully completed......................................
2024-01-18 16:40:29,413:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:29,413:INFO:Creating metrics dataframe
2024-01-18 16:40:29,431:INFO:Initializing Linear Discriminant Analysis
2024-01-18 16:40:29,431:INFO:Total runtime is 0.5712554057439169 minutes
2024-01-18 16:40:29,450:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:29,451:INFO:Initializing create_model()
2024-01-18 16:40:29,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:29,451:INFO:Checking exceptions
2024-01-18 16:40:29,451:INFO:Importing libraries
2024-01-18 16:40:29,451:INFO:Copying training dataset
2024-01-18 16:40:29,461:INFO:Defining folds
2024-01-18 16:40:29,461:INFO:Declaring metric variables
2024-01-18 16:40:29,466:INFO:Importing untrained model
2024-01-18 16:40:29,471:INFO:Linear Discriminant Analysis Imported successfully
2024-01-18 16:40:29,481:INFO:Starting cross validation
2024-01-18 16:40:29,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:32,845:INFO:Calculating mean and std
2024-01-18 16:40:32,845:INFO:Creating metrics dataframe
2024-01-18 16:40:32,845:INFO:Uploading results into container
2024-01-18 16:40:32,845:INFO:Uploading model into container now
2024-01-18 16:40:32,845:INFO:_master_model_container: 11
2024-01-18 16:40:32,845:INFO:_display_container: 2
2024-01-18 16:40:32,845:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-18 16:40:32,845:INFO:create_model() successfully completed......................................
2024-01-18 16:40:32,970:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:32,970:INFO:Creating metrics dataframe
2024-01-18 16:40:32,991:INFO:Initializing Extra Trees Classifier
2024-01-18 16:40:32,991:INFO:Total runtime is 0.6305788516998292 minutes
2024-01-18 16:40:32,996:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:32,996:INFO:Initializing create_model()
2024-01-18 16:40:32,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:32,996:INFO:Checking exceptions
2024-01-18 16:40:32,996:INFO:Importing libraries
2024-01-18 16:40:32,996:INFO:Copying training dataset
2024-01-18 16:40:32,999:INFO:Defining folds
2024-01-18 16:40:32,999:INFO:Declaring metric variables
2024-01-18 16:40:33,012:INFO:Importing untrained model
2024-01-18 16:40:33,019:INFO:Extra Trees Classifier Imported successfully
2024-01-18 16:40:33,029:INFO:Starting cross validation
2024-01-18 16:40:33,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:36,691:INFO:Calculating mean and std
2024-01-18 16:40:36,691:INFO:Creating metrics dataframe
2024-01-18 16:40:36,711:INFO:Uploading results into container
2024-01-18 16:40:36,712:INFO:Uploading model into container now
2024-01-18 16:40:36,714:INFO:_master_model_container: 12
2024-01-18 16:40:36,714:INFO:_display_container: 2
2024-01-18 16:40:36,715:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4811, verbose=0, warm_start=False)
2024-01-18 16:40:36,715:INFO:create_model() successfully completed......................................
2024-01-18 16:40:36,841:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:36,841:INFO:Creating metrics dataframe
2024-01-18 16:40:36,856:INFO:Initializing Extreme Gradient Boosting
2024-01-18 16:40:36,856:INFO:Total runtime is 0.6950050195058188 minutes
2024-01-18 16:40:36,874:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:36,875:INFO:Initializing create_model()
2024-01-18 16:40:36,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:36,875:INFO:Checking exceptions
2024-01-18 16:40:36,875:INFO:Importing libraries
2024-01-18 16:40:36,875:INFO:Copying training dataset
2024-01-18 16:40:36,883:INFO:Defining folds
2024-01-18 16:40:36,883:INFO:Declaring metric variables
2024-01-18 16:40:36,889:INFO:Importing untrained model
2024-01-18 16:40:36,895:INFO:Extreme Gradient Boosting Imported successfully
2024-01-18 16:40:36,905:INFO:Starting cross validation
2024-01-18 16:40:36,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:39,041:INFO:Calculating mean and std
2024-01-18 16:40:39,041:INFO:Creating metrics dataframe
2024-01-18 16:40:39,041:INFO:Uploading results into container
2024-01-18 16:40:39,041:INFO:Uploading model into container now
2024-01-18 16:40:39,041:INFO:_master_model_container: 13
2024-01-18 16:40:39,041:INFO:_display_container: 2
2024-01-18 16:40:39,056:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-18 16:40:39,056:INFO:create_model() successfully completed......................................
2024-01-18 16:40:39,175:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:39,175:INFO:Creating metrics dataframe
2024-01-18 16:40:39,191:INFO:Initializing Light Gradient Boosting Machine
2024-01-18 16:40:39,191:INFO:Total runtime is 0.7339121182759605 minutes
2024-01-18 16:40:39,191:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:39,191:INFO:Initializing create_model()
2024-01-18 16:40:39,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:39,191:INFO:Checking exceptions
2024-01-18 16:40:39,191:INFO:Importing libraries
2024-01-18 16:40:39,191:INFO:Copying training dataset
2024-01-18 16:40:39,208:INFO:Defining folds
2024-01-18 16:40:39,208:INFO:Declaring metric variables
2024-01-18 16:40:39,214:INFO:Importing untrained model
2024-01-18 16:40:39,219:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 16:40:39,230:INFO:Starting cross validation
2024-01-18 16:40:39,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:40:41,841:INFO:Calculating mean and std
2024-01-18 16:40:41,841:INFO:Creating metrics dataframe
2024-01-18 16:40:41,841:INFO:Uploading results into container
2024-01-18 16:40:41,841:INFO:Uploading model into container now
2024-01-18 16:40:41,841:INFO:_master_model_container: 14
2024-01-18 16:40:41,841:INFO:_display_container: 2
2024-01-18 16:40:41,841:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4811, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:40:41,841:INFO:create_model() successfully completed......................................
2024-01-18 16:40:41,959:INFO:SubProcess create_model() end ==================================
2024-01-18 16:40:41,959:INFO:Creating metrics dataframe
2024-01-18 16:40:41,974:INFO:Initializing CatBoost Classifier
2024-01-18 16:40:41,974:INFO:Total runtime is 0.7803083022435509 minutes
2024-01-18 16:40:41,983:INFO:SubProcess create_model() called ==================================
2024-01-18 16:40:41,983:INFO:Initializing create_model()
2024-01-18 16:40:41,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:40:41,984:INFO:Checking exceptions
2024-01-18 16:40:41,984:INFO:Importing libraries
2024-01-18 16:40:41,984:INFO:Copying training dataset
2024-01-18 16:40:41,989:INFO:Defining folds
2024-01-18 16:40:41,990:INFO:Declaring metric variables
2024-01-18 16:40:41,994:INFO:Importing untrained model
2024-01-18 16:40:41,999:INFO:CatBoost Classifier Imported successfully
2024-01-18 16:40:42,009:INFO:Starting cross validation
2024-01-18 16:40:42,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

tion.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:05,470:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,392:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,392:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,392:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,398:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,424:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,424:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,424:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,424:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,424:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:15,424:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:41:20,906:INFO:Calculating mean and std
2024-01-18 16:41:20,906:INFO:Creating metrics dataframe
2024-01-18 16:41:20,906:INFO:Uploading results into container
2024-01-18 16:41:20,906:INFO:Uploading model into container now
2024-01-18 16:41:20,906:INFO:_master_model_container: 15
2024-01-18 16:41:20,906:INFO:_display_container: 2
2024-01-18 16:41:20,906:INFO:<catboost.core.CatBoostClassifier object at 0x000001EFC380E210>
2024-01-18 16:41:20,906:INFO:create_model() successfully completed......................................
2024-01-18 16:41:21,039:INFO:SubProcess create_model() end ==================================
2024-01-18 16:41:21,039:INFO:Creating metrics dataframe
2024-01-18 16:41:21,068:INFO:Initializing Dummy Classifier
2024-01-18 16:41:21,068:INFO:Total runtime is 1.4318689743677777 minutes
2024-01-18 16:41:21,071:INFO:SubProcess create_model() called ==================================
2024-01-18 16:41:21,072:INFO:Initializing create_model()
2024-01-18 16:41:21,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC39B6F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:41:21,072:INFO:Checking exceptions
2024-01-18 16:41:21,072:INFO:Importing libraries
2024-01-18 16:41:21,072:INFO:Copying training dataset
2024-01-18 16:41:21,078:INFO:Defining folds
2024-01-18 16:41:21,078:INFO:Declaring metric variables
2024-01-18 16:41:21,082:INFO:Importing untrained model
2024-01-18 16:41:21,087:INFO:Dummy Classifier Imported successfully
2024-01-18 16:41:21,094:INFO:Starting cross validation
2024-01-18 16:41:21,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:41:21,782:INFO:Calculating mean and std
2024-01-18 16:41:21,782:INFO:Creating metrics dataframe
2024-01-18 16:41:21,797:INFO:Uploading results into container
2024-01-18 16:41:21,797:INFO:Uploading model into container now
2024-01-18 16:41:21,797:INFO:_master_model_container: 16
2024-01-18 16:41:21,797:INFO:_display_container: 2
2024-01-18 16:41:21,800:INFO:DummyClassifier(constant=None, random_state=4811, strategy='prior')
2024-01-18 16:41:21,800:INFO:create_model() successfully completed......................................
2024-01-18 16:41:21,910:INFO:SubProcess create_model() end ==================================
2024-01-18 16:41:21,910:INFO:Creating metrics dataframe
2024-01-18 16:41:21,964:INFO:Initializing create_model()
2024-01-18 16:41:21,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4811, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:41:21,964:INFO:Checking exceptions
2024-01-18 16:41:21,966:INFO:Importing libraries
2024-01-18 16:41:21,967:INFO:Copying training dataset
2024-01-18 16:41:21,973:INFO:Defining folds
2024-01-18 16:41:21,973:INFO:Declaring metric variables
2024-01-18 16:41:21,974:INFO:Importing untrained model
2024-01-18 16:41:21,974:INFO:Declaring custom model
2024-01-18 16:41:21,975:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 16:41:21,976:INFO:Cross validation set to False
2024-01-18 16:41:21,976:INFO:Fitting Model
2024-01-18 16:41:22,138:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-18 16:41:22,138:INFO:[LightGBM] [Info] Number of positive: 3065, number of negative: 3020
2024-01-18 16:41:22,138:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.
2024-01-18 16:41:22,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-18 16:41:22,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-18 16:41:22,138:INFO:[LightGBM] [Info] Total Bins 1371
2024-01-18 16:41:22,138:INFO:[LightGBM] [Info] Number of data points in the train set: 6085, number of used features: 14
2024-01-18 16:41:22,138:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503698 -> initscore=0.014791
2024-01-18 16:41:22,138:INFO:[LightGBM] [Info] Start training from score 0.014791
2024-01-18 16:41:22,311:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4811, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:41:22,311:INFO:create_model() successfully completed......................................
2024-01-18 16:41:22,482:INFO:_master_model_container: 16
2024-01-18 16:41:22,482:INFO:_display_container: 2
2024-01-18 16:41:22,484:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4811, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:41:22,484:INFO:compare_models() successfully completed......................................
2024-01-18 16:41:22,625:INFO:Initializing finalize_model()
2024-01-18 16:41:22,625:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4811, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-18 16:41:22,625:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4811, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:41:22,640:INFO:Initializing create_model()
2024-01-18 16:41:22,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3150A90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4811, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:41:22,640:INFO:Checking exceptions
2024-01-18 16:41:22,640:INFO:Importing libraries
2024-01-18 16:41:22,640:INFO:Copying training dataset
2024-01-18 16:41:22,640:INFO:Defining folds
2024-01-18 16:41:22,640:INFO:Declaring metric variables
2024-01-18 16:41:22,640:INFO:Importing untrained model
2024-01-18 16:41:22,640:INFO:Declaring custom model
2024-01-18 16:41:22,640:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 16:41:22,640:INFO:Cross validation set to False
2024-01-18 16:41:22,640:INFO:Fitting Model
2024-01-18 16:41:22,775:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-18 16:41:22,775:INFO:[LightGBM] [Info] Number of positive: 4378, number of negative: 4315
2024-01-18 16:41:22,775:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.
2024-01-18 16:41:22,775:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-18 16:41:22,775:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-18 16:41:22,775:INFO:[LightGBM] [Info] Total Bins 1372
2024-01-18 16:41:22,775:INFO:[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 14
2024-01-18 16:41:22,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495
2024-01-18 16:41:22,775:INFO:[LightGBM] [Info] Start training from score 0.014495
2024-01-18 16:41:22,995:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=4811, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-18 16:41:22,995:INFO:create_model() successfully completed......................................
2024-01-18 16:41:23,105:INFO:_master_model_container: 16
2024-01-18 16:41:23,105:INFO:_display_container: 2
2024-01-18 16:41:23,245:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=4811, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-18 16:41:23,245:INFO:finalize_model() successfully completed......................................
2024-01-18 16:41:59,991:INFO:PyCaret ClassificationExperiment
2024-01-18 16:41:59,991:INFO:Logging name: clf-default-name
2024-01-18 16:41:59,991:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 16:41:59,991:INFO:version 3.2.0
2024-01-18 16:41:59,992:INFO:Initializing setup()
2024-01-18 16:41:59,992:INFO:self.USI: 5700
2024-01-18 16:41:59,992:INFO:self._variable_keys: {'y', 'log_plots_param', 'fold_groups_param', 'fix_imbalance', 'USI', 'X_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'X_train', 'exp_name_log', 'idx', 'y_train', 'X', 'logging_param', 'n_jobs_param', 'pipeline', 'seed', '_available_plots', 'gpu_n_jobs_param', 'y_test', 'data', 'fold_shuffle_param', 'gpu_param', 'memory', 'fold_generator', 'target_param', 'html_param'}
2024-01-18 16:41:59,992:INFO:Checking environment
2024-01-18 16:41:59,992:INFO:python_version: 3.11.5
2024-01-18 16:41:59,992:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 16:41:59,992:INFO:machine: AMD64
2024-01-18 16:41:59,992:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 16:41:59,992:INFO:Memory: svmem(total=8361132032, available=1038942208, percent=87.6, used=7322189824, free=1038942208)
2024-01-18 16:41:59,993:INFO:Physical Core: 2
2024-01-18 16:41:59,993:INFO:Logical Core: 4
2024-01-18 16:41:59,993:INFO:Checking libraries
2024-01-18 16:41:59,993:INFO:System:
2024-01-18 16:41:59,993:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 16:41:59,993:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 16:41:59,993:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 16:41:59,993:INFO:PyCaret required dependencies:
2024-01-18 16:41:59,993:INFO:                 pip: 23.2.1
2024-01-18 16:41:59,993:INFO:          setuptools: 68.0.0
2024-01-18 16:41:59,993:INFO:             pycaret: 3.2.0
2024-01-18 16:41:59,993:INFO:             IPython: 8.15.0
2024-01-18 16:41:59,993:INFO:          ipywidgets: 8.0.4
2024-01-18 16:41:59,993:INFO:                tqdm: 4.65.0
2024-01-18 16:41:59,993:INFO:               numpy: 1.24.3
2024-01-18 16:41:59,993:INFO:              pandas: 1.5.3
2024-01-18 16:41:59,993:INFO:              jinja2: 3.1.2
2024-01-18 16:41:59,993:INFO:               scipy: 1.10.1
2024-01-18 16:41:59,993:INFO:              joblib: 1.2.0
2024-01-18 16:41:59,994:INFO:             sklearn: 1.2.2
2024-01-18 16:41:59,994:INFO:                pyod: 1.1.2
2024-01-18 16:41:59,994:INFO:            imblearn: 0.10.1
2024-01-18 16:41:59,994:INFO:   category_encoders: 2.6.3
2024-01-18 16:41:59,994:INFO:            lightgbm: 4.2.0
2024-01-18 16:41:59,994:INFO:               numba: 0.57.1
2024-01-18 16:41:59,994:INFO:            requests: 2.31.0
2024-01-18 16:41:59,994:INFO:          matplotlib: 3.6.0
2024-01-18 16:41:59,994:INFO:          scikitplot: 0.3.7
2024-01-18 16:41:59,994:INFO:         yellowbrick: 1.5
2024-01-18 16:41:59,994:INFO:              plotly: 5.9.0
2024-01-18 16:41:59,994:INFO:    plotly-resampler: Not installed
2024-01-18 16:41:59,994:INFO:             kaleido: 0.2.1
2024-01-18 16:41:59,995:INFO:           schemdraw: 0.15
2024-01-18 16:41:59,995:INFO:         statsmodels: 0.14.0
2024-01-18 16:41:59,995:INFO:              sktime: 0.21.1
2024-01-18 16:41:59,995:INFO:               tbats: 1.1.3
2024-01-18 16:41:59,995:INFO:            pmdarima: 2.0.4
2024-01-18 16:41:59,995:INFO:              psutil: 5.9.0
2024-01-18 16:41:59,995:INFO:          markupsafe: 2.1.1
2024-01-18 16:41:59,995:INFO:             pickle5: Not installed
2024-01-18 16:41:59,995:INFO:         cloudpickle: 2.2.1
2024-01-18 16:41:59,995:INFO:         deprecation: 2.1.0
2024-01-18 16:41:59,995:INFO:              xxhash: 2.0.2
2024-01-18 16:41:59,995:INFO:           wurlitzer: Not installed
2024-01-18 16:41:59,995:INFO:PyCaret optional dependencies:
2024-01-18 16:41:59,995:INFO:                shap: Not installed
2024-01-18 16:41:59,996:INFO:           interpret: Not installed
2024-01-18 16:41:59,996:INFO:                umap: Not installed
2024-01-18 16:41:59,996:INFO:     ydata_profiling: Not installed
2024-01-18 16:41:59,996:INFO:  explainerdashboard: Not installed
2024-01-18 16:41:59,996:INFO:             autoviz: Not installed
2024-01-18 16:41:59,996:INFO:           fairlearn: Not installed
2024-01-18 16:41:59,996:INFO:          deepchecks: Not installed
2024-01-18 16:41:59,996:INFO:             xgboost: 2.0.3
2024-01-18 16:41:59,996:INFO:            catboost: 1.2.2
2024-01-18 16:41:59,997:INFO:              kmodes: Not installed
2024-01-18 16:41:59,997:INFO:             mlxtend: Not installed
2024-01-18 16:41:59,997:INFO:       statsforecast: Not installed
2024-01-18 16:41:59,997:INFO:        tune_sklearn: Not installed
2024-01-18 16:41:59,997:INFO:                 ray: Not installed
2024-01-18 16:41:59,997:INFO:            hyperopt: Not installed
2024-01-18 16:41:59,997:INFO:              optuna: 3.5.0
2024-01-18 16:41:59,997:INFO:               skopt: Not installed
2024-01-18 16:41:59,997:INFO:              mlflow: Not installed
2024-01-18 16:41:59,997:INFO:              gradio: Not installed
2024-01-18 16:41:59,997:INFO:             fastapi: Not installed
2024-01-18 16:41:59,997:INFO:             uvicorn: Not installed
2024-01-18 16:41:59,997:INFO:              m2cgen: Not installed
2024-01-18 16:41:59,998:INFO:           evidently: Not installed
2024-01-18 16:41:59,998:INFO:               fugue: Not installed
2024-01-18 16:41:59,998:INFO:           streamlit: Not installed
2024-01-18 16:41:59,998:INFO:             prophet: Not installed
2024-01-18 16:41:59,998:INFO:None
2024-01-18 16:41:59,998:INFO:Set up data.
2024-01-18 16:42:00,008:INFO:Set up folding strategy.
2024-01-18 16:42:00,008:INFO:Set up train/test split.
2024-01-18 16:42:00,032:INFO:Set up index.
2024-01-18 16:42:00,032:INFO:Assigning column types.
2024-01-18 16:42:00,039:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 16:42:00,107:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:42:00,107:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:42:00,123:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:42:00,123:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:42:00,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:42:00,181:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:42:00,206:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:42:00,206:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:42:00,206:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 16:42:00,237:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:42:00,285:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:42:00,285:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:42:00,331:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:42:00,346:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:42:00,346:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:42:00,346:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 16:42:00,425:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:42:00,425:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:42:00,504:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:42:00,520:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:42:00,520:INFO:Preparing preprocessing pipeline...
2024-01-18 16:42:00,520:INFO:Set up simple imputation.
2024-01-18 16:42:00,520:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\preprocess\preprocessor.py:653: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.
  for name, column in X_transformed[self._fxs["Categorical"]].items():

2024-01-18 16:42:00,520:INFO:Set up encoding of ordinal features.
2024-01-18 16:42:00,535:INFO:Set up encoding of categorical features.
2024-01-18 16:42:00,535:INFO:Set up column name cleaning.
2024-01-18 16:42:00,629:INFO:Finished creating preprocessing pipeline.
2024-01-18 16:42:00,723:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -0.316951    0
 3.155058    1
 NaN        -1
dtype: int64},
                                                                        {'col': 'Destination_TRAPPIST-1e',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -1.546237    0
 0.646731    1
 NaN        -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 16:42:00,723:INFO:Creating final display dataframe.
2024-01-18 16:42:01,048:INFO:Setup _display_container:                     Description             Value
0                    Session id              5475
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Ordinal features                 8
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              5700
2024-01-18 16:42:01,138:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:42:01,141:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:42:01,278:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:42:01,280:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:42:01,281:INFO:setup() successfully completed in 1.3s...............
2024-01-18 16:42:11,318:INFO:Initializing compare_models()
2024-01-18 16:42:11,319:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-18 16:42:11,319:INFO:Checking exceptions
2024-01-18 16:42:11,325:INFO:Preparing display monitor
2024-01-18 16:42:11,393:INFO:Initializing Logistic Regression
2024-01-18 16:42:11,394:INFO:Total runtime is 2.2017955780029296e-05 minutes
2024-01-18 16:42:11,401:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:11,401:INFO:Initializing create_model()
2024-01-18 16:42:11,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:11,402:INFO:Checking exceptions
2024-01-18 16:42:11,402:INFO:Importing libraries
2024-01-18 16:42:11,402:INFO:Copying training dataset
2024-01-18 16:42:11,414:INFO:Defining folds
2024-01-18 16:42:11,414:INFO:Declaring metric variables
2024-01-18 16:42:11,421:INFO:Importing untrained model
2024-01-18 16:42:11,428:INFO:Logistic Regression Imported successfully
2024-01-18 16:42:11,439:INFO:Starting cross validation
2024-01-18 16:42:11,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:12,211:INFO:Calculating mean and std
2024-01-18 16:42:12,211:INFO:Creating metrics dataframe
2024-01-18 16:42:12,211:INFO:Uploading results into container
2024-01-18 16:42:12,211:INFO:Uploading model into container now
2024-01-18 16:42:12,211:INFO:_master_model_container: 1
2024-01-18 16:42:12,211:INFO:_display_container: 2
2024-01-18 16:42:12,211:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5475, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-18 16:42:12,211:INFO:create_model() successfully completed......................................
2024-01-18 16:42:12,346:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:12,346:INFO:Creating metrics dataframe
2024-01-18 16:42:12,346:INFO:Initializing K Neighbors Classifier
2024-01-18 16:42:12,346:INFO:Total runtime is 0.015885925292968752 minutes
2024-01-18 16:42:12,366:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:12,366:INFO:Initializing create_model()
2024-01-18 16:42:12,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:12,367:INFO:Checking exceptions
2024-01-18 16:42:12,367:INFO:Importing libraries
2024-01-18 16:42:12,367:INFO:Copying training dataset
2024-01-18 16:42:12,375:INFO:Defining folds
2024-01-18 16:42:12,376:INFO:Declaring metric variables
2024-01-18 16:42:12,383:INFO:Importing untrained model
2024-01-18 16:42:12,392:INFO:K Neighbors Classifier Imported successfully
2024-01-18 16:42:12,405:INFO:Starting cross validation
2024-01-18 16:42:12,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:13,733:INFO:Calculating mean and std
2024-01-18 16:42:13,733:INFO:Creating metrics dataframe
2024-01-18 16:42:13,733:INFO:Uploading results into container
2024-01-18 16:42:13,733:INFO:Uploading model into container now
2024-01-18 16:42:13,733:INFO:_master_model_container: 2
2024-01-18 16:42:13,733:INFO:_display_container: 2
2024-01-18 16:42:13,733:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-18 16:42:13,733:INFO:create_model() successfully completed......................................
2024-01-18 16:42:13,878:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:13,878:INFO:Creating metrics dataframe
2024-01-18 16:42:13,899:INFO:Initializing Naive Bayes
2024-01-18 16:42:13,899:INFO:Total runtime is 0.04176727533340455 minutes
2024-01-18 16:42:13,902:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:13,902:INFO:Initializing create_model()
2024-01-18 16:42:13,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:13,902:INFO:Checking exceptions
2024-01-18 16:42:13,902:INFO:Importing libraries
2024-01-18 16:42:13,906:INFO:Copying training dataset
2024-01-18 16:42:13,916:INFO:Defining folds
2024-01-18 16:42:13,916:INFO:Declaring metric variables
2024-01-18 16:42:13,921:INFO:Importing untrained model
2024-01-18 16:42:13,927:INFO:Naive Bayes Imported successfully
2024-01-18 16:42:13,944:INFO:Starting cross validation
2024-01-18 16:42:13,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:14,948:INFO:Calculating mean and std
2024-01-18 16:42:14,950:INFO:Creating metrics dataframe
2024-01-18 16:42:14,957:INFO:Uploading results into container
2024-01-18 16:42:14,957:INFO:Uploading model into container now
2024-01-18 16:42:14,958:INFO:_master_model_container: 3
2024-01-18 16:42:14,958:INFO:_display_container: 2
2024-01-18 16:42:14,958:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-18 16:42:14,958:INFO:create_model() successfully completed......................................
2024-01-18 16:42:15,098:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:15,098:INFO:Creating metrics dataframe
2024-01-18 16:42:15,107:INFO:Initializing Decision Tree Classifier
2024-01-18 16:42:15,107:INFO:Total runtime is 0.06189533472061158 minutes
2024-01-18 16:42:15,107:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:15,107:INFO:Initializing create_model()
2024-01-18 16:42:15,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:15,107:INFO:Checking exceptions
2024-01-18 16:42:15,107:INFO:Importing libraries
2024-01-18 16:42:15,107:INFO:Copying training dataset
2024-01-18 16:42:15,128:INFO:Defining folds
2024-01-18 16:42:15,128:INFO:Declaring metric variables
2024-01-18 16:42:15,132:INFO:Importing untrained model
2024-01-18 16:42:15,136:INFO:Decision Tree Classifier Imported successfully
2024-01-18 16:42:15,144:INFO:Starting cross validation
2024-01-18 16:42:15,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:16,068:INFO:Calculating mean and std
2024-01-18 16:42:16,068:INFO:Creating metrics dataframe
2024-01-18 16:42:16,078:INFO:Uploading results into container
2024-01-18 16:42:16,079:INFO:Uploading model into container now
2024-01-18 16:42:16,080:INFO:_master_model_container: 4
2024-01-18 16:42:16,081:INFO:_display_container: 2
2024-01-18 16:42:16,081:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5475, splitter='best')
2024-01-18 16:42:16,082:INFO:create_model() successfully completed......................................
2024-01-18 16:42:16,201:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:16,201:INFO:Creating metrics dataframe
2024-01-18 16:42:16,217:INFO:Initializing SVM - Linear Kernel
2024-01-18 16:42:16,217:INFO:Total runtime is 0.08039742708206177 minutes
2024-01-18 16:42:16,217:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:16,217:INFO:Initializing create_model()
2024-01-18 16:42:16,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:16,230:INFO:Checking exceptions
2024-01-18 16:42:16,230:INFO:Importing libraries
2024-01-18 16:42:16,230:INFO:Copying training dataset
2024-01-18 16:42:16,237:INFO:Defining folds
2024-01-18 16:42:16,238:INFO:Declaring metric variables
2024-01-18 16:42:16,243:INFO:Importing untrained model
2024-01-18 16:42:16,248:INFO:SVM - Linear Kernel Imported successfully
2024-01-18 16:42:16,258:INFO:Starting cross validation
2024-01-18 16:42:16,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:16,503:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:16,518:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:16,550:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:16,550:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:16,786:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:16,803:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:16,820:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:16,820:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:16,991:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:16,991:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:42:17,006:INFO:Calculating mean and std
2024-01-18 16:42:17,006:INFO:Creating metrics dataframe
2024-01-18 16:42:17,022:INFO:Uploading results into container
2024-01-18 16:42:17,023:INFO:Uploading model into container now
2024-01-18 16:42:17,023:INFO:_master_model_container: 5
2024-01-18 16:42:17,023:INFO:_display_container: 2
2024-01-18 16:42:17,026:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5475, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-18 16:42:17,026:INFO:create_model() successfully completed......................................
2024-01-18 16:42:17,136:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:17,136:INFO:Creating metrics dataframe
2024-01-18 16:42:17,152:INFO:Initializing Ridge Classifier
2024-01-18 16:42:17,152:INFO:Total runtime is 0.09598037004470825 minutes
2024-01-18 16:42:17,158:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:17,159:INFO:Initializing create_model()
2024-01-18 16:42:17,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:17,159:INFO:Checking exceptions
2024-01-18 16:42:17,159:INFO:Importing libraries
2024-01-18 16:42:17,159:INFO:Copying training dataset
2024-01-18 16:42:17,167:INFO:Defining folds
2024-01-18 16:42:17,168:INFO:Declaring metric variables
2024-01-18 16:42:17,171:INFO:Importing untrained model
2024-01-18 16:42:17,175:INFO:Ridge Classifier Imported successfully
2024-01-18 16:42:17,185:INFO:Starting cross validation
2024-01-18 16:42:17,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:17,439:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,469:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,485:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,485:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,659:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,691:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,706:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,725:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,927:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,959:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:42:17,959:INFO:Calculating mean and std
2024-01-18 16:42:17,959:INFO:Creating metrics dataframe
2024-01-18 16:42:17,973:INFO:Uploading results into container
2024-01-18 16:42:17,973:INFO:Uploading model into container now
2024-01-18 16:42:17,974:INFO:_master_model_container: 6
2024-01-18 16:42:17,974:INFO:_display_container: 2
2024-01-18 16:42:17,975:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5475, solver='auto',
                tol=0.0001)
2024-01-18 16:42:17,975:INFO:create_model() successfully completed......................................
2024-01-18 16:42:18,103:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:18,103:INFO:Creating metrics dataframe
2024-01-18 16:42:18,120:INFO:Initializing Random Forest Classifier
2024-01-18 16:42:18,137:INFO:Total runtime is 0.11240595181783039 minutes
2024-01-18 16:42:18,142:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:18,142:INFO:Initializing create_model()
2024-01-18 16:42:18,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:18,143:INFO:Checking exceptions
2024-01-18 16:42:18,143:INFO:Importing libraries
2024-01-18 16:42:18,143:INFO:Copying training dataset
2024-01-18 16:42:18,149:INFO:Defining folds
2024-01-18 16:42:18,150:INFO:Declaring metric variables
2024-01-18 16:42:18,154:INFO:Importing untrained model
2024-01-18 16:42:18,163:INFO:Random Forest Classifier Imported successfully
2024-01-18 16:42:18,171:INFO:Starting cross validation
2024-01-18 16:42:18,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:21,896:INFO:Calculating mean and std
2024-01-18 16:42:21,896:INFO:Creating metrics dataframe
2024-01-18 16:42:21,896:INFO:Uploading results into container
2024-01-18 16:42:21,896:INFO:Uploading model into container now
2024-01-18 16:42:21,896:INFO:_master_model_container: 7
2024-01-18 16:42:21,896:INFO:_display_container: 2
2024-01-18 16:42:21,896:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5475, verbose=0, warm_start=False)
2024-01-18 16:42:21,911:INFO:create_model() successfully completed......................................
2024-01-18 16:42:22,022:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:22,022:INFO:Creating metrics dataframe
2024-01-18 16:42:22,036:INFO:Initializing Quadratic Discriminant Analysis
2024-01-18 16:42:22,036:INFO:Total runtime is 0.17738398710886638 minutes
2024-01-18 16:42:22,043:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:22,043:INFO:Initializing create_model()
2024-01-18 16:42:22,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:22,044:INFO:Checking exceptions
2024-01-18 16:42:22,044:INFO:Importing libraries
2024-01-18 16:42:22,044:INFO:Copying training dataset
2024-01-18 16:42:22,052:INFO:Defining folds
2024-01-18 16:42:22,052:INFO:Declaring metric variables
2024-01-18 16:42:22,057:INFO:Importing untrained model
2024-01-18 16:42:22,064:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-18 16:42:22,073:INFO:Starting cross validation
2024-01-18 16:42:22,078:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:22,273:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,288:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,295:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,595:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,602:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,635:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,651:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,857:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,872:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:42:22,950:INFO:Calculating mean and std
2024-01-18 16:42:22,950:INFO:Creating metrics dataframe
2024-01-18 16:42:22,950:INFO:Uploading results into container
2024-01-18 16:42:22,950:INFO:Uploading model into container now
2024-01-18 16:42:22,950:INFO:_master_model_container: 8
2024-01-18 16:42:22,950:INFO:_display_container: 2
2024-01-18 16:42:22,950:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-18 16:42:22,950:INFO:create_model() successfully completed......................................
2024-01-18 16:42:23,061:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:23,061:INFO:Creating metrics dataframe
2024-01-18 16:42:23,071:INFO:Initializing Ada Boost Classifier
2024-01-18 16:42:23,071:INFO:Total runtime is 0.19462929964065553 minutes
2024-01-18 16:42:23,084:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:23,085:INFO:Initializing create_model()
2024-01-18 16:42:23,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:23,085:INFO:Checking exceptions
2024-01-18 16:42:23,085:INFO:Importing libraries
2024-01-18 16:42:23,086:INFO:Copying training dataset
2024-01-18 16:42:23,095:INFO:Defining folds
2024-01-18 16:42:23,095:INFO:Declaring metric variables
2024-01-18 16:42:23,101:INFO:Importing untrained model
2024-01-18 16:42:23,107:INFO:Ada Boost Classifier Imported successfully
2024-01-18 16:42:23,118:INFO:Starting cross validation
2024-01-18 16:42:23,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:25,153:INFO:Calculating mean and std
2024-01-18 16:42:25,153:INFO:Creating metrics dataframe
2024-01-18 16:42:25,169:INFO:Uploading results into container
2024-01-18 16:42:25,169:INFO:Uploading model into container now
2024-01-18 16:42:25,169:INFO:_master_model_container: 9
2024-01-18 16:42:25,169:INFO:_display_container: 2
2024-01-18 16:42:25,169:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5475)
2024-01-18 16:42:25,169:INFO:create_model() successfully completed......................................
2024-01-18 16:42:25,301:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:25,301:INFO:Creating metrics dataframe
2024-01-18 16:42:25,316:INFO:Initializing Gradient Boosting Classifier
2024-01-18 16:42:25,316:INFO:Total runtime is 0.232058854897817 minutes
2024-01-18 16:42:25,316:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:25,316:INFO:Initializing create_model()
2024-01-18 16:42:25,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:25,324:INFO:Checking exceptions
2024-01-18 16:42:25,324:INFO:Importing libraries
2024-01-18 16:42:25,324:INFO:Copying training dataset
2024-01-18 16:42:25,332:INFO:Defining folds
2024-01-18 16:42:25,332:INFO:Declaring metric variables
2024-01-18 16:42:25,337:INFO:Importing untrained model
2024-01-18 16:42:25,343:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 16:42:25,352:INFO:Starting cross validation
2024-01-18 16:42:25,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:29,084:INFO:Calculating mean and std
2024-01-18 16:42:29,099:INFO:Creating metrics dataframe
2024-01-18 16:42:29,099:INFO:Uploading results into container
2024-01-18 16:42:29,099:INFO:Uploading model into container now
2024-01-18 16:42:29,099:INFO:_master_model_container: 10
2024-01-18 16:42:29,099:INFO:_display_container: 2
2024-01-18 16:42:29,099:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5475, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 16:42:29,099:INFO:create_model() successfully completed......................................
2024-01-18 16:42:29,234:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:29,234:INFO:Creating metrics dataframe
2024-01-18 16:42:29,234:INFO:Initializing Linear Discriminant Analysis
2024-01-18 16:42:29,234:INFO:Total runtime is 0.29734774827957156 minutes
2024-01-18 16:42:29,253:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:29,253:INFO:Initializing create_model()
2024-01-18 16:42:29,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:29,254:INFO:Checking exceptions
2024-01-18 16:42:29,254:INFO:Importing libraries
2024-01-18 16:42:29,254:INFO:Copying training dataset
2024-01-18 16:42:29,261:INFO:Defining folds
2024-01-18 16:42:29,262:INFO:Declaring metric variables
2024-01-18 16:42:29,266:INFO:Importing untrained model
2024-01-18 16:42:29,274:INFO:Linear Discriminant Analysis Imported successfully
2024-01-18 16:42:29,281:INFO:Starting cross validation
2024-01-18 16:42:29,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:30,025:INFO:Calculating mean and std
2024-01-18 16:42:30,025:INFO:Creating metrics dataframe
2024-01-18 16:42:30,041:INFO:Uploading results into container
2024-01-18 16:42:30,042:INFO:Uploading model into container now
2024-01-18 16:42:30,043:INFO:_master_model_container: 11
2024-01-18 16:42:30,043:INFO:_display_container: 2
2024-01-18 16:42:30,043:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-18 16:42:30,043:INFO:create_model() successfully completed......................................
2024-01-18 16:42:30,168:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:30,168:INFO:Creating metrics dataframe
2024-01-18 16:42:30,184:INFO:Initializing Extra Trees Classifier
2024-01-18 16:42:30,184:INFO:Total runtime is 0.31318040688832605 minutes
2024-01-18 16:42:30,200:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:30,200:INFO:Initializing create_model()
2024-01-18 16:42:30,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:30,200:INFO:Checking exceptions
2024-01-18 16:42:30,200:INFO:Importing libraries
2024-01-18 16:42:30,200:INFO:Copying training dataset
2024-01-18 16:42:30,209:INFO:Defining folds
2024-01-18 16:42:30,209:INFO:Declaring metric variables
2024-01-18 16:42:30,213:INFO:Importing untrained model
2024-01-18 16:42:30,219:INFO:Extra Trees Classifier Imported successfully
2024-01-18 16:42:30,227:INFO:Starting cross validation
2024-01-18 16:42:30,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:33,832:INFO:Calculating mean and std
2024-01-18 16:42:33,834:INFO:Creating metrics dataframe
2024-01-18 16:42:33,840:INFO:Uploading results into container
2024-01-18 16:42:33,841:INFO:Uploading model into container now
2024-01-18 16:42:33,841:INFO:_master_model_container: 12
2024-01-18 16:42:33,841:INFO:_display_container: 2
2024-01-18 16:42:33,842:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5475, verbose=0, warm_start=False)
2024-01-18 16:42:33,842:INFO:create_model() successfully completed......................................
2024-01-18 16:42:33,975:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:33,975:INFO:Creating metrics dataframe
2024-01-18 16:42:34,000:INFO:Initializing Extreme Gradient Boosting
2024-01-18 16:42:34,001:INFO:Total runtime is 0.3768080751101176 minutes
2024-01-18 16:42:34,006:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:34,007:INFO:Initializing create_model()
2024-01-18 16:42:34,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:34,007:INFO:Checking exceptions
2024-01-18 16:42:34,007:INFO:Importing libraries
2024-01-18 16:42:34,007:INFO:Copying training dataset
2024-01-18 16:42:34,015:INFO:Defining folds
2024-01-18 16:42:34,015:INFO:Declaring metric variables
2024-01-18 16:42:34,019:INFO:Importing untrained model
2024-01-18 16:42:34,024:INFO:Extreme Gradient Boosting Imported successfully
2024-01-18 16:42:34,033:INFO:Starting cross validation
2024-01-18 16:42:34,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:35,461:INFO:Calculating mean and std
2024-01-18 16:42:35,649:INFO:Creating metrics dataframe
2024-01-18 16:42:35,656:INFO:Uploading results into container
2024-01-18 16:42:35,657:INFO:Uploading model into container now
2024-01-18 16:42:35,658:INFO:_master_model_container: 13
2024-01-18 16:42:35,658:INFO:_display_container: 2
2024-01-18 16:42:35,660:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-18 16:42:35,660:INFO:create_model() successfully completed......................................
2024-01-18 16:42:35,771:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:35,771:INFO:Creating metrics dataframe
2024-01-18 16:42:35,802:INFO:Initializing Light Gradient Boosting Machine
2024-01-18 16:42:35,802:INFO:Total runtime is 0.40682297945022583 minutes
2024-01-18 16:42:35,813:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:35,813:INFO:Initializing create_model()
2024-01-18 16:42:35,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:35,813:INFO:Checking exceptions
2024-01-18 16:42:35,813:INFO:Importing libraries
2024-01-18 16:42:35,814:INFO:Copying training dataset
2024-01-18 16:42:35,822:INFO:Defining folds
2024-01-18 16:42:35,822:INFO:Declaring metric variables
2024-01-18 16:42:35,826:INFO:Importing untrained model
2024-01-18 16:42:35,833:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 16:42:35,844:INFO:Starting cross validation
2024-01-18 16:42:35,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:38,274:INFO:Calculating mean and std
2024-01-18 16:42:38,275:INFO:Creating metrics dataframe
2024-01-18 16:42:38,281:INFO:Uploading results into container
2024-01-18 16:42:38,282:INFO:Uploading model into container now
2024-01-18 16:42:38,283:INFO:_master_model_container: 14
2024-01-18 16:42:38,283:INFO:_display_container: 2
2024-01-18 16:42:38,284:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5475, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:42:38,284:INFO:create_model() successfully completed......................................
2024-01-18 16:42:38,408:INFO:SubProcess create_model() end ==================================
2024-01-18 16:42:38,408:INFO:Creating metrics dataframe
2024-01-18 16:42:38,425:INFO:Initializing CatBoost Classifier
2024-01-18 16:42:38,425:INFO:Total runtime is 0.45053557952245077 minutes
2024-01-18 16:42:38,425:INFO:SubProcess create_model() called ==================================
2024-01-18 16:42:38,425:INFO:Initializing create_model()
2024-01-18 16:42:38,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:42:38,425:INFO:Checking exceptions
2024-01-18 16:42:38,425:INFO:Importing libraries
2024-01-18 16:42:38,425:INFO:Copying training dataset
2024-01-18 16:42:38,446:INFO:Defining folds
2024-01-18 16:42:38,446:INFO:Declaring metric variables
2024-01-18 16:42:38,451:INFO:Importing untrained model
2024-01-18 16:42:38,458:INFO:CatBoost Classifier Imported successfully
2024-01-18 16:42:38,469:INFO:Starting cross validation
2024-01-18 16:42:38,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:42:50,087:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,087:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,102:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,103:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,103:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,103:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,223:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,223:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,224:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,224:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,224:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,224:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,227:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,227:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,227:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,227:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,227:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,227:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,227:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,238:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,238:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,238:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,238:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:42:50,238:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,813:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,813:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,813:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,814:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,818:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,818:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,818:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,819:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,819:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,819:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,829:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,829:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,830:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,830:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,830:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:01,830:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,237:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,237:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,237:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,237:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,237:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,364:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,364:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,364:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,364:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,364:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,364:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:43:09,365:INFO:Calculating mean and std
2024-01-18 16:43:09,367:INFO:Creating metrics dataframe
2024-01-18 16:43:09,370:INFO:Uploading results into container
2024-01-18 16:43:09,371:INFO:Uploading model into container now
2024-01-18 16:43:09,371:INFO:_master_model_container: 15
2024-01-18 16:43:09,371:INFO:_display_container: 2
2024-01-18 16:43:09,371:INFO:<catboost.core.CatBoostClassifier object at 0x000001EFC2F75610>
2024-01-18 16:43:09,371:INFO:create_model() successfully completed......................................
2024-01-18 16:43:09,469:INFO:SubProcess create_model() end ==================================
2024-01-18 16:43:09,469:INFO:Creating metrics dataframe
2024-01-18 16:43:09,491:INFO:Initializing Dummy Classifier
2024-01-18 16:43:09,491:INFO:Total runtime is 0.968294374148051 minutes
2024-01-18 16:43:09,494:INFO:SubProcess create_model() called ==================================
2024-01-18 16:43:09,495:INFO:Initializing create_model()
2024-01-18 16:43:09,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC1DC4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:43:09,495:INFO:Checking exceptions
2024-01-18 16:43:09,495:INFO:Importing libraries
2024-01-18 16:43:09,495:INFO:Copying training dataset
2024-01-18 16:43:09,500:INFO:Defining folds
2024-01-18 16:43:09,500:INFO:Declaring metric variables
2024-01-18 16:43:09,503:INFO:Importing untrained model
2024-01-18 16:43:09,507:INFO:Dummy Classifier Imported successfully
2024-01-18 16:43:09,515:INFO:Starting cross validation
2024-01-18 16:43:09,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:43:10,386:INFO:Calculating mean and std
2024-01-18 16:43:10,387:INFO:Creating metrics dataframe
2024-01-18 16:43:10,393:INFO:Uploading results into container
2024-01-18 16:43:10,394:INFO:Uploading model into container now
2024-01-18 16:43:10,395:INFO:_master_model_container: 16
2024-01-18 16:43:10,395:INFO:_display_container: 2
2024-01-18 16:43:10,396:INFO:DummyClassifier(constant=None, random_state=5475, strategy='prior')
2024-01-18 16:43:10,396:INFO:create_model() successfully completed......................................
2024-01-18 16:43:10,529:INFO:SubProcess create_model() end ==================================
2024-01-18 16:43:10,530:INFO:Creating metrics dataframe
2024-01-18 16:43:10,570:INFO:Initializing create_model()
2024-01-18 16:43:10,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC1D9F250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5475, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:43:10,933:INFO:Checking exceptions
2024-01-18 16:43:10,937:INFO:Importing libraries
2024-01-18 16:43:10,937:INFO:Copying training dataset
2024-01-18 16:43:10,948:INFO:Defining folds
2024-01-18 16:43:10,948:INFO:Declaring metric variables
2024-01-18 16:43:10,948:INFO:Importing untrained model
2024-01-18 16:43:10,948:INFO:Declaring custom model
2024-01-18 16:43:10,949:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 16:43:10,951:INFO:Cross validation set to False
2024-01-18 16:43:10,951:INFO:Fitting Model
2024-01-18 16:43:11,117:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-18 16:43:11,117:INFO:[LightGBM] [Info] Number of positive: 3065, number of negative: 3020
2024-01-18 16:43:11,119:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2024-01-18 16:43:11,119:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-18 16:43:11,119:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-18 16:43:11,119:INFO:[LightGBM] [Info] Total Bins 1371
2024-01-18 16:43:11,120:INFO:[LightGBM] [Info] Number of data points in the train set: 6085, number of used features: 14
2024-01-18 16:43:11,120:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503698 -> initscore=0.014791
2024-01-18 16:43:11,120:INFO:[LightGBM] [Info] Start training from score 0.014791
2024-01-18 16:43:11,317:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5475, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:43:11,317:INFO:create_model() successfully completed......................................
2024-01-18 16:43:11,511:INFO:_master_model_container: 16
2024-01-18 16:43:11,511:INFO:_display_container: 2
2024-01-18 16:43:11,512:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5475, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:43:11,512:INFO:compare_models() successfully completed......................................
2024-01-18 16:44:40,406:INFO:PyCaret ClassificationExperiment
2024-01-18 16:44:40,406:INFO:Logging name: clf-default-name
2024-01-18 16:44:40,406:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 16:44:40,406:INFO:version 3.2.0
2024-01-18 16:44:40,406:INFO:Initializing setup()
2024-01-18 16:44:40,406:INFO:self.USI: 64a6
2024-01-18 16:44:40,406:INFO:self._variable_keys: {'y', 'log_plots_param', 'fold_groups_param', 'fix_imbalance', 'USI', 'X_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'X_train', 'exp_name_log', 'idx', 'y_train', 'X', 'logging_param', 'n_jobs_param', 'pipeline', 'seed', '_available_plots', 'gpu_n_jobs_param', 'y_test', 'data', 'fold_shuffle_param', 'gpu_param', 'memory', 'fold_generator', 'target_param', 'html_param'}
2024-01-18 16:44:40,406:INFO:Checking environment
2024-01-18 16:44:40,406:INFO:python_version: 3.11.5
2024-01-18 16:44:40,406:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 16:44:40,406:INFO:machine: AMD64
2024-01-18 16:44:40,406:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 16:44:40,406:INFO:Memory: svmem(total=8361132032, available=865677312, percent=89.6, used=7495454720, free=865677312)
2024-01-18 16:44:40,406:INFO:Physical Core: 2
2024-01-18 16:44:40,406:INFO:Logical Core: 4
2024-01-18 16:44:40,406:INFO:Checking libraries
2024-01-18 16:44:40,406:INFO:System:
2024-01-18 16:44:40,406:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 16:44:40,406:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 16:44:40,406:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 16:44:40,406:INFO:PyCaret required dependencies:
2024-01-18 16:44:40,406:INFO:                 pip: 23.2.1
2024-01-18 16:44:40,406:INFO:          setuptools: 68.0.0
2024-01-18 16:44:40,406:INFO:             pycaret: 3.2.0
2024-01-18 16:44:40,406:INFO:             IPython: 8.15.0
2024-01-18 16:44:40,406:INFO:          ipywidgets: 8.0.4
2024-01-18 16:44:40,406:INFO:                tqdm: 4.65.0
2024-01-18 16:44:40,406:INFO:               numpy: 1.24.3
2024-01-18 16:44:40,406:INFO:              pandas: 1.5.3
2024-01-18 16:44:40,406:INFO:              jinja2: 3.1.2
2024-01-18 16:44:40,406:INFO:               scipy: 1.10.1
2024-01-18 16:44:40,406:INFO:              joblib: 1.2.0
2024-01-18 16:44:40,406:INFO:             sklearn: 1.2.2
2024-01-18 16:44:40,421:INFO:                pyod: 1.1.2
2024-01-18 16:44:40,421:INFO:            imblearn: 0.10.1
2024-01-18 16:44:40,421:INFO:   category_encoders: 2.6.3
2024-01-18 16:44:40,421:INFO:            lightgbm: 4.2.0
2024-01-18 16:44:40,421:INFO:               numba: 0.57.1
2024-01-18 16:44:40,421:INFO:            requests: 2.31.0
2024-01-18 16:44:40,421:INFO:          matplotlib: 3.6.0
2024-01-18 16:44:40,421:INFO:          scikitplot: 0.3.7
2024-01-18 16:44:40,421:INFO:         yellowbrick: 1.5
2024-01-18 16:44:40,421:INFO:              plotly: 5.9.0
2024-01-18 16:44:40,421:INFO:    plotly-resampler: Not installed
2024-01-18 16:44:40,421:INFO:             kaleido: 0.2.1
2024-01-18 16:44:40,421:INFO:           schemdraw: 0.15
2024-01-18 16:44:40,421:INFO:         statsmodels: 0.14.0
2024-01-18 16:44:40,421:INFO:              sktime: 0.21.1
2024-01-18 16:44:40,421:INFO:               tbats: 1.1.3
2024-01-18 16:44:40,421:INFO:            pmdarima: 2.0.4
2024-01-18 16:44:40,421:INFO:              psutil: 5.9.0
2024-01-18 16:44:40,421:INFO:          markupsafe: 2.1.1
2024-01-18 16:44:40,421:INFO:             pickle5: Not installed
2024-01-18 16:44:40,421:INFO:         cloudpickle: 2.2.1
2024-01-18 16:44:40,421:INFO:         deprecation: 2.1.0
2024-01-18 16:44:40,421:INFO:              xxhash: 2.0.2
2024-01-18 16:44:40,421:INFO:           wurlitzer: Not installed
2024-01-18 16:44:40,421:INFO:PyCaret optional dependencies:
2024-01-18 16:44:40,421:INFO:                shap: Not installed
2024-01-18 16:44:40,421:INFO:           interpret: Not installed
2024-01-18 16:44:40,421:INFO:                umap: Not installed
2024-01-18 16:44:40,421:INFO:     ydata_profiling: Not installed
2024-01-18 16:44:40,421:INFO:  explainerdashboard: Not installed
2024-01-18 16:44:40,421:INFO:             autoviz: Not installed
2024-01-18 16:44:40,421:INFO:           fairlearn: Not installed
2024-01-18 16:44:40,421:INFO:          deepchecks: Not installed
2024-01-18 16:44:40,421:INFO:             xgboost: 2.0.3
2024-01-18 16:44:40,421:INFO:            catboost: 1.2.2
2024-01-18 16:44:40,421:INFO:              kmodes: Not installed
2024-01-18 16:44:40,421:INFO:             mlxtend: Not installed
2024-01-18 16:44:40,421:INFO:       statsforecast: Not installed
2024-01-18 16:44:40,421:INFO:        tune_sklearn: Not installed
2024-01-18 16:44:40,421:INFO:                 ray: Not installed
2024-01-18 16:44:40,421:INFO:            hyperopt: Not installed
2024-01-18 16:44:40,421:INFO:              optuna: 3.5.0
2024-01-18 16:44:40,421:INFO:               skopt: Not installed
2024-01-18 16:44:40,421:INFO:              mlflow: Not installed
2024-01-18 16:44:40,421:INFO:              gradio: Not installed
2024-01-18 16:44:40,421:INFO:             fastapi: Not installed
2024-01-18 16:44:40,421:INFO:             uvicorn: Not installed
2024-01-18 16:44:40,421:INFO:              m2cgen: Not installed
2024-01-18 16:44:40,421:INFO:           evidently: Not installed
2024-01-18 16:44:40,421:INFO:               fugue: Not installed
2024-01-18 16:44:40,421:INFO:           streamlit: Not installed
2024-01-18 16:44:40,421:INFO:             prophet: Not installed
2024-01-18 16:44:40,421:INFO:None
2024-01-18 16:44:40,421:INFO:Set up data.
2024-01-18 16:44:40,421:INFO:Set up folding strategy.
2024-01-18 16:44:40,421:INFO:Set up train/test split.
2024-01-18 16:44:40,437:INFO:Set up index.
2024-01-18 16:44:40,437:INFO:Assigning column types.
2024-01-18 16:44:40,437:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 16:44:40,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:44:40,484:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:44:40,515:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:44:40,515:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:44:40,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:44:40,562:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:44:40,587:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:44:40,593:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:44:40,593:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 16:44:40,624:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:44:40,672:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:44:40,675:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:44:40,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:44:40,763:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:44:40,766:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:44:40,768:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 16:44:40,857:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:44:40,861:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:44:40,936:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:44:40,941:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:44:40,944:INFO:Preparing preprocessing pipeline...
2024-01-18 16:44:40,946:INFO:Set up simple imputation.
2024-01-18 16:44:40,949:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\preprocess\preprocessor.py:653: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.
  for name, column in X_transformed[self._fxs["Categorical"]].items():

2024-01-18 16:44:40,954:INFO:Set up encoding of ordinal features.
2024-01-18 16:44:40,968:INFO:Set up encoding of categorical features.
2024-01-18 16:44:40,968:INFO:Set up column name cleaning.
2024-01-18 16:44:41,166:INFO:Finished creating preprocessing pipeline.
2024-01-18 16:44:41,317:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -0.316951    0
 3.155058    1
 NaN        -1
dtype: int64},
                                                                        {'col': 'Destination_TRAPPIST-1e',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -1.546237    0
 0.646731    1
 NaN        -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 16:44:41,317:INFO:Creating final display dataframe.
2024-01-18 16:44:41,661:INFO:Setup _display_container:                     Description             Value
0                    Session id              7385
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Ordinal features                 8
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              64a6
2024-01-18 16:44:41,785:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:44:41,785:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:44:41,901:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:44:41,901:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:44:41,901:INFO:setup() successfully completed in 1.89s...............
2024-01-18 16:51:37,328:INFO:PyCaret ClassificationExperiment
2024-01-18 16:51:37,328:INFO:Logging name: clf-default-name
2024-01-18 16:51:37,328:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 16:51:37,328:INFO:version 3.2.0
2024-01-18 16:51:37,328:INFO:Initializing setup()
2024-01-18 16:51:37,328:INFO:self.USI: 9050
2024-01-18 16:51:37,328:INFO:self._variable_keys: {'y', 'log_plots_param', 'fold_groups_param', 'fix_imbalance', 'USI', 'X_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'X_train', 'exp_name_log', 'idx', 'y_train', 'X', 'logging_param', 'n_jobs_param', 'pipeline', 'seed', '_available_plots', 'gpu_n_jobs_param', 'y_test', 'data', 'fold_shuffle_param', 'gpu_param', 'memory', 'fold_generator', 'target_param', 'html_param'}
2024-01-18 16:51:37,328:INFO:Checking environment
2024-01-18 16:51:37,328:INFO:python_version: 3.11.5
2024-01-18 16:51:37,329:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 16:51:37,329:INFO:machine: AMD64
2024-01-18 16:51:37,329:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 16:51:37,329:INFO:Memory: svmem(total=8361132032, available=1854324736, percent=77.8, used=6506807296, free=1854324736)
2024-01-18 16:51:37,329:INFO:Physical Core: 2
2024-01-18 16:51:37,329:INFO:Logical Core: 4
2024-01-18 16:51:37,329:INFO:Checking libraries
2024-01-18 16:51:37,329:INFO:System:
2024-01-18 16:51:37,329:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 16:51:37,329:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 16:51:37,329:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 16:51:37,330:INFO:PyCaret required dependencies:
2024-01-18 16:51:37,330:INFO:                 pip: 23.2.1
2024-01-18 16:51:37,330:INFO:          setuptools: 68.0.0
2024-01-18 16:51:37,330:INFO:             pycaret: 3.2.0
2024-01-18 16:51:37,330:INFO:             IPython: 8.15.0
2024-01-18 16:51:37,330:INFO:          ipywidgets: 8.0.4
2024-01-18 16:51:37,330:INFO:                tqdm: 4.65.0
2024-01-18 16:51:37,330:INFO:               numpy: 1.24.3
2024-01-18 16:51:37,330:INFO:              pandas: 1.5.3
2024-01-18 16:51:37,330:INFO:              jinja2: 3.1.2
2024-01-18 16:51:37,330:INFO:               scipy: 1.10.1
2024-01-18 16:51:37,330:INFO:              joblib: 1.2.0
2024-01-18 16:51:37,330:INFO:             sklearn: 1.2.2
2024-01-18 16:51:37,331:INFO:                pyod: 1.1.2
2024-01-18 16:51:37,331:INFO:            imblearn: 0.10.1
2024-01-18 16:51:37,331:INFO:   category_encoders: 2.6.3
2024-01-18 16:51:37,331:INFO:            lightgbm: 4.2.0
2024-01-18 16:51:37,331:INFO:               numba: 0.57.1
2024-01-18 16:51:37,331:INFO:            requests: 2.31.0
2024-01-18 16:51:37,331:INFO:          matplotlib: 3.6.0
2024-01-18 16:51:37,331:INFO:          scikitplot: 0.3.7
2024-01-18 16:51:37,331:INFO:         yellowbrick: 1.5
2024-01-18 16:51:37,331:INFO:              plotly: 5.9.0
2024-01-18 16:51:37,331:INFO:    plotly-resampler: Not installed
2024-01-18 16:51:37,331:INFO:             kaleido: 0.2.1
2024-01-18 16:51:37,331:INFO:           schemdraw: 0.15
2024-01-18 16:51:37,331:INFO:         statsmodels: 0.14.0
2024-01-18 16:51:37,331:INFO:              sktime: 0.21.1
2024-01-18 16:51:37,331:INFO:               tbats: 1.1.3
2024-01-18 16:51:37,331:INFO:            pmdarima: 2.0.4
2024-01-18 16:51:37,331:INFO:              psutil: 5.9.0
2024-01-18 16:51:37,332:INFO:          markupsafe: 2.1.1
2024-01-18 16:51:37,332:INFO:             pickle5: Not installed
2024-01-18 16:51:37,332:INFO:         cloudpickle: 2.2.1
2024-01-18 16:51:37,332:INFO:         deprecation: 2.1.0
2024-01-18 16:51:37,332:INFO:              xxhash: 2.0.2
2024-01-18 16:51:37,332:INFO:           wurlitzer: Not installed
2024-01-18 16:51:37,332:INFO:PyCaret optional dependencies:
2024-01-18 16:51:37,332:INFO:                shap: Not installed
2024-01-18 16:51:37,332:INFO:           interpret: Not installed
2024-01-18 16:51:37,332:INFO:                umap: Not installed
2024-01-18 16:51:37,332:INFO:     ydata_profiling: Not installed
2024-01-18 16:51:37,332:INFO:  explainerdashboard: Not installed
2024-01-18 16:51:37,332:INFO:             autoviz: Not installed
2024-01-18 16:51:37,332:INFO:           fairlearn: Not installed
2024-01-18 16:51:37,332:INFO:          deepchecks: Not installed
2024-01-18 16:51:37,332:INFO:             xgboost: 2.0.3
2024-01-18 16:51:37,332:INFO:            catboost: 1.2.2
2024-01-18 16:51:37,332:INFO:              kmodes: Not installed
2024-01-18 16:51:37,332:INFO:             mlxtend: Not installed
2024-01-18 16:51:37,332:INFO:       statsforecast: Not installed
2024-01-18 16:51:37,332:INFO:        tune_sklearn: Not installed
2024-01-18 16:51:37,332:INFO:                 ray: Not installed
2024-01-18 16:51:37,332:INFO:            hyperopt: Not installed
2024-01-18 16:51:37,332:INFO:              optuna: 3.5.0
2024-01-18 16:51:37,333:INFO:               skopt: Not installed
2024-01-18 16:51:37,333:INFO:              mlflow: Not installed
2024-01-18 16:51:37,333:INFO:              gradio: Not installed
2024-01-18 16:51:37,333:INFO:             fastapi: Not installed
2024-01-18 16:51:37,333:INFO:             uvicorn: Not installed
2024-01-18 16:51:37,333:INFO:              m2cgen: Not installed
2024-01-18 16:51:37,333:INFO:           evidently: Not installed
2024-01-18 16:51:37,333:INFO:               fugue: Not installed
2024-01-18 16:51:37,334:INFO:           streamlit: Not installed
2024-01-18 16:51:37,334:INFO:             prophet: Not installed
2024-01-18 16:51:37,334:INFO:None
2024-01-18 16:51:37,334:INFO:Set up data.
2024-01-18 16:51:37,354:INFO:Set up folding strategy.
2024-01-18 16:51:37,354:INFO:Set up train/test split.
2024-01-18 16:51:37,370:INFO:Set up index.
2024-01-18 16:51:37,370:INFO:Assigning column types.
2024-01-18 16:51:37,377:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 16:51:37,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:51:37,463:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:51:37,518:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:51:37,534:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:51:37,596:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:51:37,596:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:51:37,643:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:51:37,643:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:51:37,643:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 16:51:37,722:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:51:37,769:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:51:37,769:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:51:37,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:51:37,942:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:51:37,942:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:51:37,942:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 16:51:38,051:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:51:38,051:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:51:38,192:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:51:38,192:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:51:38,192:INFO:Preparing preprocessing pipeline...
2024-01-18 16:51:38,192:INFO:Set up simple imputation.
2024-01-18 16:51:38,192:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\preprocess\preprocessor.py:653: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.
  for name, column in X_transformed[self._fxs["Categorical"]].items():

2024-01-18 16:51:38,207:INFO:Set up encoding of ordinal features.
2024-01-18 16:51:38,223:INFO:Set up encoding of categorical features.
2024-01-18 16:51:38,223:INFO:Set up column name cleaning.
2024-01-18 16:51:38,415:INFO:Finished creating preprocessing pipeline.
2024-01-18 16:51:38,595:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -0.316951    0
 3.155058    1
 NaN        -1
dtype: int64},
                                                                        {'col': 'Destination_TRAPPIST-1e',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -1.546237    0
 0.646731    1
 NaN        -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 16:51:38,595:INFO:Creating final display dataframe.
2024-01-18 16:51:38,811:INFO:Setup _display_container:                     Description             Value
0                    Session id              5794
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Ordinal features                 8
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              9050
2024-01-18 16:51:38,976:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:51:38,981:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:51:39,115:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:51:39,115:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:51:39,115:INFO:setup() successfully completed in 1.8s...............
2024-01-18 16:56:03,840:INFO:PyCaret ClassificationExperiment
2024-01-18 16:56:03,840:INFO:Logging name: clf-default-name
2024-01-18 16:56:03,840:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 16:56:03,840:INFO:version 3.2.0
2024-01-18 16:56:03,840:INFO:Initializing setup()
2024-01-18 16:56:03,840:INFO:self.USI: 5b7e
2024-01-18 16:56:03,840:INFO:self._variable_keys: {'y', 'log_plots_param', 'fold_groups_param', 'fix_imbalance', 'USI', 'X_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'X_train', 'exp_name_log', 'idx', 'y_train', 'X', 'logging_param', 'n_jobs_param', 'pipeline', 'seed', '_available_plots', 'gpu_n_jobs_param', 'y_test', 'data', 'fold_shuffle_param', 'gpu_param', 'memory', 'fold_generator', 'target_param', 'html_param'}
2024-01-18 16:56:03,840:INFO:Checking environment
2024-01-18 16:56:03,840:INFO:python_version: 3.11.5
2024-01-18 16:56:03,840:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 16:56:03,840:INFO:machine: AMD64
2024-01-18 16:56:03,840:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 16:56:03,840:INFO:Memory: svmem(total=8361132032, available=1824522240, percent=78.2, used=6536609792, free=1824522240)
2024-01-18 16:56:03,840:INFO:Physical Core: 2
2024-01-18 16:56:03,840:INFO:Logical Core: 4
2024-01-18 16:56:03,840:INFO:Checking libraries
2024-01-18 16:56:03,840:INFO:System:
2024-01-18 16:56:03,840:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 16:56:03,840:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 16:56:03,840:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 16:56:03,840:INFO:PyCaret required dependencies:
2024-01-18 16:56:03,840:INFO:                 pip: 23.2.1
2024-01-18 16:56:03,840:INFO:          setuptools: 68.0.0
2024-01-18 16:56:03,840:INFO:             pycaret: 3.2.0
2024-01-18 16:56:03,840:INFO:             IPython: 8.15.0
2024-01-18 16:56:03,840:INFO:          ipywidgets: 8.0.4
2024-01-18 16:56:03,840:INFO:                tqdm: 4.65.0
2024-01-18 16:56:03,840:INFO:               numpy: 1.24.3
2024-01-18 16:56:03,840:INFO:              pandas: 1.5.3
2024-01-18 16:56:03,840:INFO:              jinja2: 3.1.2
2024-01-18 16:56:03,840:INFO:               scipy: 1.10.1
2024-01-18 16:56:03,840:INFO:              joblib: 1.2.0
2024-01-18 16:56:03,840:INFO:             sklearn: 1.2.2
2024-01-18 16:56:03,840:INFO:                pyod: 1.1.2
2024-01-18 16:56:03,840:INFO:            imblearn: 0.10.1
2024-01-18 16:56:03,840:INFO:   category_encoders: 2.6.3
2024-01-18 16:56:03,840:INFO:            lightgbm: 4.2.0
2024-01-18 16:56:03,840:INFO:               numba: 0.57.1
2024-01-18 16:56:03,840:INFO:            requests: 2.31.0
2024-01-18 16:56:03,840:INFO:          matplotlib: 3.6.0
2024-01-18 16:56:03,840:INFO:          scikitplot: 0.3.7
2024-01-18 16:56:03,840:INFO:         yellowbrick: 1.5
2024-01-18 16:56:03,840:INFO:              plotly: 5.9.0
2024-01-18 16:56:03,840:INFO:    plotly-resampler: Not installed
2024-01-18 16:56:03,840:INFO:             kaleido: 0.2.1
2024-01-18 16:56:03,840:INFO:           schemdraw: 0.15
2024-01-18 16:56:03,840:INFO:         statsmodels: 0.14.0
2024-01-18 16:56:03,840:INFO:              sktime: 0.21.1
2024-01-18 16:56:03,840:INFO:               tbats: 1.1.3
2024-01-18 16:56:03,840:INFO:            pmdarima: 2.0.4
2024-01-18 16:56:03,840:INFO:              psutil: 5.9.0
2024-01-18 16:56:03,840:INFO:          markupsafe: 2.1.1
2024-01-18 16:56:03,840:INFO:             pickle5: Not installed
2024-01-18 16:56:03,840:INFO:         cloudpickle: 2.2.1
2024-01-18 16:56:03,840:INFO:         deprecation: 2.1.0
2024-01-18 16:56:03,840:INFO:              xxhash: 2.0.2
2024-01-18 16:56:03,840:INFO:           wurlitzer: Not installed
2024-01-18 16:56:03,840:INFO:PyCaret optional dependencies:
2024-01-18 16:56:03,840:INFO:                shap: Not installed
2024-01-18 16:56:03,855:INFO:           interpret: Not installed
2024-01-18 16:56:03,855:INFO:                umap: Not installed
2024-01-18 16:56:03,855:INFO:     ydata_profiling: Not installed
2024-01-18 16:56:03,855:INFO:  explainerdashboard: Not installed
2024-01-18 16:56:03,855:INFO:             autoviz: Not installed
2024-01-18 16:56:03,855:INFO:           fairlearn: Not installed
2024-01-18 16:56:03,855:INFO:          deepchecks: Not installed
2024-01-18 16:56:03,855:INFO:             xgboost: 2.0.3
2024-01-18 16:56:03,855:INFO:            catboost: 1.2.2
2024-01-18 16:56:03,855:INFO:              kmodes: Not installed
2024-01-18 16:56:03,855:INFO:             mlxtend: Not installed
2024-01-18 16:56:03,855:INFO:       statsforecast: Not installed
2024-01-18 16:56:03,855:INFO:        tune_sklearn: Not installed
2024-01-18 16:56:03,855:INFO:                 ray: Not installed
2024-01-18 16:56:03,855:INFO:            hyperopt: Not installed
2024-01-18 16:56:03,855:INFO:              optuna: 3.5.0
2024-01-18 16:56:03,855:INFO:               skopt: Not installed
2024-01-18 16:56:03,855:INFO:              mlflow: Not installed
2024-01-18 16:56:03,855:INFO:              gradio: Not installed
2024-01-18 16:56:03,855:INFO:             fastapi: Not installed
2024-01-18 16:56:03,855:INFO:             uvicorn: Not installed
2024-01-18 16:56:03,855:INFO:              m2cgen: Not installed
2024-01-18 16:56:03,855:INFO:           evidently: Not installed
2024-01-18 16:56:03,855:INFO:               fugue: Not installed
2024-01-18 16:56:03,855:INFO:           streamlit: Not installed
2024-01-18 16:56:03,855:INFO:             prophet: Not installed
2024-01-18 16:56:03,855:INFO:None
2024-01-18 16:56:03,855:INFO:Set up data.
2024-01-18 16:56:03,871:INFO:Set up folding strategy.
2024-01-18 16:56:03,871:INFO:Set up train/test split.
2024-01-18 16:56:03,887:INFO:Set up index.
2024-01-18 16:56:03,887:INFO:Assigning column types.
2024-01-18 16:56:03,887:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 16:56:03,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:56:03,970:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:56:04,017:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:56:04,017:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:56:04,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 16:56:04,095:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:56:04,143:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:56:04,143:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:56:04,143:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 16:56:04,221:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:56:04,299:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:56:04,299:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:56:04,362:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 16:56:04,408:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:56:04,409:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:56:04,409:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 16:56:04,534:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:56:04,534:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:56:04,723:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:56:04,738:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:56:04,738:INFO:Preparing preprocessing pipeline...
2024-01-18 16:56:04,738:INFO:Set up simple imputation.
2024-01-18 16:56:04,738:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\preprocess\preprocessor.py:653: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.
  for name, column in X_transformed[self._fxs["Categorical"]].items():

2024-01-18 16:56:04,754:INFO:Set up encoding of ordinal features.
2024-01-18 16:56:04,780:INFO:Set up encoding of categorical features.
2024-01-18 16:56:04,781:INFO:Set up column name cleaning.
2024-01-18 16:56:04,982:INFO:Finished creating preprocessing pipeline.
2024-01-18 16:56:05,135:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -0.316951    0
 3.155058    1
 NaN        -1
dtype: int64},
                                                                        {'col': 'Destination_TRAPPIST-1e',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -1.546237    0
 0.646731    1
 NaN        -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 16:56:05,135:INFO:Creating final display dataframe.
2024-01-18 16:56:05,433:INFO:Setup _display_container:                     Description             Value
0                    Session id              7788
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Ordinal features                 8
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              5b7e
2024-01-18 16:56:05,588:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:56:05,588:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:56:05,689:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 16:56:05,704:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 16:56:05,704:INFO:setup() successfully completed in 1.98s...............
2024-01-18 16:56:12,372:INFO:Initializing compare_models()
2024-01-18 16:56:12,373:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-18 16:56:12,373:INFO:Checking exceptions
2024-01-18 16:56:12,379:INFO:Preparing display monitor
2024-01-18 16:56:12,411:INFO:Initializing Logistic Regression
2024-01-18 16:56:12,411:INFO:Total runtime is 0.0 minutes
2024-01-18 16:56:12,432:INFO:SubProcess create_model() called ==================================
2024-01-18 16:56:12,433:INFO:Initializing create_model()
2024-01-18 16:56:12,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:56:12,433:INFO:Checking exceptions
2024-01-18 16:56:12,433:INFO:Importing libraries
2024-01-18 16:56:12,434:INFO:Copying training dataset
2024-01-18 16:56:12,449:INFO:Defining folds
2024-01-18 16:56:12,449:INFO:Declaring metric variables
2024-01-18 16:56:12,460:INFO:Importing untrained model
2024-01-18 16:56:12,468:INFO:Logistic Regression Imported successfully
2024-01-18 16:56:12,481:INFO:Starting cross validation
2024-01-18 16:56:12,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:19,600:INFO:Calculating mean and std
2024-01-18 16:57:19,600:INFO:Creating metrics dataframe
2024-01-18 16:57:19,600:INFO:Uploading results into container
2024-01-18 16:57:19,600:INFO:Uploading model into container now
2024-01-18 16:57:19,600:INFO:_master_model_container: 1
2024-01-18 16:57:19,600:INFO:_display_container: 2
2024-01-18 16:57:19,615:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7788, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-18 16:57:19,616:INFO:create_model() successfully completed......................................
2024-01-18 16:57:19,804:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:19,804:INFO:Creating metrics dataframe
2024-01-18 16:57:19,819:INFO:Initializing K Neighbors Classifier
2024-01-18 16:57:19,819:INFO:Total runtime is 1.1234702865282695 minutes
2024-01-18 16:57:19,819:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:19,819:INFO:Initializing create_model()
2024-01-18 16:57:19,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:19,819:INFO:Checking exceptions
2024-01-18 16:57:19,819:INFO:Importing libraries
2024-01-18 16:57:19,835:INFO:Copying training dataset
2024-01-18 16:57:19,842:INFO:Defining folds
2024-01-18 16:57:19,842:INFO:Declaring metric variables
2024-01-18 16:57:19,846:INFO:Importing untrained model
2024-01-18 16:57:19,850:INFO:K Neighbors Classifier Imported successfully
2024-01-18 16:57:19,857:INFO:Starting cross validation
2024-01-18 16:57:19,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:21,189:INFO:Calculating mean and std
2024-01-18 16:57:21,203:INFO:Creating metrics dataframe
2024-01-18 16:57:21,203:INFO:Uploading results into container
2024-01-18 16:57:21,203:INFO:Uploading model into container now
2024-01-18 16:57:21,203:INFO:_master_model_container: 2
2024-01-18 16:57:21,203:INFO:_display_container: 2
2024-01-18 16:57:21,203:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-18 16:57:21,203:INFO:create_model() successfully completed......................................
2024-01-18 16:57:21,350:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:21,350:INFO:Creating metrics dataframe
2024-01-18 16:57:21,366:INFO:Initializing Naive Bayes
2024-01-18 16:57:21,366:INFO:Total runtime is 1.149246096611023 minutes
2024-01-18 16:57:21,380:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:21,381:INFO:Initializing create_model()
2024-01-18 16:57:21,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:21,381:INFO:Checking exceptions
2024-01-18 16:57:21,381:INFO:Importing libraries
2024-01-18 16:57:21,381:INFO:Copying training dataset
2024-01-18 16:57:21,390:INFO:Defining folds
2024-01-18 16:57:21,390:INFO:Declaring metric variables
2024-01-18 16:57:21,394:INFO:Importing untrained model
2024-01-18 16:57:21,398:INFO:Naive Bayes Imported successfully
2024-01-18 16:57:21,407:INFO:Starting cross validation
2024-01-18 16:57:21,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:22,355:INFO:Calculating mean and std
2024-01-18 16:57:22,362:INFO:Creating metrics dataframe
2024-01-18 16:57:22,362:INFO:Uploading results into container
2024-01-18 16:57:22,362:INFO:Uploading model into container now
2024-01-18 16:57:22,362:INFO:_master_model_container: 3
2024-01-18 16:57:22,362:INFO:_display_container: 2
2024-01-18 16:57:22,362:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-18 16:57:22,362:INFO:create_model() successfully completed......................................
2024-01-18 16:57:22,485:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:22,485:INFO:Creating metrics dataframe
2024-01-18 16:57:22,501:INFO:Initializing Decision Tree Classifier
2024-01-18 16:57:22,501:INFO:Total runtime is 1.1681592504183451 minutes
2024-01-18 16:57:22,501:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:22,501:INFO:Initializing create_model()
2024-01-18 16:57:22,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:22,501:INFO:Checking exceptions
2024-01-18 16:57:22,501:INFO:Importing libraries
2024-01-18 16:57:22,501:INFO:Copying training dataset
2024-01-18 16:57:22,514:INFO:Defining folds
2024-01-18 16:57:22,514:INFO:Declaring metric variables
2024-01-18 16:57:22,518:INFO:Importing untrained model
2024-01-18 16:57:22,524:INFO:Decision Tree Classifier Imported successfully
2024-01-18 16:57:22,532:INFO:Starting cross validation
2024-01-18 16:57:22,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:23,692:INFO:Calculating mean and std
2024-01-18 16:57:23,692:INFO:Creating metrics dataframe
2024-01-18 16:57:23,692:INFO:Uploading results into container
2024-01-18 16:57:23,692:INFO:Uploading model into container now
2024-01-18 16:57:23,692:INFO:_master_model_container: 4
2024-01-18 16:57:23,692:INFO:_display_container: 2
2024-01-18 16:57:23,692:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7788, splitter='best')
2024-01-18 16:57:23,692:INFO:create_model() successfully completed......................................
2024-01-18 16:57:23,834:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:23,849:INFO:Creating metrics dataframe
2024-01-18 16:57:23,864:INFO:Initializing SVM - Linear Kernel
2024-01-18 16:57:23,864:INFO:Total runtime is 1.1908904631932575 minutes
2024-01-18 16:57:23,864:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:23,864:INFO:Initializing create_model()
2024-01-18 16:57:23,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:23,870:INFO:Checking exceptions
2024-01-18 16:57:23,870:INFO:Importing libraries
2024-01-18 16:57:23,870:INFO:Copying training dataset
2024-01-18 16:57:23,876:INFO:Defining folds
2024-01-18 16:57:23,876:INFO:Declaring metric variables
2024-01-18 16:57:23,876:INFO:Importing untrained model
2024-01-18 16:57:23,889:INFO:SVM - Linear Kernel Imported successfully
2024-01-18 16:57:23,897:INFO:Starting cross validation
2024-01-18 16:57:23,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:24,620:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:24,620:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:24,620:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:24,620:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:24,950:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:24,950:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:24,950:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:24,971:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:25,155:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:25,155:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 16:57:25,171:INFO:Calculating mean and std
2024-01-18 16:57:25,171:INFO:Creating metrics dataframe
2024-01-18 16:57:25,171:INFO:Uploading results into container
2024-01-18 16:57:25,171:INFO:Uploading model into container now
2024-01-18 16:57:25,171:INFO:_master_model_container: 5
2024-01-18 16:57:25,171:INFO:_display_container: 2
2024-01-18 16:57:25,171:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7788, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-18 16:57:25,171:INFO:create_model() successfully completed......................................
2024-01-18 16:57:25,333:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:25,333:INFO:Creating metrics dataframe
2024-01-18 16:57:25,369:INFO:Initializing Ridge Classifier
2024-01-18 16:57:25,370:INFO:Total runtime is 1.2159762461980184 minutes
2024-01-18 16:57:25,371:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:25,371:INFO:Initializing create_model()
2024-01-18 16:57:25,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:25,371:INFO:Checking exceptions
2024-01-18 16:57:25,371:INFO:Importing libraries
2024-01-18 16:57:25,371:INFO:Copying training dataset
2024-01-18 16:57:25,387:INFO:Defining folds
2024-01-18 16:57:25,387:INFO:Declaring metric variables
2024-01-18 16:57:25,392:INFO:Importing untrained model
2024-01-18 16:57:25,396:INFO:Ridge Classifier Imported successfully
2024-01-18 16:57:25,406:INFO:Starting cross validation
2024-01-18 16:57:25,406:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:26,422:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,424:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,425:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,425:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,638:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,653:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,654:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,654:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,841:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,841:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 16:57:26,856:INFO:Calculating mean and std
2024-01-18 16:57:26,856:INFO:Creating metrics dataframe
2024-01-18 16:57:26,856:INFO:Uploading results into container
2024-01-18 16:57:26,856:INFO:Uploading model into container now
2024-01-18 16:57:26,856:INFO:_master_model_container: 6
2024-01-18 16:57:26,856:INFO:_display_container: 2
2024-01-18 16:57:26,856:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7788, solver='auto',
                tol=0.0001)
2024-01-18 16:57:26,856:INFO:create_model() successfully completed......................................
2024-01-18 16:57:27,000:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:27,000:INFO:Creating metrics dataframe
2024-01-18 16:57:27,016:INFO:Initializing Random Forest Classifier
2024-01-18 16:57:27,016:INFO:Total runtime is 1.24340869585673 minutes
2024-01-18 16:57:27,016:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:27,016:INFO:Initializing create_model()
2024-01-18 16:57:27,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:27,016:INFO:Checking exceptions
2024-01-18 16:57:27,016:INFO:Importing libraries
2024-01-18 16:57:27,016:INFO:Copying training dataset
2024-01-18 16:57:27,033:INFO:Defining folds
2024-01-18 16:57:27,033:INFO:Declaring metric variables
2024-01-18 16:57:27,039:INFO:Importing untrained model
2024-01-18 16:57:27,044:INFO:Random Forest Classifier Imported successfully
2024-01-18 16:57:27,059:INFO:Starting cross validation
2024-01-18 16:57:27,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:30,469:INFO:Calculating mean and std
2024-01-18 16:57:30,469:INFO:Creating metrics dataframe
2024-01-18 16:57:30,474:INFO:Uploading results into container
2024-01-18 16:57:30,476:INFO:Uploading model into container now
2024-01-18 16:57:30,477:INFO:_master_model_container: 7
2024-01-18 16:57:30,477:INFO:_display_container: 2
2024-01-18 16:57:30,478:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7788, verbose=0, warm_start=False)
2024-01-18 16:57:30,478:INFO:create_model() successfully completed......................................
2024-01-18 16:57:30,634:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:30,634:INFO:Creating metrics dataframe
2024-01-18 16:57:30,645:INFO:Initializing Quadratic Discriminant Analysis
2024-01-18 16:57:30,645:INFO:Total runtime is 1.3038970470428466 minutes
2024-01-18 16:57:30,649:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:30,650:INFO:Initializing create_model()
2024-01-18 16:57:30,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:30,650:INFO:Checking exceptions
2024-01-18 16:57:30,650:INFO:Importing libraries
2024-01-18 16:57:30,650:INFO:Copying training dataset
2024-01-18 16:57:30,659:INFO:Defining folds
2024-01-18 16:57:30,660:INFO:Declaring metric variables
2024-01-18 16:57:30,666:INFO:Importing untrained model
2024-01-18 16:57:30,672:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-18 16:57:30,682:INFO:Starting cross validation
2024-01-18 16:57:30,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:31,372:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:57:31,372:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:57:31,372:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:57:31,734:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:57:31,734:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:57:31,734:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:57:31,749:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:57:31,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:57:31,906:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 16:57:31,954:INFO:Calculating mean and std
2024-01-18 16:57:32,173:INFO:Creating metrics dataframe
2024-01-18 16:57:32,189:INFO:Uploading results into container
2024-01-18 16:57:32,191:INFO:Uploading model into container now
2024-01-18 16:57:32,193:INFO:_master_model_container: 8
2024-01-18 16:57:32,193:INFO:_display_container: 2
2024-01-18 16:57:32,193:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-18 16:57:32,193:INFO:create_model() successfully completed......................................
2024-01-18 16:57:32,365:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:32,365:INFO:Creating metrics dataframe
2024-01-18 16:57:32,385:INFO:Initializing Ada Boost Classifier
2024-01-18 16:57:32,385:INFO:Total runtime is 1.332901875178019 minutes
2024-01-18 16:57:32,399:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:32,399:INFO:Initializing create_model()
2024-01-18 16:57:32,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:32,400:INFO:Checking exceptions
2024-01-18 16:57:32,400:INFO:Importing libraries
2024-01-18 16:57:32,400:INFO:Copying training dataset
2024-01-18 16:57:32,409:INFO:Defining folds
2024-01-18 16:57:32,409:INFO:Declaring metric variables
2024-01-18 16:57:32,416:INFO:Importing untrained model
2024-01-18 16:57:32,422:INFO:Ada Boost Classifier Imported successfully
2024-01-18 16:57:32,425:INFO:Starting cross validation
2024-01-18 16:57:32,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:34,364:INFO:Calculating mean and std
2024-01-18 16:57:34,364:INFO:Creating metrics dataframe
2024-01-18 16:57:34,364:INFO:Uploading results into container
2024-01-18 16:57:34,364:INFO:Uploading model into container now
2024-01-18 16:57:34,364:INFO:_master_model_container: 9
2024-01-18 16:57:34,364:INFO:_display_container: 2
2024-01-18 16:57:34,364:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7788)
2024-01-18 16:57:34,364:INFO:create_model() successfully completed......................................
2024-01-18 16:57:34,515:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:34,515:INFO:Creating metrics dataframe
2024-01-18 16:57:34,532:INFO:Initializing Gradient Boosting Classifier
2024-01-18 16:57:34,533:INFO:Total runtime is 1.3687026619911193 minutes
2024-01-18 16:57:34,540:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:34,541:INFO:Initializing create_model()
2024-01-18 16:57:34,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:34,541:INFO:Checking exceptions
2024-01-18 16:57:34,541:INFO:Importing libraries
2024-01-18 16:57:34,541:INFO:Copying training dataset
2024-01-18 16:57:34,553:INFO:Defining folds
2024-01-18 16:57:34,553:INFO:Declaring metric variables
2024-01-18 16:57:34,559:INFO:Importing untrained model
2024-01-18 16:57:34,559:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 16:57:34,574:INFO:Starting cross validation
2024-01-18 16:57:34,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:38,489:INFO:Calculating mean and std
2024-01-18 16:57:38,489:INFO:Creating metrics dataframe
2024-01-18 16:57:38,489:INFO:Uploading results into container
2024-01-18 16:57:38,489:INFO:Uploading model into container now
2024-01-18 16:57:38,489:INFO:_master_model_container: 10
2024-01-18 16:57:38,489:INFO:_display_container: 2
2024-01-18 16:57:38,489:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7788, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 16:57:38,489:INFO:create_model() successfully completed......................................
2024-01-18 16:57:38,634:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:38,649:INFO:Creating metrics dataframe
2024-01-18 16:57:38,675:INFO:Initializing Linear Discriminant Analysis
2024-01-18 16:57:38,675:INFO:Total runtime is 1.4377281347910562 minutes
2024-01-18 16:57:38,683:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:38,684:INFO:Initializing create_model()
2024-01-18 16:57:38,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:38,685:INFO:Checking exceptions
2024-01-18 16:57:38,685:INFO:Importing libraries
2024-01-18 16:57:38,685:INFO:Copying training dataset
2024-01-18 16:57:38,691:INFO:Defining folds
2024-01-18 16:57:38,692:INFO:Declaring metric variables
2024-01-18 16:57:38,698:INFO:Importing untrained model
2024-01-18 16:57:38,703:INFO:Linear Discriminant Analysis Imported successfully
2024-01-18 16:57:38,710:INFO:Starting cross validation
2024-01-18 16:57:38,712:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:39,860:INFO:Calculating mean and std
2024-01-18 16:57:39,860:INFO:Creating metrics dataframe
2024-01-18 16:57:39,860:INFO:Uploading results into container
2024-01-18 16:57:39,860:INFO:Uploading model into container now
2024-01-18 16:57:39,860:INFO:_master_model_container: 11
2024-01-18 16:57:39,860:INFO:_display_container: 2
2024-01-18 16:57:39,860:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-18 16:57:39,860:INFO:create_model() successfully completed......................................
2024-01-18 16:57:40,020:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:40,020:INFO:Creating metrics dataframe
2024-01-18 16:57:40,039:INFO:Initializing Extra Trees Classifier
2024-01-18 16:57:40,039:INFO:Total runtime is 1.4604726910591124 minutes
2024-01-18 16:57:40,042:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:40,043:INFO:Initializing create_model()
2024-01-18 16:57:40,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:40,043:INFO:Checking exceptions
2024-01-18 16:57:40,043:INFO:Importing libraries
2024-01-18 16:57:40,043:INFO:Copying training dataset
2024-01-18 16:57:40,048:INFO:Defining folds
2024-01-18 16:57:40,048:INFO:Declaring metric variables
2024-01-18 16:57:40,052:INFO:Importing untrained model
2024-01-18 16:57:40,053:INFO:Extra Trees Classifier Imported successfully
2024-01-18 16:57:40,068:INFO:Starting cross validation
2024-01-18 16:57:40,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:43,320:INFO:Calculating mean and std
2024-01-18 16:57:43,335:INFO:Creating metrics dataframe
2024-01-18 16:57:43,335:INFO:Uploading results into container
2024-01-18 16:57:43,335:INFO:Uploading model into container now
2024-01-18 16:57:43,335:INFO:_master_model_container: 12
2024-01-18 16:57:43,335:INFO:_display_container: 2
2024-01-18 16:57:43,335:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7788, verbose=0, warm_start=False)
2024-01-18 16:57:43,345:INFO:create_model() successfully completed......................................
2024-01-18 16:57:43,466:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:43,466:INFO:Creating metrics dataframe
2024-01-18 16:57:43,497:INFO:Initializing Extreme Gradient Boosting
2024-01-18 16:57:43,497:INFO:Total runtime is 1.5181019902229307 minutes
2024-01-18 16:57:43,515:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:43,516:INFO:Initializing create_model()
2024-01-18 16:57:43,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:43,516:INFO:Checking exceptions
2024-01-18 16:57:43,517:INFO:Importing libraries
2024-01-18 16:57:43,517:INFO:Copying training dataset
2024-01-18 16:57:43,523:INFO:Defining folds
2024-01-18 16:57:43,524:INFO:Declaring metric variables
2024-01-18 16:57:43,529:INFO:Importing untrained model
2024-01-18 16:57:43,534:INFO:Extreme Gradient Boosting Imported successfully
2024-01-18 16:57:43,541:INFO:Starting cross validation
2024-01-18 16:57:43,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:45,998:INFO:Calculating mean and std
2024-01-18 16:57:45,998:INFO:Creating metrics dataframe
2024-01-18 16:57:45,998:INFO:Uploading results into container
2024-01-18 16:57:45,998:INFO:Uploading model into container now
2024-01-18 16:57:45,998:INFO:_master_model_container: 13
2024-01-18 16:57:45,998:INFO:_display_container: 2
2024-01-18 16:57:46,013:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-18 16:57:46,013:INFO:create_model() successfully completed......................................
2024-01-18 16:57:46,162:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:46,162:INFO:Creating metrics dataframe
2024-01-18 16:57:46,197:INFO:Initializing Light Gradient Boosting Machine
2024-01-18 16:57:46,198:INFO:Total runtime is 1.5631181995073953 minutes
2024-01-18 16:57:46,203:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:46,203:INFO:Initializing create_model()
2024-01-18 16:57:46,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:46,203:INFO:Checking exceptions
2024-01-18 16:57:46,203:INFO:Importing libraries
2024-01-18 16:57:46,203:INFO:Copying training dataset
2024-01-18 16:57:46,203:INFO:Defining folds
2024-01-18 16:57:46,203:INFO:Declaring metric variables
2024-01-18 16:57:46,203:INFO:Importing untrained model
2024-01-18 16:57:46,221:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 16:57:46,229:INFO:Starting cross validation
2024-01-18 16:57:46,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:57:47,853:INFO:Calculating mean and std
2024-01-18 16:57:47,853:INFO:Creating metrics dataframe
2024-01-18 16:57:47,853:INFO:Uploading results into container
2024-01-18 16:57:47,869:INFO:Uploading model into container now
2024-01-18 16:57:47,870:INFO:_master_model_container: 14
2024-01-18 16:57:47,870:INFO:_display_container: 2
2024-01-18 16:57:47,871:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:57:47,871:INFO:create_model() successfully completed......................................
2024-01-18 16:57:47,997:INFO:SubProcess create_model() end ==================================
2024-01-18 16:57:47,997:INFO:Creating metrics dataframe
2024-01-18 16:57:48,031:INFO:Initializing CatBoost Classifier
2024-01-18 16:57:48,032:INFO:Total runtime is 1.5936851302782693 minutes
2024-01-18 16:57:48,037:INFO:SubProcess create_model() called ==================================
2024-01-18 16:57:48,038:INFO:Initializing create_model()
2024-01-18 16:57:48,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:57:48,039:INFO:Checking exceptions
2024-01-18 16:57:48,039:INFO:Importing libraries
2024-01-18 16:57:48,039:INFO:Copying training dataset
2024-01-18 16:57:48,047:INFO:Defining folds
2024-01-18 16:57:48,047:INFO:Declaring metric variables
2024-01-18 16:57:48,054:INFO:Importing untrained model
2024-01-18 16:57:48,059:INFO:CatBoost Classifier Imported successfully
2024-01-18 16:57:48,069:INFO:Starting cross validation
2024-01-18 16:57:48,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:58:18,138:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,138:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,138:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,138:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,138:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,138:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,148:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,148:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,148:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,148:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,148:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:18,148:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,643:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,643:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,643:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,643:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,643:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,643:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:32,692:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,884:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 16:58:40,900:INFO:Calculating mean and std
2024-01-18 16:58:40,900:INFO:Creating metrics dataframe
2024-01-18 16:58:40,900:INFO:Uploading results into container
2024-01-18 16:58:40,900:INFO:Uploading model into container now
2024-01-18 16:58:40,900:INFO:_master_model_container: 15
2024-01-18 16:58:40,900:INFO:_display_container: 2
2024-01-18 16:58:40,900:INFO:<catboost.core.CatBoostClassifier object at 0x000001EFC36A8690>
2024-01-18 16:58:40,900:INFO:create_model() successfully completed......................................
2024-01-18 16:58:41,046:INFO:SubProcess create_model() end ==================================
2024-01-18 16:58:41,046:INFO:Creating metrics dataframe
2024-01-18 16:58:41,078:INFO:Initializing Dummy Classifier
2024-01-18 16:58:41,078:INFO:Total runtime is 2.477775796254476 minutes
2024-01-18 16:58:41,084:INFO:SubProcess create_model() called ==================================
2024-01-18 16:58:41,084:INFO:Initializing create_model()
2024-01-18 16:58:41,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFC852AB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:58:41,085:INFO:Checking exceptions
2024-01-18 16:58:41,085:INFO:Importing libraries
2024-01-18 16:58:41,085:INFO:Copying training dataset
2024-01-18 16:58:41,092:INFO:Defining folds
2024-01-18 16:58:41,093:INFO:Declaring metric variables
2024-01-18 16:58:41,099:INFO:Importing untrained model
2024-01-18 16:58:41,105:INFO:Dummy Classifier Imported successfully
2024-01-18 16:58:41,113:INFO:Starting cross validation
2024-01-18 16:58:41,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 16:58:41,898:INFO:Calculating mean and std
2024-01-18 16:58:41,914:INFO:Creating metrics dataframe
2024-01-18 16:58:41,914:INFO:Uploading results into container
2024-01-18 16:58:41,914:INFO:Uploading model into container now
2024-01-18 16:58:41,914:INFO:_master_model_container: 16
2024-01-18 16:58:41,914:INFO:_display_container: 2
2024-01-18 16:58:41,914:INFO:DummyClassifier(constant=None, random_state=7788, strategy='prior')
2024-01-18 16:58:41,914:INFO:create_model() successfully completed......................................
2024-01-18 16:58:42,046:INFO:SubProcess create_model() end ==================================
2024-01-18 16:58:42,046:INFO:Creating metrics dataframe
2024-01-18 16:58:42,077:INFO:Initializing create_model()
2024-01-18 16:58:42,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 16:58:42,077:INFO:Checking exceptions
2024-01-18 16:58:42,080:INFO:Importing libraries
2024-01-18 16:58:42,080:INFO:Copying training dataset
2024-01-18 16:58:42,085:INFO:Defining folds
2024-01-18 16:58:42,085:INFO:Declaring metric variables
2024-01-18 16:58:42,086:INFO:Importing untrained model
2024-01-18 16:58:42,086:INFO:Declaring custom model
2024-01-18 16:58:42,087:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 16:58:42,088:INFO:Cross validation set to False
2024-01-18 16:58:42,088:INFO:Fitting Model
2024-01-18 16:58:42,201:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-18 16:58:42,201:INFO:[LightGBM] [Info] Number of positive: 3065, number of negative: 3020
2024-01-18 16:58:42,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.
2024-01-18 16:58:42,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-18 16:58:42,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-18 16:58:42,201:INFO:[LightGBM] [Info] Total Bins 1371
2024-01-18 16:58:42,201:INFO:[LightGBM] [Info] Number of data points in the train set: 6085, number of used features: 14
2024-01-18 16:58:42,216:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503698 -> initscore=0.014791
2024-01-18 16:58:42,216:INFO:[LightGBM] [Info] Start training from score 0.014791
2024-01-18 16:58:42,305:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:58:42,305:INFO:create_model() successfully completed......................................
2024-01-18 16:58:42,486:INFO:_master_model_container: 16
2024-01-18 16:58:42,487:INFO:_display_container: 2
2024-01-18 16:58:42,487:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 16:58:42,488:INFO:compare_models() successfully completed......................................
2024-01-18 17:07:17,672:INFO:Initializing finalize_model()
2024-01-18 17:07:17,672:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-18 17:07:17,672:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 17:07:17,677:INFO:Initializing create_model()
2024-01-18 17:07:17,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 17:07:17,677:INFO:Checking exceptions
2024-01-18 17:07:17,679:INFO:Importing libraries
2024-01-18 17:07:17,679:INFO:Copying training dataset
2024-01-18 17:07:17,680:INFO:Defining folds
2024-01-18 17:07:17,680:INFO:Declaring metric variables
2024-01-18 17:07:17,680:INFO:Importing untrained model
2024-01-18 17:07:17,680:INFO:Declaring custom model
2024-01-18 17:07:17,681:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 17:07:17,682:INFO:Cross validation set to False
2024-01-18 17:07:17,682:INFO:Fitting Model
2024-01-18 17:07:17,852:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-18 17:07:17,852:INFO:[LightGBM] [Info] Number of positive: 4378, number of negative: 4315
2024-01-18 17:07:17,852:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.
2024-01-18 17:07:17,852:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-18 17:07:17,852:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-18 17:07:17,852:INFO:[LightGBM] [Info] Total Bins 1372
2024-01-18 17:07:17,852:INFO:[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 14
2024-01-18 17:07:17,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495
2024-01-18 17:07:17,852:INFO:[LightGBM] [Info] Start training from score 0.014495
2024-01-18 17:07:18,131:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=7788, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-18 17:07:18,131:INFO:create_model() successfully completed......................................
2024-01-18 17:07:18,289:INFO:_master_model_container: 16
2024-01-18 17:07:18,289:INFO:_display_container: 2
2024-01-18 17:07:18,415:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=7788, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-18 17:07:18,415:INFO:finalize_model() successfully completed......................................
2024-01-18 17:07:19,685:INFO:Initializing evaluate_model()
2024-01-18 17:07:19,686:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-18 17:07:20,582:INFO:Initializing plot_model()
2024-01-18 17:07:20,582:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 17:07:20,582:INFO:Checking exceptions
2024-01-18 17:07:20,589:INFO:Preloading libraries
2024-01-18 17:07:20,603:INFO:Copying training dataset
2024-01-18 17:07:20,603:INFO:Plot type: pipeline
2024-01-18 17:07:26,233:INFO:Visual Rendered Successfully
2024-01-18 17:07:26,375:INFO:plot_model() successfully completed......................................
2024-01-18 17:07:26,489:INFO:Initializing predict_model()
2024-01-18 17:07:26,489:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EFC73B8D60>)
2024-01-18 17:07:26,490:INFO:Checking exceptions
2024-01-18 17:07:26,490:INFO:Preloading libraries
2024-01-18 17:07:27,882:INFO:Initializing predict_model()
2024-01-18 17:07:27,883:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC6C0F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7788, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EFC31E2FC0>)
2024-01-18 17:07:27,883:INFO:Checking exceptions
2024-01-18 17:07:27,883:INFO:Preloading libraries
2024-01-18 17:07:27,885:INFO:Set up data.
2024-01-18 17:07:27,895:INFO:Set up index.
2024-01-18 17:12:25,962:WARNING:C:\Users\Auditor\AppData\Local\Temp\ipykernel_15080\2851369854.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.
  pd.concat(train_final,last_column, axis =1)

2024-01-18 17:29:50,092:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:29:51,096:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:29:52,307:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:29:57,747:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\joblib\externals\loky\backend\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2024-01-18 17:37:53,307:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:37:54,157:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:37:54,236:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:26,237:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:26,946:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:26,962:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:27,591:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:27,591:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:28,171:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:28,171:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:28,745:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:28,745:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:29,308:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:29,324:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:29,793:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:29,808:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:30,341:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:30,356:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:30,889:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:30,910:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:31,488:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:32,320:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:32,962:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:32,962:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:32,978:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:32,978:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:32,993:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:32,993:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,009:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,009:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,025:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,025:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,025:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,040:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,040:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,040:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,056:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,056:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,056:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,072:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,072:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,072:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,088:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,779:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,796:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,802:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,818:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,822:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,838:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,843:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,858:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,863:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,878:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,884:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,907:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,913:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,928:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,929:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,943:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,952:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,966:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:39:33,970:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 17:39:33,979:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 17:58:41,170:INFO:PyCaret ClassificationExperiment
2024-01-18 17:58:41,185:INFO:Logging name: clf-default-name
2024-01-18 17:58:41,185:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 17:58:41,185:INFO:version 3.2.0
2024-01-18 17:58:41,185:INFO:Initializing setup()
2024-01-18 17:58:41,185:INFO:self.USI: ce07
2024-01-18 17:58:41,185:INFO:self._variable_keys: {'y', 'log_plots_param', 'fold_groups_param', 'fix_imbalance', 'USI', 'X_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'X_train', 'exp_name_log', 'idx', 'y_train', 'X', 'logging_param', 'n_jobs_param', 'pipeline', 'seed', '_available_plots', 'gpu_n_jobs_param', 'y_test', 'data', 'fold_shuffle_param', 'gpu_param', 'memory', 'fold_generator', 'target_param', 'html_param'}
2024-01-18 17:58:41,185:INFO:Checking environment
2024-01-18 17:58:41,185:INFO:python_version: 3.11.5
2024-01-18 17:58:41,185:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 17:58:41,185:INFO:machine: AMD64
2024-01-18 17:58:41,185:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 17:58:41,185:INFO:Memory: svmem(total=8361132032, available=1679253504, percent=79.9, used=6681878528, free=1679253504)
2024-01-18 17:58:41,185:INFO:Physical Core: 2
2024-01-18 17:58:41,185:INFO:Logical Core: 4
2024-01-18 17:58:41,185:INFO:Checking libraries
2024-01-18 17:58:41,185:INFO:System:
2024-01-18 17:58:41,185:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 17:58:41,185:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 17:58:41,185:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 17:58:41,185:INFO:PyCaret required dependencies:
2024-01-18 17:58:41,185:INFO:                 pip: 23.2.1
2024-01-18 17:58:41,185:INFO:          setuptools: 68.0.0
2024-01-18 17:58:41,185:INFO:             pycaret: 3.2.0
2024-01-18 17:58:41,185:INFO:             IPython: 8.15.0
2024-01-18 17:58:41,185:INFO:          ipywidgets: 8.0.4
2024-01-18 17:58:41,185:INFO:                tqdm: 4.65.0
2024-01-18 17:58:41,185:INFO:               numpy: 1.24.3
2024-01-18 17:58:41,185:INFO:              pandas: 1.5.3
2024-01-18 17:58:41,185:INFO:              jinja2: 3.1.2
2024-01-18 17:58:41,185:INFO:               scipy: 1.10.1
2024-01-18 17:58:41,185:INFO:              joblib: 1.2.0
2024-01-18 17:58:41,185:INFO:             sklearn: 1.2.2
2024-01-18 17:58:41,185:INFO:                pyod: 1.1.2
2024-01-18 17:58:41,185:INFO:            imblearn: 0.10.1
2024-01-18 17:58:41,185:INFO:   category_encoders: 2.6.3
2024-01-18 17:58:41,185:INFO:            lightgbm: 4.2.0
2024-01-18 17:58:41,185:INFO:               numba: 0.57.1
2024-01-18 17:58:41,185:INFO:            requests: 2.31.0
2024-01-18 17:58:41,185:INFO:          matplotlib: 3.6.0
2024-01-18 17:58:41,185:INFO:          scikitplot: 0.3.7
2024-01-18 17:58:41,185:INFO:         yellowbrick: 1.5
2024-01-18 17:58:41,185:INFO:              plotly: 5.9.0
2024-01-18 17:58:41,185:INFO:    plotly-resampler: Not installed
2024-01-18 17:58:41,185:INFO:             kaleido: 0.2.1
2024-01-18 17:58:41,185:INFO:           schemdraw: 0.15
2024-01-18 17:58:41,185:INFO:         statsmodels: 0.14.0
2024-01-18 17:58:41,185:INFO:              sktime: 0.21.1
2024-01-18 17:58:41,185:INFO:               tbats: 1.1.3
2024-01-18 17:58:41,185:INFO:            pmdarima: 2.0.4
2024-01-18 17:58:41,185:INFO:              psutil: 5.9.0
2024-01-18 17:58:41,185:INFO:          markupsafe: 2.1.1
2024-01-18 17:58:41,185:INFO:             pickle5: Not installed
2024-01-18 17:58:41,185:INFO:         cloudpickle: 2.2.1
2024-01-18 17:58:41,185:INFO:         deprecation: 2.1.0
2024-01-18 17:58:41,185:INFO:              xxhash: 2.0.2
2024-01-18 17:58:41,185:INFO:           wurlitzer: Not installed
2024-01-18 17:58:41,185:INFO:PyCaret optional dependencies:
2024-01-18 17:58:41,185:INFO:                shap: Not installed
2024-01-18 17:58:41,185:INFO:           interpret: Not installed
2024-01-18 17:58:41,185:INFO:                umap: Not installed
2024-01-18 17:58:41,185:INFO:     ydata_profiling: Not installed
2024-01-18 17:58:41,185:INFO:  explainerdashboard: Not installed
2024-01-18 17:58:41,185:INFO:             autoviz: Not installed
2024-01-18 17:58:41,185:INFO:           fairlearn: Not installed
2024-01-18 17:58:41,185:INFO:          deepchecks: Not installed
2024-01-18 17:58:41,185:INFO:             xgboost: 2.0.3
2024-01-18 17:58:41,185:INFO:            catboost: 1.2.2
2024-01-18 17:58:41,185:INFO:              kmodes: Not installed
2024-01-18 17:58:41,185:INFO:             mlxtend: Not installed
2024-01-18 17:58:41,185:INFO:       statsforecast: Not installed
2024-01-18 17:58:41,185:INFO:        tune_sklearn: Not installed
2024-01-18 17:58:41,185:INFO:                 ray: Not installed
2024-01-18 17:58:41,185:INFO:            hyperopt: Not installed
2024-01-18 17:58:41,185:INFO:              optuna: 3.5.0
2024-01-18 17:58:41,185:INFO:               skopt: Not installed
2024-01-18 17:58:41,185:INFO:              mlflow: Not installed
2024-01-18 17:58:41,185:INFO:              gradio: Not installed
2024-01-18 17:58:41,185:INFO:             fastapi: Not installed
2024-01-18 17:58:41,185:INFO:             uvicorn: Not installed
2024-01-18 17:58:41,185:INFO:              m2cgen: Not installed
2024-01-18 17:58:41,185:INFO:           evidently: Not installed
2024-01-18 17:58:41,185:INFO:               fugue: Not installed
2024-01-18 17:58:41,201:INFO:           streamlit: Not installed
2024-01-18 17:58:41,201:INFO:             prophet: Not installed
2024-01-18 17:58:41,201:INFO:None
2024-01-18 17:58:41,201:INFO:Set up data.
2024-01-18 17:58:41,202:INFO:Set up folding strategy.
2024-01-18 17:58:41,202:INFO:Set up train/test split.
2024-01-18 17:58:41,217:INFO:Set up index.
2024-01-18 17:58:41,217:INFO:Assigning column types.
2024-01-18 17:58:41,217:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 17:58:41,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 17:58:41,264:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 17:58:41,327:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 17:58:41,342:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 17:58:41,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 17:58:41,390:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 17:58:41,421:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 17:58:41,453:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 17:58:41,453:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 17:58:41,500:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 17:58:41,547:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 17:58:41,547:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 17:58:41,594:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 17:58:41,625:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 17:58:41,625:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 17:58:41,625:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 17:58:41,703:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 17:58:41,703:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 17:58:41,781:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 17:58:41,781:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 17:58:41,781:INFO:Preparing preprocessing pipeline...
2024-01-18 17:58:41,781:INFO:Set up simple imputation.
2024-01-18 17:58:41,798:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\preprocess\preprocessor.py:653: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.
  for name, column in X_transformed[self._fxs["Categorical"]].items():

2024-01-18 17:58:41,798:INFO:Set up encoding of ordinal features.
2024-01-18 17:58:41,829:INFO:Set up encoding of categorical features.
2024-01-18 17:58:41,829:INFO:Set up column name cleaning.
2024-01-18 17:58:42,023:INFO:Finished creating preprocessing pipeline.
2024-01-18 17:58:42,130:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -0.316951    0
 3.155058    1
 NaN        -1
dtype: int64},
                                                                        {'col': 'Destination_TRAPPIST-1e',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -1.546237    0
 0.646731    1
 NaN        -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 17:58:42,130:INFO:Creating final display dataframe.
2024-01-18 17:58:42,403:INFO:Setup _display_container:                     Description             Value
0                    Session id              5817
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Ordinal features                 8
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              ce07
2024-01-18 17:58:42,514:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 17:58:42,514:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 17:58:42,626:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 17:58:42,631:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 17:58:42,631:INFO:setup() successfully completed in 1.84s...............
2024-01-18 17:58:51,009:INFO:Initializing compare_models()
2024-01-18 17:58:51,009:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-18 17:58:51,009:INFO:Checking exceptions
2024-01-18 17:58:51,015:INFO:Preparing display monitor
2024-01-18 17:58:51,041:INFO:Initializing Logistic Regression
2024-01-18 17:58:51,041:INFO:Total runtime is 0.0 minutes
2024-01-18 17:58:51,046:INFO:SubProcess create_model() called ==================================
2024-01-18 17:58:51,047:INFO:Initializing create_model()
2024-01-18 17:58:51,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 17:58:51,047:INFO:Checking exceptions
2024-01-18 17:58:51,047:INFO:Importing libraries
2024-01-18 17:58:51,047:INFO:Copying training dataset
2024-01-18 17:58:51,059:INFO:Defining folds
2024-01-18 17:58:51,061:INFO:Declaring metric variables
2024-01-18 17:58:51,068:INFO:Importing untrained model
2024-01-18 17:58:51,075:INFO:Logistic Regression Imported successfully
2024-01-18 17:58:51,101:INFO:Starting cross validation
2024-01-18 17:58:51,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 17:59:57,678:INFO:Calculating mean and std
2024-01-18 17:59:57,694:INFO:Creating metrics dataframe
2024-01-18 17:59:57,699:INFO:Uploading results into container
2024-01-18 17:59:57,699:INFO:Uploading model into container now
2024-01-18 17:59:57,701:INFO:_master_model_container: 1
2024-01-18 17:59:57,701:INFO:_display_container: 2
2024-01-18 17:59:57,702:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5817, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-18 17:59:57,702:INFO:create_model() successfully completed......................................
2024-01-18 17:59:58,011:INFO:SubProcess create_model() end ==================================
2024-01-18 17:59:58,012:INFO:Creating metrics dataframe
2024-01-18 17:59:58,019:INFO:Initializing K Neighbors Classifier
2024-01-18 17:59:58,019:INFO:Total runtime is 1.1162981271743775 minutes
2024-01-18 17:59:58,024:INFO:SubProcess create_model() called ==================================
2024-01-18 17:59:58,025:INFO:Initializing create_model()
2024-01-18 17:59:58,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 17:59:58,025:INFO:Checking exceptions
2024-01-18 17:59:58,025:INFO:Importing libraries
2024-01-18 17:59:58,025:INFO:Copying training dataset
2024-01-18 17:59:58,032:INFO:Defining folds
2024-01-18 17:59:58,033:INFO:Declaring metric variables
2024-01-18 17:59:58,037:INFO:Importing untrained model
2024-01-18 17:59:58,047:INFO:K Neighbors Classifier Imported successfully
2024-01-18 17:59:58,056:INFO:Starting cross validation
2024-01-18 17:59:58,058:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 17:59:59,499:INFO:Calculating mean and std
2024-01-18 17:59:59,499:INFO:Creating metrics dataframe
2024-01-18 17:59:59,519:INFO:Uploading results into container
2024-01-18 17:59:59,520:INFO:Uploading model into container now
2024-01-18 17:59:59,520:INFO:_master_model_container: 2
2024-01-18 17:59:59,522:INFO:_display_container: 2
2024-01-18 17:59:59,522:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-18 17:59:59,522:INFO:create_model() successfully completed......................................
2024-01-18 17:59:59,762:INFO:SubProcess create_model() end ==================================
2024-01-18 17:59:59,762:INFO:Creating metrics dataframe
2024-01-18 17:59:59,774:INFO:Initializing Naive Bayes
2024-01-18 17:59:59,774:INFO:Total runtime is 1.1455474932988485 minutes
2024-01-18 17:59:59,781:INFO:SubProcess create_model() called ==================================
2024-01-18 17:59:59,781:INFO:Initializing create_model()
2024-01-18 17:59:59,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 17:59:59,782:INFO:Checking exceptions
2024-01-18 17:59:59,782:INFO:Importing libraries
2024-01-18 17:59:59,782:INFO:Copying training dataset
2024-01-18 17:59:59,790:INFO:Defining folds
2024-01-18 17:59:59,791:INFO:Declaring metric variables
2024-01-18 17:59:59,796:INFO:Importing untrained model
2024-01-18 17:59:59,802:INFO:Naive Bayes Imported successfully
2024-01-18 17:59:59,810:INFO:Starting cross validation
2024-01-18 17:59:59,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:00,820:INFO:Calculating mean and std
2024-01-18 18:00:00,820:INFO:Creating metrics dataframe
2024-01-18 18:00:00,835:INFO:Uploading results into container
2024-01-18 18:00:00,837:INFO:Uploading model into container now
2024-01-18 18:00:00,837:INFO:_master_model_container: 3
2024-01-18 18:00:00,837:INFO:_display_container: 2
2024-01-18 18:00:00,837:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-18 18:00:00,837:INFO:create_model() successfully completed......................................
2024-01-18 18:00:01,088:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:01,088:INFO:Creating metrics dataframe
2024-01-18 18:00:01,088:INFO:Initializing Decision Tree Classifier
2024-01-18 18:00:01,088:INFO:Total runtime is 1.167454187075297 minutes
2024-01-18 18:00:01,105:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:01,105:INFO:Initializing create_model()
2024-01-18 18:00:01,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:01,105:INFO:Checking exceptions
2024-01-18 18:00:01,105:INFO:Importing libraries
2024-01-18 18:00:01,105:INFO:Copying training dataset
2024-01-18 18:00:01,116:INFO:Defining folds
2024-01-18 18:00:01,117:INFO:Declaring metric variables
2024-01-18 18:00:01,122:INFO:Importing untrained model
2024-01-18 18:00:01,127:INFO:Decision Tree Classifier Imported successfully
2024-01-18 18:00:01,135:INFO:Starting cross validation
2024-01-18 18:00:01,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:01,933:INFO:Calculating mean and std
2024-01-18 18:00:01,936:INFO:Creating metrics dataframe
2024-01-18 18:00:01,936:INFO:Uploading results into container
2024-01-18 18:00:01,936:INFO:Uploading model into container now
2024-01-18 18:00:01,936:INFO:_master_model_container: 4
2024-01-18 18:00:01,936:INFO:_display_container: 2
2024-01-18 18:00:01,936:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5817, splitter='best')
2024-01-18 18:00:01,936:INFO:create_model() successfully completed......................................
2024-01-18 18:00:02,143:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:02,143:INFO:Creating metrics dataframe
2024-01-18 18:00:02,158:INFO:Initializing SVM - Linear Kernel
2024-01-18 18:00:02,158:INFO:Total runtime is 1.1852813839912415 minutes
2024-01-18 18:00:02,158:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:02,158:INFO:Initializing create_model()
2024-01-18 18:00:02,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:02,158:INFO:Checking exceptions
2024-01-18 18:00:02,174:INFO:Importing libraries
2024-01-18 18:00:02,174:INFO:Copying training dataset
2024-01-18 18:00:02,182:INFO:Defining folds
2024-01-18 18:00:02,182:INFO:Declaring metric variables
2024-01-18 18:00:02,188:INFO:Importing untrained model
2024-01-18 18:00:02,195:INFO:SVM - Linear Kernel Imported successfully
2024-01-18 18:00:02,206:INFO:Starting cross validation
2024-01-18 18:00:02,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:03,131:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:00:03,131:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:00:03,146:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:00:03,399:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:00:03,414:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:00:03,414:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:00:03,414:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:00:03,588:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:00:03,603:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:00:03,619:INFO:Calculating mean and std
2024-01-18 18:00:03,619:INFO:Creating metrics dataframe
2024-01-18 18:00:03,639:INFO:Uploading results into container
2024-01-18 18:00:03,641:INFO:Uploading model into container now
2024-01-18 18:00:03,642:INFO:_master_model_container: 5
2024-01-18 18:00:03,642:INFO:_display_container: 2
2024-01-18 18:00:03,643:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5817, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-18 18:00:03,644:INFO:create_model() successfully completed......................................
2024-01-18 18:00:03,873:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:03,873:INFO:Creating metrics dataframe
2024-01-18 18:00:03,889:INFO:Initializing Ridge Classifier
2024-01-18 18:00:03,889:INFO:Total runtime is 1.2141304691632588 minutes
2024-01-18 18:00:03,889:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:03,889:INFO:Initializing create_model()
2024-01-18 18:00:03,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:03,889:INFO:Checking exceptions
2024-01-18 18:00:03,889:INFO:Importing libraries
2024-01-18 18:00:03,889:INFO:Copying training dataset
2024-01-18 18:00:03,904:INFO:Defining folds
2024-01-18 18:00:03,904:INFO:Declaring metric variables
2024-01-18 18:00:03,909:INFO:Importing untrained model
2024-01-18 18:00:03,913:INFO:Ridge Classifier Imported successfully
2024-01-18 18:00:03,922:INFO:Starting cross validation
2024-01-18 18:00:03,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:04,312:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:00:04,312:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:00:04,327:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:00:04,328:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:00:04,563:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:00:04,578:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:00:04,594:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:00:04,751:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:00:04,767:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:00:04,782:INFO:Calculating mean and std
2024-01-18 18:00:04,782:INFO:Creating metrics dataframe
2024-01-18 18:00:04,782:INFO:Uploading results into container
2024-01-18 18:00:04,782:INFO:Uploading model into container now
2024-01-18 18:00:04,782:INFO:_master_model_container: 6
2024-01-18 18:00:04,782:INFO:_display_container: 2
2024-01-18 18:00:04,782:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5817, solver='auto',
                tol=0.0001)
2024-01-18 18:00:04,782:INFO:create_model() successfully completed......................................
2024-01-18 18:00:04,992:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:04,992:INFO:Creating metrics dataframe
2024-01-18 18:00:05,008:INFO:Initializing Random Forest Classifier
2024-01-18 18:00:05,008:INFO:Total runtime is 1.2327738205591838 minutes
2024-01-18 18:00:05,008:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:05,008:INFO:Initializing create_model()
2024-01-18 18:00:05,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:05,008:INFO:Checking exceptions
2024-01-18 18:00:05,008:INFO:Importing libraries
2024-01-18 18:00:05,008:INFO:Copying training dataset
2024-01-18 18:00:05,029:INFO:Defining folds
2024-01-18 18:00:05,030:INFO:Declaring metric variables
2024-01-18 18:00:05,034:INFO:Importing untrained model
2024-01-18 18:00:05,038:INFO:Random Forest Classifier Imported successfully
2024-01-18 18:00:05,045:INFO:Starting cross validation
2024-01-18 18:00:05,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:08,519:INFO:Calculating mean and std
2024-01-18 18:00:08,519:INFO:Creating metrics dataframe
2024-01-18 18:00:08,543:INFO:Uploading results into container
2024-01-18 18:00:08,544:INFO:Uploading model into container now
2024-01-18 18:00:08,545:INFO:_master_model_container: 7
2024-01-18 18:00:08,545:INFO:_display_container: 2
2024-01-18 18:00:08,547:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5817, verbose=0, warm_start=False)
2024-01-18 18:00:08,547:INFO:create_model() successfully completed......................................
2024-01-18 18:00:08,789:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:08,789:INFO:Creating metrics dataframe
2024-01-18 18:00:08,805:INFO:Initializing Quadratic Discriminant Analysis
2024-01-18 18:00:08,820:INFO:Total runtime is 1.2960592269897462 minutes
2024-01-18 18:00:08,825:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:08,827:INFO:Initializing create_model()
2024-01-18 18:00:08,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:08,827:INFO:Checking exceptions
2024-01-18 18:00:08,827:INFO:Importing libraries
2024-01-18 18:00:08,827:INFO:Copying training dataset
2024-01-18 18:00:08,834:INFO:Defining folds
2024-01-18 18:00:08,835:INFO:Declaring metric variables
2024-01-18 18:00:08,839:INFO:Importing untrained model
2024-01-18 18:00:08,843:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-18 18:00:08,850:INFO:Starting cross validation
2024-01-18 18:00:08,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:09,374:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:00:09,374:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:00:09,374:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:00:09,737:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:00:09,737:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:00:09,737:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:00:09,752:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:00:09,911:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:00:09,922:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:00:09,958:INFO:Calculating mean and std
2024-01-18 18:00:09,958:INFO:Creating metrics dataframe
2024-01-18 18:00:09,977:INFO:Uploading results into container
2024-01-18 18:00:09,977:INFO:Uploading model into container now
2024-01-18 18:00:09,978:INFO:_master_model_container: 8
2024-01-18 18:00:09,978:INFO:_display_container: 2
2024-01-18 18:00:09,978:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-18 18:00:09,978:INFO:create_model() successfully completed......................................
2024-01-18 18:00:10,207:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:10,583:INFO:Creating metrics dataframe
2024-01-18 18:00:10,614:INFO:Initializing Ada Boost Classifier
2024-01-18 18:00:10,614:INFO:Total runtime is 1.3262126684188844 minutes
2024-01-18 18:00:10,627:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:10,628:INFO:Initializing create_model()
2024-01-18 18:00:10,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:10,628:INFO:Checking exceptions
2024-01-18 18:00:10,628:INFO:Importing libraries
2024-01-18 18:00:10,628:INFO:Copying training dataset
2024-01-18 18:00:10,635:INFO:Defining folds
2024-01-18 18:00:10,635:INFO:Declaring metric variables
2024-01-18 18:00:10,639:INFO:Importing untrained model
2024-01-18 18:00:10,645:INFO:Ada Boost Classifier Imported successfully
2024-01-18 18:00:10,652:INFO:Starting cross validation
2024-01-18 18:00:10,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:12,624:INFO:Calculating mean and std
2024-01-18 18:00:12,624:INFO:Creating metrics dataframe
2024-01-18 18:00:12,624:INFO:Uploading results into container
2024-01-18 18:00:12,624:INFO:Uploading model into container now
2024-01-18 18:00:12,624:INFO:_master_model_container: 9
2024-01-18 18:00:12,624:INFO:_display_container: 2
2024-01-18 18:00:12,624:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5817)
2024-01-18 18:00:12,624:INFO:create_model() successfully completed......................................
2024-01-18 18:00:12,873:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:12,873:INFO:Creating metrics dataframe
2024-01-18 18:00:12,875:INFO:Initializing Gradient Boosting Classifier
2024-01-18 18:00:12,875:INFO:Total runtime is 1.363890568415324 minutes
2024-01-18 18:00:12,895:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:12,896:INFO:Initializing create_model()
2024-01-18 18:00:12,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:12,897:INFO:Checking exceptions
2024-01-18 18:00:12,897:INFO:Importing libraries
2024-01-18 18:00:12,897:INFO:Copying training dataset
2024-01-18 18:00:12,907:INFO:Defining folds
2024-01-18 18:00:12,907:INFO:Declaring metric variables
2024-01-18 18:00:12,913:INFO:Importing untrained model
2024-01-18 18:00:12,917:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 18:00:12,926:INFO:Starting cross validation
2024-01-18 18:00:12,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:16,662:INFO:Calculating mean and std
2024-01-18 18:00:16,662:INFO:Creating metrics dataframe
2024-01-18 18:00:16,662:INFO:Uploading results into container
2024-01-18 18:00:16,677:INFO:Uploading model into container now
2024-01-18 18:00:16,678:INFO:_master_model_container: 10
2024-01-18 18:00:16,678:INFO:_display_container: 2
2024-01-18 18:00:16,678:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 18:00:16,678:INFO:create_model() successfully completed......................................
2024-01-18 18:00:16,907:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:16,907:INFO:Creating metrics dataframe
2024-01-18 18:00:16,923:INFO:Initializing Linear Discriminant Analysis
2024-01-18 18:00:16,923:INFO:Total runtime is 1.4313599626223248 minutes
2024-01-18 18:00:16,929:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:16,929:INFO:Initializing create_model()
2024-01-18 18:00:16,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:16,929:INFO:Checking exceptions
2024-01-18 18:00:16,930:INFO:Importing libraries
2024-01-18 18:00:16,930:INFO:Copying training dataset
2024-01-18 18:00:16,939:INFO:Defining folds
2024-01-18 18:00:16,939:INFO:Declaring metric variables
2024-01-18 18:00:16,944:INFO:Importing untrained model
2024-01-18 18:00:16,950:INFO:Linear Discriminant Analysis Imported successfully
2024-01-18 18:00:16,960:INFO:Starting cross validation
2024-01-18 18:00:16,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:18,074:INFO:Calculating mean and std
2024-01-18 18:00:18,074:INFO:Creating metrics dataframe
2024-01-18 18:00:18,080:INFO:Uploading results into container
2024-01-18 18:00:18,080:INFO:Uploading model into container now
2024-01-18 18:00:18,081:INFO:_master_model_container: 11
2024-01-18 18:00:18,081:INFO:_display_container: 2
2024-01-18 18:00:18,082:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-18 18:00:18,082:INFO:create_model() successfully completed......................................
2024-01-18 18:00:18,326:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:18,342:INFO:Creating metrics dataframe
2024-01-18 18:00:18,357:INFO:Initializing Extra Trees Classifier
2024-01-18 18:00:18,357:INFO:Total runtime is 1.4552691340446473 minutes
2024-01-18 18:00:18,357:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:18,357:INFO:Initializing create_model()
2024-01-18 18:00:18,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:18,357:INFO:Checking exceptions
2024-01-18 18:00:18,357:INFO:Importing libraries
2024-01-18 18:00:18,357:INFO:Copying training dataset
2024-01-18 18:00:18,372:INFO:Defining folds
2024-01-18 18:00:18,373:INFO:Declaring metric variables
2024-01-18 18:00:18,378:INFO:Importing untrained model
2024-01-18 18:00:18,382:INFO:Extra Trees Classifier Imported successfully
2024-01-18 18:00:18,390:INFO:Starting cross validation
2024-01-18 18:00:18,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:21,469:INFO:Calculating mean and std
2024-01-18 18:00:21,469:INFO:Creating metrics dataframe
2024-01-18 18:00:21,485:INFO:Uploading results into container
2024-01-18 18:00:21,485:INFO:Uploading model into container now
2024-01-18 18:00:21,485:INFO:_master_model_container: 12
2024-01-18 18:00:21,485:INFO:_display_container: 2
2024-01-18 18:00:21,488:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5817, verbose=0, warm_start=False)
2024-01-18 18:00:21,488:INFO:create_model() successfully completed......................................
2024-01-18 18:00:21,718:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:21,718:INFO:Creating metrics dataframe
2024-01-18 18:00:21,755:INFO:Initializing Extreme Gradient Boosting
2024-01-18 18:00:21,755:INFO:Total runtime is 1.5118924101193747 minutes
2024-01-18 18:00:21,762:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:21,763:INFO:Initializing create_model()
2024-01-18 18:00:21,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:21,763:INFO:Checking exceptions
2024-01-18 18:00:21,763:INFO:Importing libraries
2024-01-18 18:00:21,763:INFO:Copying training dataset
2024-01-18 18:00:21,772:INFO:Defining folds
2024-01-18 18:00:21,773:INFO:Declaring metric variables
2024-01-18 18:00:21,777:INFO:Importing untrained model
2024-01-18 18:00:21,784:INFO:Extreme Gradient Boosting Imported successfully
2024-01-18 18:00:21,793:INFO:Starting cross validation
2024-01-18 18:00:21,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:24,423:INFO:Calculating mean and std
2024-01-18 18:00:24,423:INFO:Creating metrics dataframe
2024-01-18 18:00:24,423:INFO:Uploading results into container
2024-01-18 18:00:24,423:INFO:Uploading model into container now
2024-01-18 18:00:24,423:INFO:_master_model_container: 13
2024-01-18 18:00:24,423:INFO:_display_container: 2
2024-01-18 18:00:24,423:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-18 18:00:24,423:INFO:create_model() successfully completed......................................
2024-01-18 18:00:24,657:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:24,657:INFO:Creating metrics dataframe
2024-01-18 18:00:24,673:INFO:Initializing Light Gradient Boosting Machine
2024-01-18 18:00:24,673:INFO:Total runtime is 1.5605315725008648 minutes
2024-01-18 18:00:24,673:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:24,689:INFO:Initializing create_model()
2024-01-18 18:00:24,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:24,689:INFO:Checking exceptions
2024-01-18 18:00:24,689:INFO:Importing libraries
2024-01-18 18:00:24,689:INFO:Copying training dataset
2024-01-18 18:00:24,697:INFO:Defining folds
2024-01-18 18:00:24,697:INFO:Declaring metric variables
2024-01-18 18:00:24,701:INFO:Importing untrained model
2024-01-18 18:00:24,705:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 18:00:24,712:INFO:Starting cross validation
2024-01-18 18:00:24,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:26,316:INFO:Calculating mean and std
2024-01-18 18:00:26,316:INFO:Creating metrics dataframe
2024-01-18 18:00:26,316:INFO:Uploading results into container
2024-01-18 18:00:26,316:INFO:Uploading model into container now
2024-01-18 18:00:26,316:INFO:_master_model_container: 14
2024-01-18 18:00:26,316:INFO:_display_container: 2
2024-01-18 18:00:26,316:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5817, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 18:00:26,330:INFO:create_model() successfully completed......................................
2024-01-18 18:00:26,556:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:26,556:INFO:Creating metrics dataframe
2024-01-18 18:00:26,572:INFO:Initializing CatBoost Classifier
2024-01-18 18:00:26,572:INFO:Total runtime is 1.5921840429306031 minutes
2024-01-18 18:00:26,589:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:26,589:INFO:Initializing create_model()
2024-01-18 18:00:26,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:26,589:INFO:Checking exceptions
2024-01-18 18:00:26,589:INFO:Importing libraries
2024-01-18 18:00:26,590:INFO:Copying training dataset
2024-01-18 18:00:26,595:INFO:Defining folds
2024-01-18 18:00:26,595:INFO:Declaring metric variables
2024-01-18 18:00:26,599:INFO:Importing untrained model
2024-01-18 18:00:26,604:INFO:CatBoost Classifier Imported successfully
2024-01-18 18:00:26,612:INFO:Starting cross validation
2024-01-18 18:00:26,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(



2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

tion.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,113:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:43,120:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,312:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,312:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,312:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,312:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,312:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,312:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,319:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,336:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,336:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,336:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,336:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,336:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:52,336:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,245:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:00:57,260:INFO:Calculating mean and std
2024-01-18 18:00:57,260:INFO:Creating metrics dataframe
2024-01-18 18:00:57,260:INFO:Uploading results into container
2024-01-18 18:00:57,260:INFO:Uploading model into container now
2024-01-18 18:00:57,260:INFO:_master_model_container: 15
2024-01-18 18:00:57,260:INFO:_display_container: 2
2024-01-18 18:00:57,260:INFO:<catboost.core.CatBoostClassifier object at 0x000001EFC3727990>
2024-01-18 18:00:57,260:INFO:create_model() successfully completed......................................
2024-01-18 18:00:57,475:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:57,475:INFO:Creating metrics dataframe
2024-01-18 18:00:57,489:INFO:Initializing Dummy Classifier
2024-01-18 18:00:57,489:INFO:Total runtime is 2.107471263408661 minutes
2024-01-18 18:00:57,503:INFO:SubProcess create_model() called ==================================
2024-01-18 18:00:57,504:INFO:Initializing create_model()
2024-01-18 18:00:57,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD041EF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:57,504:INFO:Checking exceptions
2024-01-18 18:00:57,504:INFO:Importing libraries
2024-01-18 18:00:57,504:INFO:Copying training dataset
2024-01-18 18:00:57,518:INFO:Defining folds
2024-01-18 18:00:57,518:INFO:Declaring metric variables
2024-01-18 18:00:57,523:INFO:Importing untrained model
2024-01-18 18:00:57,529:INFO:Dummy Classifier Imported successfully
2024-01-18 18:00:57,538:INFO:Starting cross validation
2024-01-18 18:00:57,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:00:58,211:INFO:Calculating mean and std
2024-01-18 18:00:58,211:INFO:Creating metrics dataframe
2024-01-18 18:00:58,211:INFO:Uploading results into container
2024-01-18 18:00:58,211:INFO:Uploading model into container now
2024-01-18 18:00:58,222:INFO:_master_model_container: 16
2024-01-18 18:00:58,222:INFO:_display_container: 2
2024-01-18 18:00:58,222:INFO:DummyClassifier(constant=None, random_state=5817, strategy='prior')
2024-01-18 18:00:58,222:INFO:create_model() successfully completed......................................
2024-01-18 18:00:58,439:INFO:SubProcess create_model() end ==================================
2024-01-18 18:00:58,439:INFO:Creating metrics dataframe
2024-01-18 18:00:58,494:INFO:Initializing create_model()
2024-01-18 18:00:58,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:00:58,494:INFO:Checking exceptions
2024-01-18 18:00:58,496:INFO:Importing libraries
2024-01-18 18:00:58,497:INFO:Copying training dataset
2024-01-18 18:00:58,502:INFO:Defining folds
2024-01-18 18:00:58,502:INFO:Declaring metric variables
2024-01-18 18:00:58,502:INFO:Importing untrained model
2024-01-18 18:00:58,502:INFO:Declaring custom model
2024-01-18 18:00:58,503:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 18:00:58,504:INFO:Cross validation set to False
2024-01-18 18:00:58,505:INFO:Fitting Model
2024-01-18 18:01:00,025:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 18:01:00,025:INFO:create_model() successfully completed......................................
2024-01-18 18:01:00,273:INFO:_master_model_container: 16
2024-01-18 18:01:00,273:INFO:_display_container: 2
2024-01-18 18:01:00,274:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 18:01:00,274:INFO:compare_models() successfully completed......................................
2024-01-18 18:01:04,836:INFO:Initializing finalize_model()
2024-01-18 18:01:04,836:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-18 18:01:04,837:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 18:01:04,842:INFO:Initializing create_model()
2024-01-18 18:01:04,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:01:04,842:INFO:Checking exceptions
2024-01-18 18:01:04,845:INFO:Importing libraries
2024-01-18 18:01:04,845:INFO:Copying training dataset
2024-01-18 18:01:04,845:INFO:Defining folds
2024-01-18 18:01:04,845:INFO:Declaring metric variables
2024-01-18 18:01:04,846:INFO:Importing untrained model
2024-01-18 18:01:04,846:INFO:Declaring custom model
2024-01-18 18:01:04,847:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 18:01:04,848:INFO:Cross validation set to False
2024-01-18 18:01:04,849:INFO:Fitting Model
2024-01-18 18:01:06,458:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=5817, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-01-18 18:01:06,458:INFO:create_model() successfully completed......................................
2024-01-18 18:01:06,678:INFO:_master_model_container: 16
2024-01-18 18:01:06,678:INFO:_display_container: 2
2024-01-18 18:01:06,825:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=5817, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-01-18 18:01:06,825:INFO:finalize_model() successfully completed......................................
2024-01-18 18:01:07,989:INFO:Initializing evaluate_model()
2024-01-18 18:01:07,989:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-18 18:01:08,003:INFO:Initializing plot_model()
2024-01-18 18:01:08,004:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 18:01:08,004:INFO:Checking exceptions
2024-01-18 18:01:08,059:INFO:Preloading libraries
2024-01-18 18:01:08,169:INFO:Copying training dataset
2024-01-18 18:01:08,208:INFO:Plot type: pipeline
2024-01-18 18:01:08,475:INFO:Visual Rendered Successfully
2024-01-18 18:01:08,647:INFO:plot_model() successfully completed......................................
2024-01-18 18:01:09,251:INFO:Initializing predict_model()
2024-01-18 18:01:09,251:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFCA3E5010>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5817, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EFB067CCC0>)
2024-01-18 18:01:09,251:INFO:Checking exceptions
2024-01-18 18:01:09,251:INFO:Preloading libraries
2024-01-18 18:01:18,189:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:18,721:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:18,815:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:21,889:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:22,573:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:22,668:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:23,537:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:24,210:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:24,226:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:24,765:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:24,765:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:25,358:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:25,374:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:25,953:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:26,016:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:26,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:26,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:27,301:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:27,316:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:27,927:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:27,927:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:28,382:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:28,382:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:28,932:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:28,948:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,527:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,527:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,543:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,543:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,543:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,559:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,559:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,559:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,574:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,590:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,606:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,606:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,606:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,621:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,634:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,637:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,637:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,637:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,653:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:29,653:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:29,668:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,266:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,281:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,281:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,300:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,300:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,313:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,329:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,344:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,344:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,360:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,360:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,391:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,391:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,439:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,454:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,485:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,485:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,533:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:01:30,548:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:01:30,564:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:02:02,310:WARNING:C:\Users\Auditor\AppData\Local\Temp\ipykernel_15080\792700367.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
  test_final = test_final[train_feature_names]

2024-01-18 18:26:45,795:INFO:PyCaret ClassificationExperiment
2024-01-18 18:26:45,795:INFO:Logging name: clf-default-name
2024-01-18 18:26:45,795:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-18 18:26:45,795:INFO:version 3.2.0
2024-01-18 18:26:45,796:INFO:Initializing setup()
2024-01-18 18:26:45,796:INFO:self.USI: c509
2024-01-18 18:26:45,796:INFO:self._variable_keys: {'y', 'log_plots_param', 'fold_groups_param', 'fix_imbalance', 'USI', 'X_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'X_train', 'exp_name_log', 'idx', 'y_train', 'X', 'logging_param', 'n_jobs_param', 'pipeline', 'seed', '_available_plots', 'gpu_n_jobs_param', 'y_test', 'data', 'fold_shuffle_param', 'gpu_param', 'memory', 'fold_generator', 'target_param', 'html_param'}
2024-01-18 18:26:45,796:INFO:Checking environment
2024-01-18 18:26:45,797:INFO:python_version: 3.11.5
2024-01-18 18:26:45,797:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-01-18 18:26:45,797:INFO:machine: AMD64
2024-01-18 18:26:45,797:INFO:platform: Windows-10-10.0.22621-SP0
2024-01-18 18:26:45,797:INFO:Memory: svmem(total=8361132032, available=1531420672, percent=81.7, used=6829711360, free=1531420672)
2024-01-18 18:26:45,797:INFO:Physical Core: 2
2024-01-18 18:26:45,797:INFO:Logical Core: 4
2024-01-18 18:26:45,798:INFO:Checking libraries
2024-01-18 18:26:45,798:INFO:System:
2024-01-18 18:26:45,798:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-01-18 18:26:45,798:INFO:executable: C:\Users\Auditor\anaconda3.2\python.exe
2024-01-18 18:26:45,798:INFO:   machine: Windows-10-10.0.22621-SP0
2024-01-18 18:26:45,798:INFO:PyCaret required dependencies:
2024-01-18 18:26:45,798:INFO:                 pip: 23.2.1
2024-01-18 18:26:45,798:INFO:          setuptools: 68.0.0
2024-01-18 18:26:45,798:INFO:             pycaret: 3.2.0
2024-01-18 18:26:45,800:INFO:             IPython: 8.15.0
2024-01-18 18:26:45,801:INFO:          ipywidgets: 8.0.4
2024-01-18 18:26:45,802:INFO:                tqdm: 4.65.0
2024-01-18 18:26:45,803:INFO:               numpy: 1.24.3
2024-01-18 18:26:45,803:INFO:              pandas: 1.5.3
2024-01-18 18:26:45,803:INFO:              jinja2: 3.1.2
2024-01-18 18:26:45,803:INFO:               scipy: 1.10.1
2024-01-18 18:26:45,803:INFO:              joblib: 1.2.0
2024-01-18 18:26:45,803:INFO:             sklearn: 1.2.2
2024-01-18 18:26:45,803:INFO:                pyod: 1.1.2
2024-01-18 18:26:45,803:INFO:            imblearn: 0.10.1
2024-01-18 18:26:45,803:INFO:   category_encoders: 2.6.3
2024-01-18 18:26:45,803:INFO:            lightgbm: 4.2.0
2024-01-18 18:26:45,803:INFO:               numba: 0.57.1
2024-01-18 18:26:45,803:INFO:            requests: 2.31.0
2024-01-18 18:26:45,803:INFO:          matplotlib: 3.6.0
2024-01-18 18:26:45,804:INFO:          scikitplot: 0.3.7
2024-01-18 18:26:45,804:INFO:         yellowbrick: 1.5
2024-01-18 18:26:45,804:INFO:              plotly: 5.9.0
2024-01-18 18:26:45,804:INFO:    plotly-resampler: Not installed
2024-01-18 18:26:45,804:INFO:             kaleido: 0.2.1
2024-01-18 18:26:45,804:INFO:           schemdraw: 0.15
2024-01-18 18:26:45,804:INFO:         statsmodels: 0.14.0
2024-01-18 18:26:45,804:INFO:              sktime: 0.21.1
2024-01-18 18:26:45,804:INFO:               tbats: 1.1.3
2024-01-18 18:26:45,804:INFO:            pmdarima: 2.0.4
2024-01-18 18:26:45,804:INFO:              psutil: 5.9.0
2024-01-18 18:26:45,804:INFO:          markupsafe: 2.1.1
2024-01-18 18:26:45,804:INFO:             pickle5: Not installed
2024-01-18 18:26:45,805:INFO:         cloudpickle: 2.2.1
2024-01-18 18:26:45,805:INFO:         deprecation: 2.1.0
2024-01-18 18:26:45,805:INFO:              xxhash: 2.0.2
2024-01-18 18:26:45,805:INFO:           wurlitzer: Not installed
2024-01-18 18:26:45,805:INFO:PyCaret optional dependencies:
2024-01-18 18:26:45,805:INFO:                shap: Not installed
2024-01-18 18:26:45,805:INFO:           interpret: Not installed
2024-01-18 18:26:45,805:INFO:                umap: Not installed
2024-01-18 18:26:45,805:INFO:     ydata_profiling: Not installed
2024-01-18 18:26:45,805:INFO:  explainerdashboard: Not installed
2024-01-18 18:26:45,805:INFO:             autoviz: Not installed
2024-01-18 18:26:45,805:INFO:           fairlearn: Not installed
2024-01-18 18:26:45,805:INFO:          deepchecks: Not installed
2024-01-18 18:26:45,805:INFO:             xgboost: 2.0.3
2024-01-18 18:26:45,805:INFO:            catboost: 1.2.2
2024-01-18 18:26:45,806:INFO:              kmodes: Not installed
2024-01-18 18:26:45,806:INFO:             mlxtend: Not installed
2024-01-18 18:26:45,806:INFO:       statsforecast: Not installed
2024-01-18 18:26:45,806:INFO:        tune_sklearn: Not installed
2024-01-18 18:26:45,806:INFO:                 ray: Not installed
2024-01-18 18:26:45,806:INFO:            hyperopt: Not installed
2024-01-18 18:26:45,806:INFO:              optuna: 3.5.0
2024-01-18 18:26:45,806:INFO:               skopt: Not installed
2024-01-18 18:26:45,806:INFO:              mlflow: Not installed
2024-01-18 18:26:45,806:INFO:              gradio: Not installed
2024-01-18 18:26:45,806:INFO:             fastapi: Not installed
2024-01-18 18:26:45,806:INFO:             uvicorn: Not installed
2024-01-18 18:26:45,806:INFO:              m2cgen: Not installed
2024-01-18 18:26:45,806:INFO:           evidently: Not installed
2024-01-18 18:26:45,807:INFO:               fugue: Not installed
2024-01-18 18:26:45,807:INFO:           streamlit: Not installed
2024-01-18 18:26:45,807:INFO:             prophet: Not installed
2024-01-18 18:26:45,807:INFO:None
2024-01-18 18:26:45,807:INFO:Set up data.
2024-01-18 18:26:45,820:INFO:Set up folding strategy.
2024-01-18 18:26:45,820:INFO:Set up train/test split.
2024-01-18 18:26:45,829:INFO:Set up index.
2024-01-18 18:26:45,831:INFO:Assigning column types.
2024-01-18 18:26:45,836:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-18 18:26:45,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 18:26:45,878:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 18:26:45,909:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 18:26:45,909:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 18:26:45,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-18 18:26:45,946:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 18:26:45,977:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 18:26:46,024:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 18:26:46,024:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-18 18:26:46,086:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 18:26:46,133:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 18:26:46,133:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 18:26:46,197:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-18 18:26:46,227:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 18:26:46,227:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 18:26:46,227:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-18 18:26:46,337:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 18:26:46,353:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 18:26:46,415:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 18:26:46,415:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 18:26:46,463:INFO:Preparing preprocessing pipeline...
2024-01-18 18:26:46,463:INFO:Set up simple imputation.
2024-01-18 18:26:46,463:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\preprocess\preprocessor.py:653: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.
  for name, column in X_transformed[self._fxs["Categorical"]].items():

2024-01-18 18:26:46,478:INFO:Set up encoding of ordinal features.
2024-01-18 18:26:46,495:INFO:Set up encoding of categorical features.
2024-01-18 18:26:46,495:INFO:Set up column name cleaning.
2024-01-18 18:26:46,699:INFO:Finished creating preprocessing pipeline.
2024-01-18 18:26:46,846:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Auditor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbo...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -0.316951    0
 3.155058    1
 NaN        -1
dtype: int64},
                                                                        {'col': 'Destination_TRAPPIST-1e',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': -1.546237    0
 0.646731    1
 NaN        -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-18 18:26:46,846:INFO:Creating final display dataframe.
2024-01-18 18:26:47,127:INFO:Setup _display_container:                     Description             Value
0                    Session id              4558
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 15)
4        Transformed data shape        (8693, 15)
5   Transformed train set shape        (6085, 15)
6    Transformed test set shape        (2608, 15)
7              Ordinal features                 8
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              c509
2024-01-18 18:26:47,226:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 18:26:47,230:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 18:26:47,355:INFO:Soft dependency imported: xgboost: 2.0.3
2024-01-18 18:26:47,358:INFO:Soft dependency imported: catboost: 1.2.2
2024-01-18 18:26:47,359:INFO:setup() successfully completed in 1.62s...............
2024-01-18 18:26:54,385:INFO:Initializing compare_models()
2024-01-18 18:26:54,385:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-01-18 18:26:54,385:INFO:Checking exceptions
2024-01-18 18:26:54,391:INFO:Preparing display monitor
2024-01-18 18:26:54,425:INFO:Initializing Logistic Regression
2024-01-18 18:26:54,425:INFO:Total runtime is 0.0 minutes
2024-01-18 18:26:54,430:INFO:SubProcess create_model() called ==================================
2024-01-18 18:26:54,430:INFO:Initializing create_model()
2024-01-18 18:26:54,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:26:54,431:INFO:Checking exceptions
2024-01-18 18:26:54,431:INFO:Importing libraries
2024-01-18 18:26:54,431:INFO:Copying training dataset
2024-01-18 18:26:54,449:INFO:Defining folds
2024-01-18 18:26:54,449:INFO:Declaring metric variables
2024-01-18 18:26:54,454:INFO:Importing untrained model
2024-01-18 18:26:54,460:INFO:Logistic Regression Imported successfully
2024-01-18 18:26:54,475:INFO:Starting cross validation
2024-01-18 18:26:54,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:06,038:INFO:Calculating mean and std
2024-01-18 18:28:06,038:INFO:Creating metrics dataframe
2024-01-18 18:28:06,038:INFO:Uploading results into container
2024-01-18 18:28:06,038:INFO:Uploading model into container now
2024-01-18 18:28:06,038:INFO:_master_model_container: 1
2024-01-18 18:28:06,038:INFO:_display_container: 2
2024-01-18 18:28:06,038:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4558, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-18 18:28:06,038:INFO:create_model() successfully completed......................................
2024-01-18 18:28:06,290:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:06,290:INFO:Creating metrics dataframe
2024-01-18 18:28:06,290:INFO:Initializing K Neighbors Classifier
2024-01-18 18:28:06,290:INFO:Total runtime is 1.1977523684501648 minutes
2024-01-18 18:28:06,307:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:06,307:INFO:Initializing create_model()
2024-01-18 18:28:06,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:06,307:INFO:Checking exceptions
2024-01-18 18:28:06,307:INFO:Importing libraries
2024-01-18 18:28:06,307:INFO:Copying training dataset
2024-01-18 18:28:06,317:INFO:Defining folds
2024-01-18 18:28:06,318:INFO:Declaring metric variables
2024-01-18 18:28:06,323:INFO:Importing untrained model
2024-01-18 18:28:06,327:INFO:K Neighbors Classifier Imported successfully
2024-01-18 18:28:06,335:INFO:Starting cross validation
2024-01-18 18:28:06,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:07,565:INFO:Calculating mean and std
2024-01-18 18:28:07,565:INFO:Creating metrics dataframe
2024-01-18 18:28:07,565:INFO:Uploading results into container
2024-01-18 18:28:07,565:INFO:Uploading model into container now
2024-01-18 18:28:07,580:INFO:_master_model_container: 2
2024-01-18 18:28:07,580:INFO:_display_container: 2
2024-01-18 18:28:07,580:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-18 18:28:07,580:INFO:create_model() successfully completed......................................
2024-01-18 18:28:07,822:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:07,822:INFO:Creating metrics dataframe
2024-01-18 18:28:07,822:INFO:Initializing Naive Bayes
2024-01-18 18:28:07,822:INFO:Total runtime is 1.2232778509457907 minutes
2024-01-18 18:28:07,837:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:07,837:INFO:Initializing create_model()
2024-01-18 18:28:07,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:07,837:INFO:Checking exceptions
2024-01-18 18:28:07,837:INFO:Importing libraries
2024-01-18 18:28:07,837:INFO:Copying training dataset
2024-01-18 18:28:07,849:INFO:Defining folds
2024-01-18 18:28:07,850:INFO:Declaring metric variables
2024-01-18 18:28:07,855:INFO:Importing untrained model
2024-01-18 18:28:07,862:INFO:Naive Bayes Imported successfully
2024-01-18 18:28:07,874:INFO:Starting cross validation
2024-01-18 18:28:07,877:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:08,533:INFO:Calculating mean and std
2024-01-18 18:28:08,533:INFO:Creating metrics dataframe
2024-01-18 18:28:08,548:INFO:Uploading results into container
2024-01-18 18:28:08,548:INFO:Uploading model into container now
2024-01-18 18:28:08,548:INFO:_master_model_container: 3
2024-01-18 18:28:08,548:INFO:_display_container: 2
2024-01-18 18:28:08,548:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-18 18:28:08,548:INFO:create_model() successfully completed......................................
2024-01-18 18:28:08,774:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:08,774:INFO:Creating metrics dataframe
2024-01-18 18:28:08,789:INFO:Initializing Decision Tree Classifier
2024-01-18 18:28:08,789:INFO:Total runtime is 1.2394038796424867 minutes
2024-01-18 18:28:08,789:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:08,802:INFO:Initializing create_model()
2024-01-18 18:28:08,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:08,802:INFO:Checking exceptions
2024-01-18 18:28:08,802:INFO:Importing libraries
2024-01-18 18:28:08,802:INFO:Copying training dataset
2024-01-18 18:28:08,811:INFO:Defining folds
2024-01-18 18:28:08,811:INFO:Declaring metric variables
2024-01-18 18:28:08,814:INFO:Importing untrained model
2024-01-18 18:28:08,819:INFO:Decision Tree Classifier Imported successfully
2024-01-18 18:28:08,826:INFO:Starting cross validation
2024-01-18 18:28:08,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:09,605:INFO:Calculating mean and std
2024-01-18 18:28:09,605:INFO:Creating metrics dataframe
2024-01-18 18:28:09,611:INFO:Uploading results into container
2024-01-18 18:28:09,612:INFO:Uploading model into container now
2024-01-18 18:28:09,612:INFO:_master_model_container: 4
2024-01-18 18:28:09,612:INFO:_display_container: 2
2024-01-18 18:28:09,612:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4558, splitter='best')
2024-01-18 18:28:09,612:INFO:create_model() successfully completed......................................
2024-01-18 18:28:09,855:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:09,855:INFO:Creating metrics dataframe
2024-01-18 18:28:09,874:INFO:Initializing SVM - Linear Kernel
2024-01-18 18:28:09,874:INFO:Total runtime is 1.257474168141683 minutes
2024-01-18 18:28:09,885:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:09,885:INFO:Initializing create_model()
2024-01-18 18:28:09,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:09,886:INFO:Checking exceptions
2024-01-18 18:28:09,886:INFO:Importing libraries
2024-01-18 18:28:09,886:INFO:Copying training dataset
2024-01-18 18:28:09,895:INFO:Defining folds
2024-01-18 18:28:09,895:INFO:Declaring metric variables
2024-01-18 18:28:09,899:INFO:Importing untrained model
2024-01-18 18:28:09,902:INFO:SVM - Linear Kernel Imported successfully
2024-01-18 18:28:09,913:INFO:Starting cross validation
2024-01-18 18:28:09,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:10,486:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:28:10,486:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:28:10,486:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:28:10,804:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:28:10,804:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:28:10,804:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:28:10,804:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:28:11,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:28:11,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-18 18:28:11,040:INFO:Calculating mean and std
2024-01-18 18:28:11,040:INFO:Creating metrics dataframe
2024-01-18 18:28:11,058:INFO:Uploading results into container
2024-01-18 18:28:11,059:INFO:Uploading model into container now
2024-01-18 18:28:11,060:INFO:_master_model_container: 5
2024-01-18 18:28:11,061:INFO:_display_container: 2
2024-01-18 18:28:11,062:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4558, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-18 18:28:11,062:INFO:create_model() successfully completed......................................
2024-01-18 18:28:11,320:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:11,320:INFO:Creating metrics dataframe
2024-01-18 18:28:11,337:INFO:Initializing Ridge Classifier
2024-01-18 18:28:11,337:INFO:Total runtime is 1.2818601846694946 minutes
2024-01-18 18:28:11,352:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:11,357:INFO:Initializing create_model()
2024-01-18 18:28:11,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:11,357:INFO:Checking exceptions
2024-01-18 18:28:11,357:INFO:Importing libraries
2024-01-18 18:28:11,357:INFO:Copying training dataset
2024-01-18 18:28:11,365:INFO:Defining folds
2024-01-18 18:28:11,365:INFO:Declaring metric variables
2024-01-18 18:28:11,371:INFO:Importing untrained model
2024-01-18 18:28:11,374:INFO:Ridge Classifier Imported successfully
2024-01-18 18:28:11,381:INFO:Starting cross validation
2024-01-18 18:28:11,385:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:11,796:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:11,796:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:11,796:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:11,811:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:12,031:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:12,047:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:12,062:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:12,062:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:12,328:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:12,328:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-18 18:28:12,359:INFO:Calculating mean and std
2024-01-18 18:28:12,359:INFO:Creating metrics dataframe
2024-01-18 18:28:12,359:INFO:Uploading results into container
2024-01-18 18:28:12,359:INFO:Uploading model into container now
2024-01-18 18:28:12,359:INFO:_master_model_container: 6
2024-01-18 18:28:12,359:INFO:_display_container: 2
2024-01-18 18:28:12,359:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4558, solver='auto',
                tol=0.0001)
2024-01-18 18:28:12,359:INFO:create_model() successfully completed......................................
2024-01-18 18:28:12,591:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:12,591:INFO:Creating metrics dataframe
2024-01-18 18:28:12,622:INFO:Initializing Random Forest Classifier
2024-01-18 18:28:12,622:INFO:Total runtime is 1.3032750209172566 minutes
2024-01-18 18:28:12,622:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:12,622:INFO:Initializing create_model()
2024-01-18 18:28:12,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:12,622:INFO:Checking exceptions
2024-01-18 18:28:12,622:INFO:Importing libraries
2024-01-18 18:28:12,622:INFO:Copying training dataset
2024-01-18 18:28:12,646:INFO:Defining folds
2024-01-18 18:28:12,646:INFO:Declaring metric variables
2024-01-18 18:28:12,651:INFO:Importing untrained model
2024-01-18 18:28:12,656:INFO:Random Forest Classifier Imported successfully
2024-01-18 18:28:12,667:INFO:Starting cross validation
2024-01-18 18:28:12,667:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:16,103:INFO:Calculating mean and std
2024-01-18 18:28:16,103:INFO:Creating metrics dataframe
2024-01-18 18:28:16,121:INFO:Uploading results into container
2024-01-18 18:28:16,122:INFO:Uploading model into container now
2024-01-18 18:28:16,123:INFO:_master_model_container: 7
2024-01-18 18:28:16,124:INFO:_display_container: 2
2024-01-18 18:28:16,126:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4558, verbose=0, warm_start=False)
2024-01-18 18:28:16,126:INFO:create_model() successfully completed......................................
2024-01-18 18:28:16,340:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:16,340:INFO:Creating metrics dataframe
2024-01-18 18:28:16,355:INFO:Initializing Quadratic Discriminant Analysis
2024-01-18 18:28:16,355:INFO:Total runtime is 1.3655021985371907 minutes
2024-01-18 18:28:16,368:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:16,369:INFO:Initializing create_model()
2024-01-18 18:28:16,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:16,369:INFO:Checking exceptions
2024-01-18 18:28:16,370:INFO:Importing libraries
2024-01-18 18:28:16,370:INFO:Copying training dataset
2024-01-18 18:28:16,377:INFO:Defining folds
2024-01-18 18:28:16,378:INFO:Declaring metric variables
2024-01-18 18:28:16,382:INFO:Importing untrained model
2024-01-18 18:28:16,389:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-18 18:28:16,401:INFO:Starting cross validation
2024-01-18 18:28:16,404:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:16,937:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:16,937:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:16,937:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:16,940:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:17,190:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:17,190:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:17,209:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:17,222:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:17,428:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:17,443:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-18 18:28:17,494:INFO:Calculating mean and std
2024-01-18 18:28:17,505:INFO:Creating metrics dataframe
2024-01-18 18:28:17,505:INFO:Uploading results into container
2024-01-18 18:28:17,505:INFO:Uploading model into container now
2024-01-18 18:28:17,505:INFO:_master_model_container: 8
2024-01-18 18:28:17,505:INFO:_display_container: 2
2024-01-18 18:28:17,505:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-18 18:28:17,505:INFO:create_model() successfully completed......................................
2024-01-18 18:28:17,708:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:17,708:INFO:Creating metrics dataframe
2024-01-18 18:28:17,723:INFO:Initializing Ada Boost Classifier
2024-01-18 18:28:17,723:INFO:Total runtime is 1.3883054773012797 minutes
2024-01-18 18:28:17,733:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:17,734:INFO:Initializing create_model()
2024-01-18 18:28:17,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:17,735:INFO:Checking exceptions
2024-01-18 18:28:17,735:INFO:Importing libraries
2024-01-18 18:28:17,735:INFO:Copying training dataset
2024-01-18 18:28:17,744:INFO:Defining folds
2024-01-18 18:28:17,744:INFO:Declaring metric variables
2024-01-18 18:28:17,749:INFO:Importing untrained model
2024-01-18 18:28:17,755:INFO:Ada Boost Classifier Imported successfully
2024-01-18 18:28:17,765:INFO:Starting cross validation
2024-01-18 18:28:17,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:19,784:INFO:Calculating mean and std
2024-01-18 18:28:19,784:INFO:Creating metrics dataframe
2024-01-18 18:28:19,796:INFO:Uploading results into container
2024-01-18 18:28:19,798:INFO:Uploading model into container now
2024-01-18 18:28:19,799:INFO:_master_model_container: 9
2024-01-18 18:28:19,800:INFO:_display_container: 2
2024-01-18 18:28:19,800:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=4558)
2024-01-18 18:28:19,800:INFO:create_model() successfully completed......................................
2024-01-18 18:28:20,023:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:20,023:INFO:Creating metrics dataframe
2024-01-18 18:28:20,054:INFO:Initializing Gradient Boosting Classifier
2024-01-18 18:28:20,054:INFO:Total runtime is 1.4271486282348633 minutes
2024-01-18 18:28:20,060:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:20,060:INFO:Initializing create_model()
2024-01-18 18:28:20,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:20,061:INFO:Checking exceptions
2024-01-18 18:28:20,061:INFO:Importing libraries
2024-01-18 18:28:20,061:INFO:Copying training dataset
2024-01-18 18:28:20,069:INFO:Defining folds
2024-01-18 18:28:20,069:INFO:Declaring metric variables
2024-01-18 18:28:20,074:INFO:Importing untrained model
2024-01-18 18:28:20,080:INFO:Gradient Boosting Classifier Imported successfully
2024-01-18 18:28:20,089:INFO:Starting cross validation
2024-01-18 18:28:20,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:23,517:INFO:Calculating mean and std
2024-01-18 18:28:23,517:INFO:Creating metrics dataframe
2024-01-18 18:28:23,533:INFO:Uploading results into container
2024-01-18 18:28:23,533:INFO:Uploading model into container now
2024-01-18 18:28:23,533:INFO:_master_model_container: 10
2024-01-18 18:28:23,533:INFO:_display_container: 2
2024-01-18 18:28:23,537:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4558, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-18 18:28:23,537:INFO:create_model() successfully completed......................................
2024-01-18 18:28:23,772:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:23,772:INFO:Creating metrics dataframe
2024-01-18 18:28:23,804:INFO:Initializing Linear Discriminant Analysis
2024-01-18 18:28:23,804:INFO:Total runtime is 1.489642616113027 minutes
2024-01-18 18:28:23,815:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:23,816:INFO:Initializing create_model()
2024-01-18 18:28:23,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:23,816:INFO:Checking exceptions
2024-01-18 18:28:23,816:INFO:Importing libraries
2024-01-18 18:28:23,816:INFO:Copying training dataset
2024-01-18 18:28:23,826:INFO:Defining folds
2024-01-18 18:28:23,826:INFO:Declaring metric variables
2024-01-18 18:28:23,830:INFO:Importing untrained model
2024-01-18 18:28:23,834:INFO:Linear Discriminant Analysis Imported successfully
2024-01-18 18:28:23,842:INFO:Starting cross validation
2024-01-18 18:28:23,844:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:24,807:INFO:Calculating mean and std
2024-01-18 18:28:24,807:INFO:Creating metrics dataframe
2024-01-18 18:28:24,807:INFO:Uploading results into container
2024-01-18 18:28:24,807:INFO:Uploading model into container now
2024-01-18 18:28:24,807:INFO:_master_model_container: 11
2024-01-18 18:28:24,807:INFO:_display_container: 2
2024-01-18 18:28:24,807:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-18 18:28:24,807:INFO:create_model() successfully completed......................................
2024-01-18 18:28:25,040:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:25,040:INFO:Creating metrics dataframe
2024-01-18 18:28:25,040:INFO:Initializing Extra Trees Classifier
2024-01-18 18:28:25,040:INFO:Total runtime is 1.51024493376414 minutes
2024-01-18 18:28:25,056:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:25,057:INFO:Initializing create_model()
2024-01-18 18:28:25,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:25,057:INFO:Checking exceptions
2024-01-18 18:28:25,057:INFO:Importing libraries
2024-01-18 18:28:25,058:INFO:Copying training dataset
2024-01-18 18:28:25,064:INFO:Defining folds
2024-01-18 18:28:25,065:INFO:Declaring metric variables
2024-01-18 18:28:25,069:INFO:Importing untrained model
2024-01-18 18:28:25,073:INFO:Extra Trees Classifier Imported successfully
2024-01-18 18:28:25,080:INFO:Starting cross validation
2024-01-18 18:28:25,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:28,284:INFO:Calculating mean and std
2024-01-18 18:28:28,284:INFO:Creating metrics dataframe
2024-01-18 18:28:28,284:INFO:Uploading results into container
2024-01-18 18:28:28,300:INFO:Uploading model into container now
2024-01-18 18:28:28,300:INFO:_master_model_container: 12
2024-01-18 18:28:28,300:INFO:_display_container: 2
2024-01-18 18:28:28,300:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4558, verbose=0, warm_start=False)
2024-01-18 18:28:28,300:INFO:create_model() successfully completed......................................
2024-01-18 18:28:28,507:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:28,507:INFO:Creating metrics dataframe
2024-01-18 18:28:28,523:INFO:Initializing Extreme Gradient Boosting
2024-01-18 18:28:28,523:INFO:Total runtime is 1.5682959636052451 minutes
2024-01-18 18:28:28,523:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:28,523:INFO:Initializing create_model()
2024-01-18 18:28:28,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:28,523:INFO:Checking exceptions
2024-01-18 18:28:28,523:INFO:Importing libraries
2024-01-18 18:28:28,523:INFO:Copying training dataset
2024-01-18 18:28:28,538:INFO:Defining folds
2024-01-18 18:28:28,538:INFO:Declaring metric variables
2024-01-18 18:28:28,544:INFO:Importing untrained model
2024-01-18 18:28:28,549:INFO:Extreme Gradient Boosting Imported successfully
2024-01-18 18:28:28,556:INFO:Starting cross validation
2024-01-18 18:28:28,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:30,216:INFO:Calculating mean and std
2024-01-18 18:28:30,216:INFO:Creating metrics dataframe
2024-01-18 18:28:30,232:INFO:Uploading results into container
2024-01-18 18:28:30,232:INFO:Uploading model into container now
2024-01-18 18:28:30,232:INFO:_master_model_container: 13
2024-01-18 18:28:30,232:INFO:_display_container: 2
2024-01-18 18:28:30,232:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-01-18 18:28:30,232:INFO:create_model() successfully completed......................................
2024-01-18 18:28:30,468:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:30,468:INFO:Creating metrics dataframe
2024-01-18 18:28:30,495:INFO:Initializing Light Gradient Boosting Machine
2024-01-18 18:28:30,495:INFO:Total runtime is 1.6011646509170534 minutes
2024-01-18 18:28:30,508:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:30,509:INFO:Initializing create_model()
2024-01-18 18:28:30,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:30,509:INFO:Checking exceptions
2024-01-18 18:28:30,509:INFO:Importing libraries
2024-01-18 18:28:30,509:INFO:Copying training dataset
2024-01-18 18:28:30,518:INFO:Defining folds
2024-01-18 18:28:30,518:INFO:Declaring metric variables
2024-01-18 18:28:30,524:INFO:Importing untrained model
2024-01-18 18:28:30,529:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 18:28:30,536:INFO:Starting cross validation
2024-01-18 18:28:30,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:32,583:INFO:Calculating mean and std
2024-01-18 18:28:32,599:INFO:Creating metrics dataframe
2024-01-18 18:28:32,606:INFO:Uploading results into container
2024-01-18 18:28:32,606:INFO:Uploading model into container now
2024-01-18 18:28:32,607:INFO:_master_model_container: 14
2024-01-18 18:28:32,608:INFO:_display_container: 2
2024-01-18 18:28:32,608:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 18:28:32,608:INFO:create_model() successfully completed......................................
2024-01-18 18:28:32,807:INFO:SubProcess create_model() end ==================================
2024-01-18 18:28:32,823:INFO:Creating metrics dataframe
2024-01-18 18:28:32,839:INFO:Initializing CatBoost Classifier
2024-01-18 18:28:32,839:INFO:Total runtime is 1.6402242978413901 minutes
2024-01-18 18:28:32,839:INFO:SubProcess create_model() called ==================================
2024-01-18 18:28:32,839:INFO:Initializing create_model()
2024-01-18 18:28:32,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:28:32,839:INFO:Checking exceptions
2024-01-18 18:28:32,839:INFO:Importing libraries
2024-01-18 18:28:32,839:INFO:Copying training dataset
2024-01-18 18:28:32,854:INFO:Defining folds
2024-01-18 18:28:32,854:INFO:Declaring metric variables
2024-01-18 18:28:32,854:INFO:Importing untrained model
2024-01-18 18:28:32,870:INFO:CatBoost Classifier Imported successfully
2024-01-18 18:28:32,885:INFO:Starting cross validation
2024-01-18 18:28:32,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:28:50,261:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,261:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,261:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,261:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,261:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,261:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,261:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,261:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,261:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:50,262:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:59,977:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:59,977:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:59,977:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:59,977:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:59,977:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:28:59,977:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,024:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,040:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,040:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,040:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,040:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,040:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:00,040:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\pycaret\internal\metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
           ^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,795:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in union1d
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in unique
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\numpy\lib\arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'str' and 'bool'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2024-01-18 18:29:07,811:INFO:Calculating mean and std
2024-01-18 18:29:07,811:INFO:Creating metrics dataframe
2024-01-18 18:29:07,811:INFO:Uploading results into container
2024-01-18 18:29:07,811:INFO:Uploading model into container now
2024-01-18 18:29:07,811:INFO:_master_model_container: 15
2024-01-18 18:29:07,811:INFO:_display_container: 2
2024-01-18 18:29:07,811:INFO:<catboost.core.CatBoostClassifier object at 0x000001EFCE0B4110>
2024-01-18 18:29:07,811:INFO:create_model() successfully completed......................................
2024-01-18 18:29:08,023:INFO:SubProcess create_model() end ==================================
2024-01-18 18:29:08,023:INFO:Creating metrics dataframe
2024-01-18 18:29:08,039:INFO:Initializing Dummy Classifier
2024-01-18 18:29:08,039:INFO:Total runtime is 2.2268901387850444 minutes
2024-01-18 18:29:08,039:INFO:SubProcess create_model() called ==================================
2024-01-18 18:29:08,039:INFO:Initializing create_model()
2024-01-18 18:29:08,039:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EFD137EA50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:29:08,039:INFO:Checking exceptions
2024-01-18 18:29:08,039:INFO:Importing libraries
2024-01-18 18:29:08,039:INFO:Copying training dataset
2024-01-18 18:29:08,039:INFO:Defining folds
2024-01-18 18:29:08,039:INFO:Declaring metric variables
2024-01-18 18:29:08,039:INFO:Importing untrained model
2024-01-18 18:29:08,054:INFO:Dummy Classifier Imported successfully
2024-01-18 18:29:08,070:INFO:Starting cross validation
2024-01-18 18:29:08,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-18 18:29:08,847:INFO:Calculating mean and std
2024-01-18 18:29:08,847:INFO:Creating metrics dataframe
2024-01-18 18:29:08,847:INFO:Uploading results into container
2024-01-18 18:29:08,847:INFO:Uploading model into container now
2024-01-18 18:29:08,847:INFO:_master_model_container: 16
2024-01-18 18:29:08,847:INFO:_display_container: 2
2024-01-18 18:29:08,847:INFO:DummyClassifier(constant=None, random_state=4558, strategy='prior')
2024-01-18 18:29:08,847:INFO:create_model() successfully completed......................................
2024-01-18 18:29:09,071:INFO:SubProcess create_model() end ==================================
2024-01-18 18:29:09,071:INFO:Creating metrics dataframe
2024-01-18 18:29:09,117:INFO:Initializing create_model()
2024-01-18 18:29:09,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:29:09,117:INFO:Checking exceptions
2024-01-18 18:29:09,120:INFO:Importing libraries
2024-01-18 18:29:09,120:INFO:Copying training dataset
2024-01-18 18:29:09,125:INFO:Defining folds
2024-01-18 18:29:09,125:INFO:Declaring metric variables
2024-01-18 18:29:09,125:INFO:Importing untrained model
2024-01-18 18:29:09,125:INFO:Declaring custom model
2024-01-18 18:29:09,126:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 18:29:09,127:INFO:Cross validation set to False
2024-01-18 18:29:09,127:INFO:Fitting Model
2024-01-18 18:29:10,840:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-18 18:29:10,840:INFO:[LightGBM] [Info] Number of positive: 3065, number of negative: 3020
2024-01-18 18:29:10,840:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2024-01-18 18:29:10,840:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-18 18:29:10,840:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-18 18:29:10,852:INFO:[LightGBM] [Info] Total Bins 1371
2024-01-18 18:29:10,852:INFO:[LightGBM] [Info] Number of data points in the train set: 6085, number of used features: 14
2024-01-18 18:29:10,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503698 -> initscore=0.014791
2024-01-18 18:29:10,852:INFO:[LightGBM] [Info] Start training from score 0.014791
2024-01-18 18:29:11,251:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 18:29:11,251:INFO:create_model() successfully completed......................................
2024-01-18 18:29:11,521:INFO:_master_model_container: 16
2024-01-18 18:29:11,522:INFO:_display_container: 2
2024-01-18 18:29:11,522:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 18:29:11,523:INFO:compare_models() successfully completed......................................
2024-01-18 18:29:18,294:INFO:Initializing finalize_model()
2024-01-18 18:29:18,294:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-18 18:29:18,295:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-18 18:29:18,300:INFO:Initializing create_model()
2024-01-18 18:29:18,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-01-18 18:29:18,300:INFO:Checking exceptions
2024-01-18 18:29:18,303:INFO:Importing libraries
2024-01-18 18:29:18,303:INFO:Copying training dataset
2024-01-18 18:29:18,303:INFO:Defining folds
2024-01-18 18:29:18,304:INFO:Declaring metric variables
2024-01-18 18:29:18,304:INFO:Importing untrained model
2024-01-18 18:29:18,304:INFO:Declaring custom model
2024-01-18 18:29:18,305:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-18 18:29:18,308:INFO:Cross validation set to False
2024-01-18 18:29:18,308:INFO:Fitting Model
2024-01-18 18:29:18,520:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-18 18:29:18,520:INFO:[LightGBM] [Info] Number of positive: 4378, number of negative: 4315
2024-01-18 18:29:18,522:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001128 seconds.
2024-01-18 18:29:18,522:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-01-18 18:29:18,522:INFO:[LightGBM] [Info] Total Bins 1372
2024-01-18 18:29:18,522:INFO:[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 14
2024-01-18 18:29:18,523:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495
2024-01-18 18:29:18,523:INFO:[LightGBM] [Info] Start training from score 0.014495
2024-01-18 18:29:19,719:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=4558, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-18 18:29:19,719:INFO:create_model() successfully completed......................................
2024-01-18 18:29:19,923:INFO:_master_model_container: 16
2024-01-18 18:29:19,923:INFO:_display_container: 2
2024-01-18 18:29:20,048:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=4558, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-18 18:29:20,048:INFO:finalize_model() successfully completed......................................
2024-01-18 18:29:21,291:INFO:Initializing evaluate_model()
2024-01-18 18:29:21,291:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-18 18:29:21,308:INFO:Initializing plot_model()
2024-01-18 18:29:21,308:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-01-18 18:29:21,308:INFO:Checking exceptions
2024-01-18 18:29:21,310:INFO:Preloading libraries
2024-01-18 18:29:21,322:INFO:Copying training dataset
2024-01-18 18:29:21,322:INFO:Plot type: pipeline
2024-01-18 18:29:22,245:INFO:Visual Rendered Successfully
2024-01-18 18:29:22,455:INFO:plot_model() successfully completed......................................
2024-01-18 18:29:22,680:INFO:Initializing predict_model()
2024-01-18 18:29:22,680:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFC3588410>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4558, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EFC6AC79C0>)
2024-01-18 18:29:22,680:INFO:Checking exceptions
2024-01-18 18:29:22,680:INFO:Preloading libraries
2024-01-18 18:29:28,943:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:29,547:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:29,609:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:32,594:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:33,114:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:33,194:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:33,850:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:34,468:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:34,480:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:35,060:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:35,066:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:35,645:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:35,651:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:36,114:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:36,114:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:36,745:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:36,745:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:37,357:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:37,357:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:37,938:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:37,938:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:38,455:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:38,456:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:38,988:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,004:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\ensemble\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,599:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,599:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,614:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,614:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,614:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,630:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,630:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,630:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,646:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,646:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,661:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,661:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,661:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,677:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,677:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,677:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,693:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,693:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,708:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:39,708:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:39,724:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,370:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,385:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,385:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,401:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,401:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,417:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,417:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,433:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,448:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,480:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,480:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,527:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,527:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,558:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,558:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,589:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,606:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,637:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:29:40,637:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-01-18 18:29:40,652:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 18:46:50,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 18:46:50,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 18:46:50,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 18:46:50,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 19:24:24,219:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\joblib\externals\loky\backend\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2024-01-18 21:22:52,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 21:22:52,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 21:22:52,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 21:22:52,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-18 21:47:57,450:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\joblib\externals\loky\backend\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2024-01-18 21:48:31,743:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:34,387:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:36,954:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:39,067:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:41,446:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:43,964:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:46,613:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:49,301:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:51,882:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:54,280:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:54,940:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:55,639:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:56,591:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:57,486:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:58,425:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:48:59,349:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:00,234:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:01,143:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:02,037:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:02,946:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,080:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,122:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,168:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,216:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,263:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,310:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,357:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,412:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,452:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

2024-01-18 21:49:05,501:WARNING:C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Auditor\anaconda3.2\Lib\site-packages\sklearn\metrics\_regression.py", line 446, in mean_squared_error
    output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)
                                ~~~~~~~^~~~~~~~
TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.

  warnings.warn(

